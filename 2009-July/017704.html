<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r31402 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2009-July/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r31402%20-%0A%09haiku/trunk/src/add-ons/media/plugins/ffmpeg&In-Reply-To=%3C200907032140.n63LeLeH015903%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017703.html">
   <LINK REL="Next"  HREF="017705.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r31402 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg</H1>
    <B>stippi at mail.berlios.de</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r31402%20-%0A%09haiku/trunk/src/add-ons/media/plugins/ffmpeg&In-Reply-To=%3C200907032140.n63LeLeH015903%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r31402 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg">stippi at mail.berlios.de
       </A><BR>
    <I>Fri Jul  3 23:40:21 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="017703.html">[Haiku-commits] r31401 - haiku/trunk/src/bin/network/ftpd
</A></li>
        <LI>Next message: <A HREF="017705.html">[Haiku-commits] r31403 - in haiku/trunk/docs: . userguide/en	userguide/en/applications userguide/en/preferences	userguide/images userguide/images/apps-images	userguide/images/queries-images
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17704">[ date ]</a>
              <a href="thread.html#17704">[ thread ]</a>
              <a href="subject.html#17704">[ subject ]</a>
              <a href="author.html#17704">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: stippi
Date: 2009-07-03 23:40:19 +0200 (Fri, 03 Jul 2009)
New Revision: 31402
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=31402&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=31402&amp;view=rev</A>

Modified:
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.h
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.cpp
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.h
Log:
* Fleshed out some more of the format detection.
* Moved stuff from testing in Sniff() into class members.
* Added function to gfx_utils() that converts an FFmpeg pix_fmt to color_space.


Modified: haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp	2009-07-03 21:31:28 UTC (rev 31401)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp	2009-07-03 21:40:19 UTC (rev 31402)
@@ -13,13 +13,10 @@
 
 #include &lt;ByteOrder.h&gt;
 #include &lt;DataIO.h&gt;
-//#include &lt;InterfaceDefs.h&gt;
+#include &lt;MediaDefs.h&gt;
 #include &lt;MediaFormats.h&gt;
 
-extern &quot;C&quot; {
-	#include &quot;avformat.h&quot;
-	#include &quot;libavutil/avstring.h&quot;
-}
+#include &quot;gfx_util.h&quot;
 
 //#include &quot;RawFormats.h&quot;
 
@@ -36,11 +33,18 @@
 #define ERROR(a...) fprintf(stderr, a)
 
 
+static const size_t kIOBufferSize = 64 * 1024;
+	// TODO: This could depend on the BMediaFile creation flags, IIRC,
+	// the allow to specify a buffering mode.
+
+
 AVFormatReader::AVFormatReader()
 	:
-	fContext(NULL)
+	fContext(NULL),
+	fIOBuffer(NULL)
 {
 	TRACE(&quot;AVFormatReader::AVFormatReader\n&quot;);
+	memset(&amp;fFormatParameters, 0, sizeof(fFormatParameters));
 }
 
 
@@ -48,7 +52,8 @@
 {
 	TRACE(&quot;AVFormatReader::~AVFormatReader\n&quot;);
 
-	// TODO: Deallocate fContext
+	av_free(fContext);
+	free(fIOBuffer);
 }
 
 
@@ -68,16 +73,17 @@
 {
 	TRACE(&quot;AVFormatReader::Sniff\n&quot;);
 
-	size_t bufferSize = 64 * 1024;
+	free(fIOBuffer);
+	fIOBuffer = (uint8*)malloc(kIOBufferSize);
+
 	size_t probeSize = 1024;
-	uint8 buffer[bufferSize];
 	AVProbeData probeData;
 	probeData.filename = &quot;&quot;;
-	probeData.buf = buffer;
+	probeData.buf = fIOBuffer;
 	probeData.buf_size = probeSize;
 
 	// Read a bit of the input...
-	if (_ReadPacket(Source(), buffer, probeSize) != (ssize_t)probeSize)
+	if (_ReadPacket(Source(), fIOBuffer, probeSize) != (ssize_t)probeSize)
 		return B_IO_ERROR;
 	// ...and seek back to the beginning of the file.
 	_Seek(Source(), 0, SEEK_SET);
@@ -93,20 +99,15 @@
 	TRACE(&quot;AVFormatReader::Sniff() - av_probe_input_format(): %s\n&quot;,
 		inputFormat-&gt;name);
 
-	ByteIOContext ioContext;
-
-	// Init io module for input
-	if (init_put_byte(&amp;ioContext, buffer, bufferSize, 0, Source(),
+	// Init I/O context with buffer and hook functions
+	if (init_put_byte(&amp;fIOContext, fIOBuffer, kIOBufferSize, 0, Source(),
 		_ReadPacket, 0, _Seek) != 0) {
 		TRACE(&quot;AVFormatReader::Sniff() - init_put_byte() failed!\n&quot;);
 		return B_ERROR;
 	}
 
-	AVFormatParameters formatParameters;
-	memset(&amp;formatParameters, 0, sizeof(formatParameters));
-
-	if (av_open_input_stream(&amp;fContext, &amp;ioContext, &quot;&quot;, inputFormat,
-		&amp;formatParameters) &lt; 0) {
+	if (av_open_input_stream(&amp;fContext, &amp;fIOContext, &quot;&quot;, inputFormat,
+		&amp;fFormatParameters) &lt; 0) {
 		TRACE(&quot;AVFormatReader::Sniff() - av_open_input_stream() failed!\n&quot;);
 		return B_ERROR;
 	}
@@ -122,7 +123,11 @@
 	// Dump information about stream onto standard error
 	dump_format(fContext, 0, &quot;&quot;, 0);
 
-	return B_ERROR;
+	if (streamCount != NULL)
+		*streamCount = fContext-&gt;nb_streams;
+
+//	return B_OK;
+return B_ERROR; // For now...
 }
 
 
@@ -131,16 +136,41 @@
 {
 	TRACE(&quot;AVFormatReader::GetFileFormatInfo\n&quot;);
 
+	if (fContext == NULL || fContext-&gt;iformat == NULL) {
+		TRACE(&quot;  no context or AVInputFormat!\n&quot;);
+		return;
+	}
+
 	mff-&gt;capabilities = media_file_format::B_READABLE
 		| media_file_format::B_KNOWS_ENCODED_VIDEO
 		| media_file_format::B_KNOWS_ENCODED_AUDIO
 		| media_file_format::B_IMPERFECTLY_SEEKABLE;
 	mff-&gt;family = B_MISC_FORMAT_FAMILY;
 	mff-&gt;version = 100;
-	strcpy(mff-&gt;mime_type, &quot;video/mpg&quot;);
-	strcpy(mff-&gt;file_extension, &quot;mpg&quot;);
-	strcpy(mff-&gt;short_name,  &quot;MPEG&quot;);
-	strcpy(mff-&gt;pretty_name, &quot;MPEG (Motion Picture Experts Group)&quot;);
+	strcpy(mff-&gt;mime_type, &quot;&quot;);
+		// TODO: Would be nice to be able to provide this, maybe by extending
+		// the FFmpeg code itself (all demuxers, see AVInputFormat struct).
+
+	if (fContext-&gt;iformat-&gt;extensions != NULL)
+		strcpy(mff-&gt;file_extension, fContext-&gt;iformat-&gt;extensions);
+	else {
+		TRACE(&quot;  no file extensions for AVInputFormat.\n&quot;);
+		strcpy(mff-&gt;file_extension, &quot;&quot;);
+	}
+
+	if (fContext-&gt;iformat-&gt;name != NULL)
+		strcpy(mff-&gt;short_name,  fContext-&gt;iformat-&gt;name);
+	else {
+		TRACE(&quot;  no short name for AVInputFormat.\n&quot;);
+		strcpy(mff-&gt;short_name,  &quot;&quot;);
+	}
+
+	if (fContext-&gt;iformat-&gt;long_name != NULL)
+		strcpy(mff-&gt;pretty_name, fContext-&gt;iformat-&gt;long_name);
+	else {
+		TRACE(&quot;  no long name for AVInputFormat.\n&quot;);
+		strcpy(mff-&gt;pretty_name, &quot;&quot;);
+	}
 }
 
 
@@ -148,18 +178,132 @@
 
 
 status_t
-AVFormatReader::AllocateCookie(int32 streamNumber, void** _cookie)
+AVFormatReader::AllocateCookie(int32 streamIndex, void** _cookie)
 {
-	TRACE(&quot;AVFormatReader::AllocateCookie(%ld)\n&quot;, streamNumber);
+	TRACE(&quot;AVFormatReader::AllocateCookie(%ld)\n&quot;, streamIndex);
 
-	return B_ERROR;
+	if (fContext == NULL)
+		return B_NO_INIT;
+
+	if (streamIndex &lt; 0 || streamIndex &gt;= (int32)fContext-&gt;nb_streams)
+		return B_BAD_INDEX;
+
+	if (_cookie == NULL)
+		return B_BAD_VALUE;
+
+	StreamCookie* cookie = new(std::nothrow) StreamCookie;
+	if (cookie == NULL)
+		return B_NO_MEMORY;
+
+	// Get a pointer to the codec context for the stream at sreamIndex.
+	AVCodecContext* codecContext = fContext-&gt;streams[streamIndex]-&gt;codec;
+	AVCodec* codec = avcodec_find_decoder(codecContext-&gt;codec_id);
+	if (codec == NULL || avcodec_open(codecContext, codec) &lt; 0) {
+		delete cookie;
+		return B_ERROR;
+	}
+
+//    codecContext-&gt;get_buffer = _GetBuffer;
+//    codecContext-&gt;release_buffer = _ReleaseBuffer;
+
+	AVStream* stream = fContext-&gt;streams[streamIndex];
+
+	cookie-&gt;stream = stream;
+	cookie-&gt;codecContext = codecContext;
+	cookie-&gt;codec = codec;
+
+	media_format* format = &amp;cookie-&gt;format;
+	memset(format, 0, sizeof(media_format));
+
+	BMediaFormats formats;
+	media_format_description description;
+
+	if (stream-&gt;codec-&gt;codec_type == CODEC_TYPE_VIDEO) {
+		// TODO: Fix this up! Maybe do this for AVI demuxer and MOV
+		// demuxer and use B_MISC_FORMAT_FAMILY for all the others?
+		description.family = B_AVI_FORMAT_FAMILY;
+		description.u.avi.codec = codecContext-&gt;codec_tag;
+		TRACE(&quot;  fourcc '%.4s'\n&quot;, (char*)&amp;codecContext-&gt;codec_tag);
+
+		if (formats.GetFormatFor(description, format) &lt; B_OK)
+			format-&gt;type = B_MEDIA_ENCODED_VIDEO;
+
+//		format-&gt;require_flags = 
+//		format-&gt;deny_flags = 
+
+		format-&gt;user_data_type = B_CODEC_TYPE_INFO;
+		*(uint32*)format-&gt;user_data = codecContext-&gt;codec_tag;
+		format-&gt;user_data[4] = 0;
+
+		// TODO: We don't actually know the bitrate for this stream,
+		// only the total bitrate!
+		format-&gt;u.encoded_video.avg_bit_rate = codecContext-&gt;bit_rate; 
+		format-&gt;u.encoded_video.max_bit_rate = codecContext-&gt;bit_rate
+			+ codecContext-&gt;bit_rate_tolerance;
+
+		format-&gt;u.encoded_video.encoding = media_encoded_video_format::B_ANY;
+
+		format-&gt;u.encoded_video.frame_size = 1;
+//		format-&gt;u.encoded_video.forward_history = 0;
+//		format-&gt;u.encoded_video.backward_history = 0;
+
+		format-&gt;u.encoded_video.output.field_rate
+			= av_q2d(stream-&gt;r_frame_rate);
+		format-&gt;u.encoded_video.output.interlace = 1;
+			// TODO: Fix up for interlaced video
+		format-&gt;u.encoded_video.output.first_active = 0;
+		format-&gt;u.encoded_video.output.last_active = 0;
+			// TODO: Maybe libavformat actually provides that info somewhere...
+		format-&gt;u.encoded_video.output.orientation = B_VIDEO_TOP_LEFT_RIGHT;
+
+		// TODO: Implement aspect ratio for real
+		format-&gt;u.encoded_video.output.pixel_width_aspect
+			= 1;//stream-&gt;sample_aspect_ratio.num;
+		format-&gt;u.encoded_video.output.pixel_height_aspect
+			= 1;//stream-&gt;sample_aspect_ratio.den;
+
+		TRACE(&quot;  pixel width/height aspect: %d/%d or %.4f\n&quot;,
+			stream-&gt;sample_aspect_ratio.num,
+			stream-&gt;sample_aspect_ratio.den,
+			av_q2d(stream-&gt;sample_aspect_ratio));
+
+		format-&gt;u.encoded_video.output.display.format
+			= pixfmt_to_colorspace(codecContext-&gt;pix_fmt);
+		format-&gt;u.encoded_video.output.display.line_width = codecContext-&gt;width;
+		format-&gt;u.encoded_video.output.display.line_count = codecContext-&gt;height;
+		format-&gt;u.encoded_video.output.display.bytes_per_row = 0;
+		format-&gt;u.encoded_video.output.display.pixel_offset = 0;
+		format-&gt;u.encoded_video.output.display.line_offset = 0;
+		format-&gt;u.encoded_video.output.display.flags = 0; // TODO
+
+		uint32 encoding = format-&gt;Encoding();
+		TRACE(&quot;  encoding '%.4s'\n&quot;, (char*)&amp;encoding);
+
+	} else if (stream-&gt;codec-&gt;codec_type == CODEC_TYPE_AUDIO) {
+		format-&gt;type = B_MEDIA_ENCODED_AUDIO;
+//		format-&gt;require_flags = 
+//		format-&gt;deny_flags = 
+
+//		format-&gt;u.encoded_audio.
+	} else {
+		return B_NOT_SUPPORTED;
+	}
+
+	*_cookie = cookie;
+
+	return B_OK;
 }
 
 
 status_t
 AVFormatReader::FreeCookie(void *_cookie)
 {
-	return B_ERROR;
+	StreamCookie* cookie = reinterpret_cast&lt;StreamCookie*&gt;(_cookie);
+
+	avcodec_close(cookie-&gt;codecContext);
+	delete cookie;
+
+	return B_OK;
 }
 
 
@@ -171,7 +315,35 @@
 	bigtime_t* duration, media_format* format, const void** infoBuffer,
 	size_t* infoSize)
 {
-	return B_ERROR;
+	TRACE(&quot;AVFormatReader::GetStreamInfo()\n&quot;);
+
+	StreamCookie* cookie = reinterpret_cast&lt;StreamCookie*&gt;(_cookie);
+	AVStream* stream = cookie-&gt;stream;
+
+	double frameRate = av_q2d(stream-&gt;r_frame_rate);
+
+	TRACE(&quot;  frameRate: %.4f\n&quot;, frameRate);
+
+	*duration = (bigtime_t)(1000000LL * stream-&gt;duration
+		* av_q2d(stream-&gt;time_base));
+
+	TRACE(&quot;  duration: %lld\n&quot;, *duration);
+
+	*frameCount = stream-&gt;nb_frames;
+	if (*frameCount == 0) {
+		// TODO: Calculate from duration and frame rate!
+		*frameCount = (int64)(*duration * frameRate / 1000000);
+	}
+
+	TRACE(&quot;  frameCount: %lld\n&quot;, *frameCount);
+
+	*format = cookie-&gt;format;
+
+	// TODO: Possibly use stream-&gt;metadata for this:
+	*infoBuffer = 0;
+	*infoSize = 0;
+
+	return B_OK;
 }
 
 

Modified: haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.h
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.h	2009-07-03 21:31:28 UTC (rev 31401)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.h	2009-07-03 21:40:19 UTC (rev 31402)
@@ -8,10 +8,11 @@
 
 #include &quot;ReaderPlugin.h&quot;
 
+extern &quot;C&quot; {
+	#include &quot;avformat.h&quot;
+}
 
-struct AVFormatContext;
 
-
 class AVFormatReader : public Reader {
 public:
 								AVFormatReader();
@@ -49,6 +50,20 @@
 									off_t offset, int whence);
 
 			AVFormatContext*	fContext;
+			AVFormatParameters	fFormatParameters;
+			ByteIOContext		fIOContext;
+			uint8*				fIOBuffer;
+
+	struct StreamCookie {
+		AVStream*			stream;
+		AVCodecContext*		codecContext;
+		AVCodec*			codec;
+		media_format		format;
+		// TODO: Maybe we don't need the codec after all, maybe we do
+		// for getting stream information...
+		// TODO: Some form of packet queue
+	};
+
 };
 
 

Modified: haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.cpp
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.cpp	2009-07-03 21:31:28 UTC (rev 31401)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.cpp	2009-07-03 21:40:19 UTC (rev 31402)
@@ -146,7 +146,8 @@
 	}
 }
 
-const char *pixfmt_to_string(int p)
+const char*
+pixfmt_to_string(int p)
 {
 	switch(p) {
     case PIX_FMT_NONE: return &quot;PIX_FMT_NONE&quot;;
@@ -205,6 +206,69 @@
 	}
 }
 
+
+color_space
+pixfmt_to_colorspace(int p)
+{
+	switch(p) {
+	default:
+    case PIX_FMT_NONE:
+		return B_NO_COLOR_SPACE;
+
+    case PIX_FMT_YUV420P: return B_YUV420;   ///&lt; planar YUV 4:2:0, 12bpp, (1 Cr &amp; Cb sample per 2x2 Y samples)
+    case PIX_FMT_YUYV422: return B_YUV422;   ///&lt; packed YUV 4:2:2, 16bpp, Y0 Cb Y1 Cr
+    case PIX_FMT_RGB24: return B_RGB24_BIG;     ///&lt; packed RGB 8:8:8, 24bpp, RGBRGB...
+    case PIX_FMT_BGR24: return B_RGB24;     ///&lt; packed RGB 8:8:8, 24bpp, BGRBGR...
+    case PIX_FMT_YUV422P: return B_YUV422;   ///&lt; planar YUV 4:2:2, 16bpp, (1 Cr &amp; Cb sample per 2x1 Y samples)
+    case PIX_FMT_YUV444P: return B_YUV444;   ///&lt; planar YUV 4:4:4, 24bpp, (1 Cr &amp; Cb sample per 1x1 Y samples)
+    case PIX_FMT_RGB32: return B_RGBA32_BIG;     ///&lt; packed RGB 8:8:8, 32bpp, (msb)8A 8R 8G 8B(lsb), in CPU endianness
+    case PIX_FMT_YUV410P: return B_YUV9;   ///&lt; planar YUV 4:1:0,  9bpp, (1 Cr &amp; Cb sample per 4x4 Y samples)
+    case PIX_FMT_YUV411P: return B_YUV12;   ///&lt; planar YUV 4:1:1, 12bpp, (1 Cr &amp; Cb sample per 4x1 Y samples)
+    case PIX_FMT_RGB565: return B_RGB16_BIG;    ///&lt; packed RGB 5:6:5, 16bpp, (msb)   5R 6G 5B(lsb), in CPU endianness
+    case PIX_FMT_RGB555: return B_RGB15_BIG;    ///&lt; packed RGB 5:5:5, 16bpp, (msb)1A 5R 5G 5B(lsb), in CPU endianness, most significant bit to 0
+    case PIX_FMT_GRAY8: return B_GRAY8;     ///&lt;        Y        ,  8bpp
+//    case PIX_FMT_MONOWHITE: return B_GRAY1; ///&lt;        Y        ,  1bpp, 0 is white, 1 is black
+    case PIX_FMT_MONOBLACK: return B_GRAY1; ///&lt;        Y        ,  1bpp, 0 is black, 1 is white
+    case PIX_FMT_PAL8: return B_CMAP8;      ///&lt; 8 bit with PIX_FMT_RGB32 palette
+//    case PIX_FMT_YUVJ420P: return &quot;PIX_FMT_YUVJ420P - YUV420P (Jpeg)&quot;;  ///&lt; planar YUV 4:2:0, 12bpp, full scale (JPEG)
+//    case PIX_FMT_YUVJ422P: return &quot;PIX_FMT_YUVJ422P - YUV422P (Jpeg)&quot;;  ///&lt; planar YUV 4:2:2, 16bpp, full scale (JPEG)
+//    case PIX_FMT_YUVJ444P: return &quot;PIX_FMT_YUVJ444P&quot;;  ///&lt; planar YUV 4:4:4, 24bpp, full scale (JPEG)
+//    case PIX_FMT_XVMC_MPEG2_MC: return &quot;PIX_FMT_XVMC_MPEG2_MC&quot;;///&lt; XVideo Motion Acceleration via common packet passing
+//    case PIX_FMT_XVMC_MPEG2_IDCT: return &quot;PIX_FMT_XVMC_MPEG2_IDCT&quot;;
+//    case PIX_FMT_UYVY422: return &quot;PIX_FMT_UYVY422&quot;;   ///&lt; packed YUV 4:2:2, 16bpp, Cb Y0 Cr Y1
+//    case PIX_FMT_UYYVYY411: return &quot;PIX_FMT_UYYVYY411&quot;; ///&lt; packed YUV 4:1:1, 12bpp, Cb Y0 Y1 Cr Y2 Y3
+    case PIX_FMT_BGR32: return B_RGB32;     ///&lt; packed RGB 8:8:8, 32bpp, (msb)8A 8B 8G 8R(lsb), in CPU endianness
+    case PIX_FMT_BGR565: return B_RGB16;    ///&lt; packed RGB 5:6:5, 16bpp, (msb)   5B 6G 5R(lsb), in CPU endianness
+    case PIX_FMT_BGR555: return B_RGB15;    ///&lt; packed RGB 5:5:5, 16bpp, (msb)1A 5B 5G 5R(lsb), in CPU endianness, most significant bit to 1
+//    case PIX_FMT_BGR8: return &quot;PIX_FMT_BGR8&quot;;      ///&lt; packed RGB 3:3:2,  8bpp, (msb)2B 3G 3R(lsb)
+//    case PIX_FMT_BGR4: return &quot;PIX_FMT_BGR4&quot;;      ///&lt; packed RGB 1:2:1,  4bpp, (msb)1B 2G 1R(lsb)
+//    case PIX_FMT_BGR4_BYTE: return &quot;PIX_FMT_BGR4_BYTE&quot;; ///&lt; packed RGB 1:2:1,  8bpp, (msb)1B 2G 1R(lsb)
+//    case PIX_FMT_RGB8: return &quot;PIX_FMT_RGB8&quot;;      ///&lt; packed RGB 3:3:2,  8bpp, (msb)2R 3G 3B(lsb)
+//    case PIX_FMT_RGB4: return &quot;PIX_FMT_RGB4&quot;;      ///&lt; packed RGB 1:2:1,  4bpp, (msb)1R 2G 1B(lsb)
+//    case PIX_FMT_RGB4_BYTE: return &quot;PIX_FMT_RGB4_BYTE&quot;; ///&lt; packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)
+//    case PIX_FMT_NV12: return &quot;PIX_FMT_NV12&quot;;      ///&lt; planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 for UV
+//    case PIX_FMT_NV21: return &quot;PIX_FMT_NV21&quot;;      ///&lt; as above, but U and V bytes are swapped
+//    case PIX_FMT_RGB32_1: return &quot;PIX_FMT_RGB32_1&quot;;   ///&lt; packed RGB 8:8:8, 32bpp, (msb)8R 8G 8B 8A(lsb), in CPU endianness
+//    case PIX_FMT_BGR32_1: return &quot;PIX_FMT_BGR32_1&quot;;   ///&lt; packed RGB 8:8:8, 32bpp, (msb)8B 8G 8R 8A(lsb), in CPU endianness
+//    case PIX_FMT_GRAY16BE: return &quot;PIX_FMT_GRAY16BE&quot;;  ///&lt;        Y        , 16bpp, big-endian
+//    case PIX_FMT_GRAY16LE: return &quot;PIX_FMT_GRAY16LE&quot;;  ///&lt;        Y        , 16bpp, little-endian
+//    case PIX_FMT_YUV440P: return &quot;PIX_FMT_YUV440P&quot;;   ///&lt; planar YUV 4:4:0 (1 Cr &amp; Cb sample per 1x2 Y samples)
+//    case PIX_FMT_YUVJ440P: return &quot;PIX_FMT_YUVJ440P - YUV440P (Jpeg)&quot;;  ///&lt; planar YUV 4:4:0 full scale (JPEG)
+//    case PIX_FMT_YUVA420P: return &quot;PIX_FMT_YUVA420P - YUV420P (Alpha)&quot;;  ///&lt; planar YUV 4:2:0, 20bpp, (1 Cr &amp; Cb sample per 2x2 Y &amp; A samples)
+//    case PIX_FMT_VDPAU_H264: return &quot;PIX_FMT_VDPAU_H264&quot;;///&lt; H.264 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
+//    case PIX_FMT_VDPAU_MPEG1: return &quot;PIX_FMT_VDPAU_MPEG1&quot;;///&lt; MPEG-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
+//    case PIX_FMT_VDPAU_MPEG2: return &quot;PIX_FMT_VDPAU_MPEG2&quot;;///&lt; MPEG-2 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
+//    case PIX_FMT_VDPAU_WMV3: return &quot;PIX_FMT_VDPAU_WMV3&quot;;///&lt; WMV3 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
+//    case PIX_FMT_VDPAU_VC1: return &quot;PIX_FMT_VDPAU_VC1&quot;; ///&lt; VC-1 HW decoding with VDPAU, data[0] contains a vdpau_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
+//    case PIX_FMT_RGB48BE: return &quot;PIX_FMT_RGB48BE&quot;;   ///&lt; packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, big-endian
+//    case PIX_FMT_RGB48LE: return &quot;PIX_FMT_RGB48LE&quot;;   ///&lt; packed RGB 16:16:16, 48bpp, 16R, 16G, 16B, little-endian
+//    case PIX_FMT_VAAPI_MOCO: return &quot;PIX_FMT_VAAPI_MOCO&quot;; ///&lt; HW acceleration through VA API at motion compensation entry-point, Picture.data[0] contains a vaapi_render_state struct which contains macroblocks as well as various fields extracted from headers
+//    case PIX_FMT_VAAPI_IDCT: return &quot;PIX_FMT_VAAPI_IDCT&quot;; ///&lt; HW acceleration through VA API at IDCT entry-point, Picture.data[0] contains a vaapi_render_state struct which contains fields extracted from headers
+//    case PIX_FMT_VAAPI_VLD: return &quot;PIX_FMT_VAAPI_VLD&quot;;  ///&lt; HW decoding through VA API, Picture.data[0] contains a vaapi_render_state struct which contains the bitstream of the slices as well as various fields extracted from headers
+	}
+}
+
+
 #define BEGIN_TAG &quot;\033[31m&quot;
 #define END_TAG &quot;\033[0m&quot;
 

Modified: haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.h
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.h	2009-07-03 21:31:28 UTC (rev 31401)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/gfx_util.h	2009-07-03 21:40:19 UTC (rev 31402)
@@ -36,6 +36,8 @@
 
 const char *pixfmt_to_string(int p);
 
+color_space pixfmt_to_colorspace(int p);
+
 void dump_ffframe(AVFrame *frame, const char *name);
 
 #endif


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="017703.html">[Haiku-commits] r31401 - haiku/trunk/src/bin/network/ftpd
</A></li>
	<LI>Next message: <A HREF="017705.html">[Haiku-commits] r31403 - in haiku/trunk/docs: . userguide/en	userguide/en/applications userguide/en/preferences	userguide/images userguide/images/apps-images	userguide/images/queries-images
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17704">[ date ]</a>
              <a href="thread.html#17704">[ thread ]</a>
              <a href="subject.html#17704">[ subject ]</a>
              <a href="author.html#17704">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
