<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r31421 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2009-July/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r31421%20-%0A%09haiku/trunk/src/add-ons/media/plugins/ffmpeg&In-Reply-To=%3C200907061343.n66Dh56i000193%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="017747.html">
   <LINK REL="Next"  HREF="017801.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r31421 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg</H1>
    <B>stippi at mail.berlios.de</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r31421%20-%0A%09haiku/trunk/src/add-ons/media/plugins/ffmpeg&In-Reply-To=%3C200907061343.n66Dh56i000193%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r31421 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg">stippi at mail.berlios.de
       </A><BR>
    <I>Mon Jul  6 15:43:05 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="017747.html">[Haiku-commits] r31420 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg
</A></li>
        <LI>Next message: <A HREF="017801.html">[Haiku-commits] r31421 - haiku/trunk/src/add-ons/media/plugins/ffmpeg
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17748">[ date ]</a>
              <a href="thread.html#17748">[ thread ]</a>
              <a href="subject.html#17748">[ subject ]</a>
              <a href="author.html#17748">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: stippi
Date: 2009-07-06 15:43:02 +0200 (Mon, 06 Jul 2009)
New Revision: 31421
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=31421&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=31421&amp;view=rev</A>

Added:
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/DemuxerTable.cpp
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/DemuxerTable.h
Modified:
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.h
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/Jamfile
Log:
Get the AVFormatReader into a usable state. DemuxerTable.cpp controls which
container formats we support. I hope I have turned on only those that don't
have an implementation already (did we support ASF already?). I mostly tested
with AVI and that works reasonably well, but I only tested raw audio so far.
However, the backend for Marcus' avi_reader is much nicer than FFmpeg, so I
think it should stay and have disabled the support for AVI in AVFormatReader.
A big disappointment is that MPG containers only give scrambled video. It may
be a problem of the AVCodecDecoder, but I am not so sure. After all, it works
fine for other container formats. If I am not mistaken, VLC also does not use
the mpeg demuxer from FFmpeg. :-\ On top of that, libavformat detects the
time_base and stream duration wrongly for one of my test MPGs.
As for the implementation: Although seeking in libavformat happens for an
individual stream, in reality, the packets for all other streams need to be
flushed (that's also what happens in the libavformat tutorials I've seen).
Since our MediaKit API allows to seek tracks indivually, this is of course
a no-go, since then all other tracks would be out of sync. My solution is to
simply open the demuxer once for each stream and then completely ignore the
packets of the respective other streams. This also works around the problem
that libavformat is unable to provide packets by stream, requiring the
API user to queue the packets that he needs not now, but later for other
streams. It also means we have to no memory copies, since we can directly
use the packet buffer until the next call to GetNextChunk().


Modified: haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp	2009-07-06 13:31:38 UTC (rev 31420)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/AVFormatReader.cpp	2009-07-06 13:43:02 UTC (rev 31421)
@@ -11,13 +11,19 @@
 
 #include &lt;new&gt;
 
+#include &lt;AutoDeleter.h&gt;
+#include &lt;Autolock.h&gt;
 #include &lt;ByteOrder.h&gt;
 #include &lt;DataIO.h&gt;
 #include &lt;MediaDefs.h&gt;
 #include &lt;MediaFormats.h&gt;
 
+extern &quot;C&quot; {
+	#include &quot;avformat.h&quot;
+}
+
+#include &quot;DemuxerTable.h&quot;
 #include &quot;gfx_util.h&quot;
-
 //#include &quot;RawFormats.h&quot;
 
 
@@ -25,9 +31,11 @@
 #ifdef TRACE_AVFORMAT_READER
 #	define TRACE printf
 #	define TRACE_IO(a...)
+#	define TRACE_PACKET(a...)
 #else
 #	define TRACE(a...)
 #	define TRACE_IO(a...)
+#	define TRACE_PACKET(a...)
 #endif
 
 #define ERROR(a...) fprintf(stderr, a)
@@ -38,44 +46,104 @@
 	// the allow to specify a buffering mode.
 
 
-AVFormatReader::AVFormatReader()
+class AVFormatReader::StreamCookie {
+public:
+								StreamCookie(BPositionIO* source,
+									BLocker* streamLock);
+	virtual						~StreamCookie();
+
+	// Init an indivual AVFormatContext
+			status_t			Open();
+
+	// Setup this stream to point to the AVStream at the given streamIndex.
+	// This will also initialize the media_format.
+			status_t			Init(int32 streamIndex);
+
+	inline	const AVFormatContext* Context() const
+									{ return fContext; }
+			int32				Index() const;
+
+	inline	const media_format&amp;	Format() const
+									{ return fFormat; }
+
+			double				FrameRate() const;
+
+	// Support for AVFormatContext
+			status_t			GetStreamInfo(int64* frameCount,
+									bigtime_t* duration, media_format* format,
+									const void** infoBuffer,
+									size_t* infoSize) const;
+
+			status_t			Seek(uint32 flags, int64* frame,
+									bigtime_t* time);
+			status_t			FindKeyFrame(uint32 flags, int64* frame,
+									bigtime_t* time) const;
+
+			status_t			GetNextChunk(const void** chunkBuffer,
+									size_t* chunkSize,
+									media_header* mediaHeader);
+
+private:
+	// I/O hooks for libavformat, cookie will be a StreamCookie instance.
+	// Since multiple StreamCookies use the same BPositionIO source, they
+	// maintain the position individually, and may need to seek the source
+	// if it does not match anymore in _Read().
+	static	int					_Read(void* cookie, uint8* buffer,
+									int bufferSize);
+	static	off_t				_Seek(void* cookie, off_t offset, int whence);
+
+
+			status_t			_NextPacket(bool reuse);
+private:
+			BPositionIO*		fSource;
+			off_t				fPosition;
+			// Since different threads may read from the source,
+			// we need to protect the file position and I/O by a lock.
+			BLocker*			fStreamLock;
+
+			AVFormatContext*	fContext;
+			AVStream*			fStream;
+
+			ByteIOContext		fIOContext;
+			uint8				fIOBuffer[kIOBufferSize];
+
+			AVPacket			fPacket;
+			bool				fReusePacket;
+
+			media_format		fFormat;
+};
+
+
+
+AVFormatReader::StreamCookie::StreamCookie(BPositionIO* source,
+		BLocker* streamLock)
 	:
+	fSource(source),
+	fPosition(0),
+	fStreamLock(streamLock),
+
 	fContext(NULL),
-	fIOBuffer(NULL)
+	fStream(NULL),
+
+	fReusePacket(false)
 {
-	TRACE(&quot;AVFormatReader::AVFormatReader\n&quot;);
-	memset(&amp;fFormatParameters, 0, sizeof(fFormatParameters));
+	memset(&amp;fIOBuffer, 0, sizeof(fIOBuffer));
+	memset(&amp;fFormat, 0, sizeof(media_format));
+	av_new_packet(&amp;fPacket, 0);
 }
 
 
-AVFormatReader::~AVFormatReader()
+AVFormatReader::StreamCookie::~StreamCookie()
 {
-	TRACE(&quot;AVFormatReader::~AVFormatReader\n&quot;);
-
+	av_free_packet(&amp;fPacket);
 	av_free(fContext);
-	free(fIOBuffer);
 }
 
 
-// #pragma mark -
-
-
-const char*
-AVFormatReader::Copyright()
-{
-	// TODO: Return copyright of the file instead!
-	return &quot;Copyright 2009, Stephan A&#223;mus&quot;;
-}
-
-	
 status_t
-AVFormatReader::Sniff(int32* streamCount)
+AVFormatReader::StreamCookie::Open()
 {
-	TRACE(&quot;AVFormatReader::Sniff\n&quot;);
-
-	free(fIOBuffer);
-	fIOBuffer = (uint8*)malloc(kIOBufferSize);
-
+	// Init probing data
 	size_t probeSize = 1024;
 	AVProbeData probeData;
 	probeData.filename = &quot;&quot;;
@@ -83,334 +151,926 @@
 	probeData.buf_size = probeSize;
 
 	// Read a bit of the input...
-	if (_ReadPacket(Source(), fIOBuffer, probeSize) != (ssize_t)probeSize)
+	// NOTE: Even if other streams have already read from the source,
+	// it is ok to not seek first, since our fPosition is 0, so the necessary
+	// seek will happen automatically in _Read().
+	if (_Read(this, fIOBuffer, probeSize) != (ssize_t)probeSize)
 		return B_IO_ERROR;
-	// ...and seek back to the beginning of the file.
-	_Seek(Source(), 0, SEEK_SET);
+	// ...and seek back to the beginning of the file. This is important
+	// since libavformat will assume the stream to be at offset 0, the
+	// probe data is not reused.
+	_Seek(this, 0, SEEK_SET);
 
 	// Probe the input format
 	AVInputFormat* inputFormat = av_probe_input_format(&amp;probeData, 1);
 
 	if (inputFormat == NULL) {
-		TRACE(&quot;AVFormatReader::Sniff() - av_probe_input_format() failed!\n&quot;);
-		return B_ERROR;
+		TRACE(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+			&quot;av_probe_input_format() failed!\n&quot;);
+		return B_NOT_SUPPORTED;
 	}
 
-	TRACE(&quot;AVFormatReader::Sniff() - av_probe_input_format(): %s\n&quot;,
-		inputFormat-&gt;name);
+	TRACE(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+		&quot;av_probe_input_format(): %s\n&quot;, inputFormat-&gt;name);
 
-	// Init I/O context with buffer and hook functions
-	if (init_put_byte(&amp;fIOContext, fIOBuffer, kIOBufferSize, 0, Source(),
-		_ReadPacket, 0, _Seek) != 0) {
-		TRACE(&quot;AVFormatReader::Sniff() - init_put_byte() failed!\n&quot;);
+	const DemuxerFormat* demuxerFormat = demuxer_format_for(inputFormat);
+	if (demuxerFormat == NULL) {
+		// We could support this format, but we don't want to. Bail out.
+		ERROR(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+			&quot;support for demuxer '%s' is not enabled. &quot;
+			&quot;See DemuxerTable.cpp\n&quot;, inputFormat-&gt;name);
+		return B_NOT_SUPPORTED;
+	}
+
+	// Init I/O context with buffer and hook functions, pass ourself as
+	// cookie.
+	if (init_put_byte(&amp;fIOContext, fIOBuffer, kIOBufferSize, 0, this,
+			_Read, 0, _Seek) != 0) {
+		TRACE(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+			&quot;init_put_byte() failed!\n&quot;);
 		return B_ERROR;
 	}
 
+	// Initialize our context.
 	if (av_open_input_stream(&amp;fContext, &amp;fIOContext, &quot;&quot;, inputFormat,
-		&amp;fFormatParameters) &lt; 0) {
-		TRACE(&quot;AVFormatReader::Sniff() - av_open_input_stream() failed!\n&quot;);
-		return B_ERROR;
+			NULL) &lt; 0) {
+		TRACE(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+			&quot;av_open_input_stream() failed!\n&quot;);
+		return B_NOT_SUPPORTED;
 	}
 
 	// Retrieve stream information
 	if (av_find_stream_info(fContext) &lt; 0) {
-		TRACE(&quot;AVFormatReader::Sniff() - av_find_stream_info() failed!\n&quot;);
-		return B_ERROR;
+		TRACE(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+			&quot;av_find_stream_info() failed!\n&quot;);
+		return B_NOT_SUPPORTED;
 	}
 
-	TRACE(&quot;AVFormatReader::Sniff() - av_find_stream_info() success!\n&quot;);
+	TRACE(&quot;AVFormatReader::StreamCookie::Init() - &quot;
+		&quot;av_find_stream_info() success!\n&quot;);
 
-	// Dump information about stream onto standard error
-	dump_format(fContext, 0, &quot;&quot;, 0);
-
-	if (streamCount != NULL)
-		*streamCount = fContext-&gt;nb_streams;
-
-//	return B_OK;
-return B_ERROR; // For now...
+	return B_OK;
 }
 
 
-void
-AVFormatReader::GetFileFormatInfo(media_file_format* mff)
+status_t
+AVFormatReader::StreamCookie::Init(int32 streamIndex)
 {
-	TRACE(&quot;AVFormatReader::GetFileFormatInfo\n&quot;);
+	TRACE(&quot;AVFormatReader::StreamCookie::Init(%ld)\n&quot;, streamIndex);
 
-	if (fContext == NULL || fContext-&gt;iformat == NULL) {
-		TRACE(&quot;  no context or AVInputFormat!\n&quot;);
-		return;
+	if (fContext == NULL)
+		return B_NO_INIT;
+
+	if (streamIndex &lt; 0 || streamIndex &gt;= (int32)fContext-&gt;nb_streams)
+		return B_BAD_INDEX;
+
+	const DemuxerFormat* demuxerFormat = demuxer_format_for(fContext-&gt;iformat);
+	if (demuxerFormat == NULL) {
+		TRACE(&quot;  unknown AVInputFormat!\n&quot;);
+		return B_NOT_SUPPORTED;
 	}
 
-	mff-&gt;capabilities = media_file_format::B_READABLE
-		| media_file_format::B_KNOWS_ENCODED_VIDEO
-		| media_file_format::B_KNOWS_ENCODED_AUDIO
-		| media_file_format::B_IMPERFECTLY_SEEKABLE;
-	mff-&gt;family = B_MISC_FORMAT_FAMILY;
-	mff-&gt;version = 100;
-	strcpy(mff-&gt;mime_type, &quot;&quot;);
-		// TODO: Would be nice to be able to provide this, maybe by extending
-		// the FFmpeg code itself (all demuxers, see AVInputFormat struct).
+	// Make us point to the AVStream at streamIndex
+	fStream = fContext-&gt;streams[streamIndex];
 
-	if (fContext-&gt;iformat-&gt;extensions != NULL)
-		strcpy(mff-&gt;file_extension, fContext-&gt;iformat-&gt;extensions);
-	else {
-		TRACE(&quot;  no file extensions for AVInputFormat.\n&quot;);
-		strcpy(mff-&gt;file_extension, &quot;&quot;);
+	// Get a pointer to the AVCodecContext for the stream at streamIndex.
+	AVCodecContext* codecContext = fStream-&gt;codec;
+	AVStream* stream = fStream;
+
+	// initialize the media_format for this stream
+	media_format* format = &fFormat;
+	memset(format, 0, sizeof(media_format));
+
+	media_format_description description;
+
+	// Set format family and type depending on codec_type of the stream.
+	switch (codecContext-&gt;codec_type) {
+		case CODEC_TYPE_AUDIO:
+			if ((codecContext-&gt;codec_id &gt;= CODEC_ID_PCM_S16LE)
+				&amp;&amp; (codecContext-&gt;codec_id &lt;= CODEC_ID_PCM_U8)) {
+				TRACE(&quot;  raw audio\n&quot;);
+				format-&gt;type = B_MEDIA_RAW_AUDIO;
+				description.family = B_ANY_FORMAT_FAMILY;
+			} else {
+				TRACE(&quot;  encoded audio\n&quot;);
+				format-&gt;type = B_MEDIA_ENCODED_AUDIO;
+				description.family = demuxerFormat-&gt;audio_family;
+			}
+			break;
+		case CODEC_TYPE_VIDEO:
+			TRACE(&quot;  encoded video\n&quot;);
+			format-&gt;type = B_MEDIA_ENCODED_VIDEO;
+			description.family = demuxerFormat-&gt;video_family;
+			break;
+		default:
+			TRACE(&quot;  unknown type\n&quot;);
+			format-&gt;type = B_MEDIA_UNKNOWN_TYPE;
+			break;
 	}
 
-	if (fContext-&gt;iformat-&gt;name != NULL)
-		strcpy(mff-&gt;short_name,  fContext-&gt;iformat-&gt;name);
-	else {
-		TRACE(&quot;  no short name for AVInputFormat.\n&quot;);
-		strcpy(mff-&gt;short_name,  &quot;&quot;);
+	if (format-&gt;type == B_MEDIA_RAW_AUDIO) {
+		switch (codecContext-&gt;codec_id) {
+			case CODEC_ID_PCM_S16LE:
+				format-&gt;u.raw_audio.format
+					= media_raw_audio_format::B_AUDIO_SHORT;
+				format-&gt;u.raw_audio.byte_order
+					= B_MEDIA_LITTLE_ENDIAN;
+				break;
+			case CODEC_ID_PCM_S16BE:
+				format-&gt;u.raw_audio.format
+					= media_raw_audio_format::B_AUDIO_SHORT;
+				format-&gt;u.raw_audio.byte_order
+					= B_MEDIA_BIG_ENDIAN;
+				break;
+			case CODEC_ID_PCM_U16LE:
+//				format-&gt;u.raw_audio.format
+//					= media_raw_audio_format::B_AUDIO_USHORT;
+//				format-&gt;u.raw_audio.byte_order
+//					= B_MEDIA_LITTLE_ENDIAN;
+				return B_NOT_SUPPORTED;
+				break;
+			case CODEC_ID_PCM_U16BE:
+//				format-&gt;u.raw_audio.format
+//					= media_raw_audio_format::B_AUDIO_USHORT;
+//				format-&gt;u.raw_audio.byte_order
+//					= B_MEDIA_BIG_ENDIAN;
+				return B_NOT_SUPPORTED;
+				break;
+			case CODEC_ID_PCM_S8:
+				format-&gt;u.raw_audio.format
+					= media_raw_audio_format::B_AUDIO_CHAR;
+				break;
+			case CODEC_ID_PCM_U8:
+				format-&gt;u.raw_audio.format
+					= media_raw_audio_format::B_AUDIO_UCHAR;
+				break;
+			default:
+				return B_NOT_SUPPORTED;
+				break;
+		}
+	} else {
+		switch (description.family) {
+			case B_AIFF_FORMAT_FAMILY:
+				TRACE(&quot;  B_AIFF_FORMAT_FAMILY\n&quot;);
+				description.u.aiff.codec = codecContext-&gt;codec_tag;
+				break;
+			case B_ASF_FORMAT_FAMILY:
+				TRACE(&quot;  B_ASF_FORMAT_FAMILY\n&quot;);
+//				description.u.asf.guid = GUID(codecContext-&gt;codec_tag);
+				return B_NOT_SUPPORTED;
+				break;
+			case B_AVI_FORMAT_FAMILY:
+				TRACE(&quot;  B_AVI_FORMAT_FAMILY\n&quot;);
+				description.u.avi.codec = codecContext-&gt;codec_tag;
+				break;
+			case B_AVR_FORMAT_FAMILY:
+				TRACE(&quot;  B_AVR_FORMAT_FAMILY\n&quot;);
+				description.u.avr.id = codecContext-&gt;codec_tag;
+				break;
+			case B_MPEG_FORMAT_FAMILY:
+				TRACE(&quot;  B_MPEG_FORMAT_FAMILY\n&quot;);
+				if (codecContext-&gt;codec_id == CODEC_ID_MPEG1VIDEO)
+					description.u.mpeg.id = B_MPEG_1_VIDEO;
+				else if (codecContext-&gt;codec_id == CODEC_ID_MPEG2VIDEO)
+					description.u.mpeg.id = B_MPEG_2_VIDEO;
+				else if (codecContext-&gt;codec_id == CODEC_ID_MP2)
+					description.u.mpeg.id = B_MPEG_2_AUDIO_LAYER_2;
+				else if (codecContext-&gt;codec_id == CODEC_ID_MP3)
+					description.u.mpeg.id = B_MPEG_1_AUDIO_LAYER_3;
+				// TODO: Add some more...
+				else
+					description.u.mpeg.id = B_MPEG_ANY;
+				break;
+			case B_QUICKTIME_FORMAT_FAMILY:
+				TRACE(&quot;  B_QUICKTIME_FORMAT_FAMILY\n&quot;);
+				description.u.quicktime.codec
+					= B_HOST_TO_BENDIAN_INT32(codecContext-&gt;codec_tag);
+				break;
+			case B_WAV_FORMAT_FAMILY:
+				TRACE(&quot;  B_WAV_FORMAT_FAMILY\n&quot;);
+				description.u.wav.codec = codecContext-&gt;codec_tag;
+				break;
+			case B_MISC_FORMAT_FAMILY:
+				TRACE(&quot;  B_MISC_FORMAT_FAMILY\n&quot;);
+				description.u.misc.codec = codecContext-&gt;codec_tag;
+				break;
+
+			default:
+				break;
+		}
+		TRACE(&quot;  fourcc '%.4s'\n&quot;, (char*)&amp;codecContext-&gt;codec_tag);
+
+		BMediaFormats formats;
+		status_t status = formats.GetFormatFor(description, format);
+		if (status &lt; B_OK)
+			TRACE(&quot;  formats.GetFormatFor() error: %s\n&quot;, strerror(status));
+
+		format-&gt;user_data_type = B_CODEC_TYPE_INFO;
+		*(uint32*)format-&gt;user_data = codecContext-&gt;codec_tag;
+		format-&gt;user_data[4] = 0;
 	}
 
-	if (fContext-&gt;iformat-&gt;long_name != NULL)
-		strcpy(mff-&gt;pretty_name, fContext-&gt;iformat-&gt;long_name);
-	else {
-		TRACE(&quot;  no long name for AVInputFormat.\n&quot;);
-		strcpy(mff-&gt;pretty_name, &quot;&quot;);
+//	format-&gt;require_flags = 0;
+	format-&gt;deny_flags = B_MEDIA_MAUI_UNDEFINED_FLAGS;
+
+	switch (format-&gt;type) {
+		case B_MEDIA_RAW_AUDIO:
+			format-&gt;u.raw_audio.frame_rate = (float)codecContext-&gt;sample_rate;
+			format-&gt;u.raw_audio.channel_count = codecContext-&gt;channels;
+			format-&gt;u.raw_audio.buffer_size = 0;
+
+			// Read one packet and mark it for later re-use. (So our first
+			// GetNextChunk() call does not read another packet.)
+			if ( _NextPacket(true) == B_OK) {
+				TRACE(&quot;  successfully determined audio buffer size: %d\n&quot;,
+					fPacket.size);
+				format-&gt;u.raw_audio.buffer_size = fPacket.size;
+			}
+			break;
+
+		case B_MEDIA_ENCODED_AUDIO:
+			format-&gt;u.encoded_audio.bit_rate = codecContext-&gt;bit_rate;
+			format-&gt;u.encoded_audio.frame_size = codecContext-&gt;frame_size;
+			// Fill in some info about possible output format
+			format-&gt;u.encoded_audio.output
+				= media_multi_audio_format::wildcard;
+			format-&gt;u.encoded_audio.output.frame_rate
+				= (float)codecContext-&gt;sample_rate;
+			format-&gt;u.encoded_audio.output.channel_count
+				= codecContext-&gt;channels;
+			break;
+
+		case B_MEDIA_ENCODED_VIDEO:
+// TODO: Specifying any of these seems to throw off the format matching
+// later on.
+//			format-&gt;u.encoded_video.avg_bit_rate = codecContext-&gt;bit_rate; 
+//			format-&gt;u.encoded_video.max_bit_rate = codecContext-&gt;bit_rate
+//				+ codecContext-&gt;bit_rate_tolerance;
+	
+//			format-&gt;u.encoded_video.encoding
+//				= media_encoded_video_format::B_ANY;
+	
+//			format-&gt;u.encoded_video.frame_size = 1;
+//			format-&gt;u.encoded_video.forward_history = 0;
+//			format-&gt;u.encoded_video.backward_history = 0;
+	
+			format-&gt;u.encoded_video.output.field_rate
+				= av_q2d(stream-&gt;r_frame_rate);
+			format-&gt;u.encoded_video.output.interlace = 1;
+				// TODO: Fix up for interlaced video
+			format-&gt;u.encoded_video.output.first_active = 0;
+			format-&gt;u.encoded_video.output.last_active
+				= codecContext-&gt;height - 1;
+				// TODO: Maybe libavformat actually provides that info
+				// somewhere...
+			format-&gt;u.encoded_video.output.orientation
+				= B_VIDEO_TOP_LEFT_RIGHT;
+	
+			// TODO: Implement aspect ratio for real
+			format-&gt;u.encoded_video.output.pixel_width_aspect
+				= 1;//stream-&gt;sample_aspect_ratio.num;
+			format-&gt;u.encoded_video.output.pixel_height_aspect
+				= 1;//stream-&gt;sample_aspect_ratio.den;
+	
+			TRACE(&quot;  pixel width/height aspect: %d/%d or %.4f\n&quot;,
+				stream-&gt;sample_aspect_ratio.num,
+				stream-&gt;sample_aspect_ratio.den,
+				av_q2d(stream-&gt;sample_aspect_ratio));
+
+			format-&gt;u.encoded_video.output.display.format
+				= pixfmt_to_colorspace(codecContext-&gt;pix_fmt);
+			format-&gt;u.encoded_video.output.display.line_width
+				= codecContext-&gt;width;
+			format-&gt;u.encoded_video.output.display.line_count
+				= codecContext-&gt;height;
+			format-&gt;u.encoded_video.output.display.bytes_per_row = 0;
+			format-&gt;u.encoded_video.output.display.pixel_offset = 0;
+			format-&gt;u.encoded_video.output.display.line_offset = 0;
+			format-&gt;u.encoded_video.output.display.flags = 0; // TODO
+
+			break;
+
+		default:
+			// This is an unknown format to us.
+			break;
 	}
+
+	// Add the meta data, if any
+	if (codecContext-&gt;extradata_size &gt; 0) {
+		format-&gt;SetMetaData(codecContext-&gt;extradata,
+			codecContext-&gt;extradata_size);
+	}
+
+#ifdef TRACE_AVFORMAT_READER
+	char formatString[512];
+	if (string_for_format(*format, formatString, sizeof(formatString)))
+		TRACE(&quot;  format: %s\n&quot;, formatString);
+
+	uint32 encoding = format-&gt;Encoding();
+	TRACE(&quot;  encoding '%.4s'\n&quot;, (char*)&amp;encoding);
+#endif
+
+	return B_OK;
 }
 
 
-// #pragma mark -
+int32
+AVFormatReader::StreamCookie::Index() const
+{
+	if (fStream != NULL)
+		return fStream-&gt;index;
+	return -1;
+}
 
 
+double
+AVFormatReader::StreamCookie::FrameRate() const
+{
+	switch (fStream-&gt;codec-&gt;codec_type) {
+		case CODEC_TYPE_AUDIO:
+			return (double)fStream-&gt;codec-&gt;sample_rate;
+		case CODEC_TYPE_VIDEO:
+			return av_q2d(fStream-&gt;r_frame_rate);
+		default:
+			return 0.0;
+	}
+}
+
+
 status_t
-AVFormatReader::AllocateCookie(int32 streamIndex, void** _cookie)
+AVFormatReader::StreamCookie::GetStreamInfo(int64* frameCount,
+	bigtime_t* duration, media_format* format, const void** infoBuffer,
+	size_t* infoSize) const
 {
-	TRACE(&quot;AVFormatReader::AllocateCookie(%ld)\n&quot;, streamIndex);
+	TRACE(&quot;AVFormatReader::StreamCookie::GetStreamInfo()\n&quot;);
 
-	if (fContext == NULL)
+	double frameRate = FrameRate();
+	TRACE(&quot;  frameRate: %.4f\n&quot;, frameRate);
+
+	// TODO: This is obviously not working correctly for all stream types...
+	// It seems that the calculations here are correct, because they work
+	// for a couple of streams and are in line with the documentation, but
+	// unfortunately, libavformat itself seems to set the time_base and
+	// duration wrongly sometimes. :-(
+	TRACE(&quot;  stream duration: %lld, time_base %.4f (%d/%d)\n&quot;,
+		fStream-&gt;duration,
+		av_q2d(fStream-&gt;time_base),
+		fStream-&gt;time_base.num, fStream-&gt;time_base.den);
+	*duration = (bigtime_t)(1000000LL * fStream-&gt;duration
+		* av_q2d(fStream-&gt;time_base));
+
+	TRACE(&quot;  duration: %lld or %.2fs\n&quot;, *duration, *duration / 1000000.0);
+
+	*frameCount = fStream-&gt;nb_frames;
+	if (*frameCount == 0) {
+		// Calculate from duration and frame rate
+		*frameCount = (int64)(*duration * frameRate / 1000000LL);
+		TRACE(&quot;  frameCount (calculated): %lld\n&quot;, *frameCount);
+	} else
+		TRACE(&quot;  frameCount: %lld\n&quot;, *frameCount);
+
+	*format = fFormat;
+
+	// TODO: Possibly use fStream-&gt;metadata for this?
+	*infoBuffer = 0;
+	*infoSize = 0;
+
+	return B_OK;
+}
+
+
+status_t
+AVFormatReader::StreamCookie::Seek(uint32 flags, int64* frame,
+	bigtime_t* time)
+{
+	if (fContext == NULL || fStream == NULL)
 		return B_NO_INIT;
 
-	if (streamIndex &lt; 0 || streamIndex &gt;= (int32)fContext-&gt;nb_streams)
-		return B_BAD_INDEX;
+	if ((flags &amp; B_MEDIA_SEEK_CLOSEST_FORWARD) != 0) {
+		TRACE(&quot;  AVFormatReader::Seek() - B_MEDIA_SEEK_CLOSEST_FORWARD &quot;
+			&quot;not supported.\n&quot;);
+		return B_NOT_SUPPORTED;
+	}
 
-	if (_cookie == NULL)
-		return B_BAD_VALUE;
+	TRACE(&quot;AVFormatReader::StreamCookie::Seek(%ld, %s %s %s %s, %lld, &quot;
+		&quot;%lld)\n&quot;, Index(),
+		(flags &amp; B_MEDIA_SEEK_TO_FRAME) ? &quot;B_MEDIA_SEEK_TO_FRAME&quot; : &quot;&quot;,
+		(flags &amp; B_MEDIA_SEEK_TO_TIME) ? &quot;B_MEDIA_SEEK_TO_TIME&quot; : &quot;&quot;,
+		(flags &amp; B_MEDIA_SEEK_CLOSEST_BACKWARD) ? &quot;B_MEDIA_SEEK_CLOSEST_BACKWARD&quot; : &quot;&quot;,
+		(flags &amp; B_MEDIA_SEEK_CLOSEST_FORWARD) ? &quot;B_MEDIA_SEEK_CLOSEST_FORWARD&quot; : &quot;&quot;,
+		*frame, *time);
 
-	StreamCookie* cookie = new(std::nothrow) StreamCookie;
-	if (cookie == NULL)
-		return B_NO_MEMORY;
+	if ((flags &amp; B_MEDIA_SEEK_TO_FRAME) != 0)
+		*time = *frame * 1000000LL / FrameRate();
 
-	// Get a pointer to the codec context for the stream at sreamIndex.
-	AVCodecContext* codecContext = fContext-&gt;streams[streamIndex]-&gt;codec;
-	AVCodec* codec = avcodec_find_decoder(codecContext-&gt;codec_id);
-	if (codec == NULL || avcodec_open(codecContext, codec) &lt; 0) {
-		delete cookie;
+	double timeBase = av_q2d(fStream-&gt;time_base);
+	int64_t timeStamp;
+	if ((flags &amp; B_MEDIA_SEEK_TO_FRAME) != 0) {
+		// Can use frame, because stream timeStamp is actually in frame
+		// units.
+		timeStamp = *frame;
+	} else
+		timeStamp = (int64_t)(*time / timeBase / 1000000.0);
+
+	TRACE(&quot;  time: %.2fs -&gt; %lld, current DTS: %lld (time_base: %f)\n&quot;,
+		*time / 1000000.0, timeStamp, fStream-&gt;cur_dts, timeBase);
+
+	if (av_seek_frame(fContext, Index(), timeStamp, 0) &lt; 0) {
+		TRACE(&quot;  av_seek_frame() failed.\n&quot;);
 		return B_ERROR;
 	}
 
-//    codecContext-&gt;get_buffer = _GetBuffer;
-//    codecContext-&gt;release_buffer = _ReleaseBuffer;
+	// Our last packet is toast in any case.
+	av_free_packet(&amp;fPacket);
+	fReusePacket = false;
 
-	AVStream* stream = fContext-&gt;streams[streamIndex];
+	return B_OK;	
+}
 
-	cookie-&gt;stream = stream;
-	cookie-&gt;codecContext = codecContext;
-	cookie-&gt;codec = codec;
 
-	media_format* format = &amp;cookie-&gt;format;
-	memset(format, 0, sizeof(media_format));
+status_t
+AVFormatReader::StreamCookie::FindKeyFrame(uint32 flags, int64* frame,
+	bigtime_t* time) const
+{
+	if (fContext == NULL || fStream == NULL)
+		return B_NO_INIT;
 
-	BMediaFormats formats;
-	media_format_description description;
+	TRACE(&quot;AVFormatReader::StreamCookie::FindKeyFrame(%ld, %s %s %s %s, %lld, &quot;
+		&quot;%lld)\n&quot;, Index(),
+		(flags &amp; B_MEDIA_SEEK_TO_FRAME) ? &quot;B_MEDIA_SEEK_TO_FRAME&quot; : &quot;&quot;,
+		(flags &amp; B_MEDIA_SEEK_TO_TIME) ? &quot;B_MEDIA_SEEK_TO_TIME&quot; : &quot;&quot;,
+		(flags &amp; B_MEDIA_SEEK_CLOSEST_BACKWARD) ? &quot;B_MEDIA_SEEK_CLOSEST_BACKWARD&quot; : &quot;&quot;,
+		(flags &amp; B_MEDIA_SEEK_CLOSEST_FORWARD) ? &quot;B_MEDIA_SEEK_CLOSEST_FORWARD&quot; : &quot;&quot;,
+		*frame, *time);
 
-	if (stream-&gt;codec-&gt;codec_type == CODEC_TYPE_VIDEO) {
-		// TODO: Fix this up! Maybe do this for AVI demuxer and MOV
-		// demuxer and use B_MISC_FORMAT_FAMILY for all the others?
-		description.family = B_AVI_FORMAT_FAMILY;
-		description.u.avi.codec = codecContext-&gt;codec_tag;
-		TRACE(&quot;  fourcc '%.4s'\n&quot;, (char*)&amp;codecContext-&gt;codec_tag);
+	double frameRate = FrameRate();
+	if ((flags &amp; B_MEDIA_SEEK_TO_FRAME) != 0)
+		*time = *frame * 1000000LL / frameRate;
 
-		if (formats.GetFormatFor(description, format) &lt; B_OK)
-			format-&gt;type = B_MEDIA_ENCODED_VIDEO;
+	double timeBase = av_q2d(fStream-&gt;time_base);
+	int64_t timeStamp;
+	if ((flags &amp; B_MEDIA_SEEK_TO_FRAME) != 0) {
+		// Can use frame, because stream timeStamp is actually in frame
+		// units.
+		timeStamp = *frame;
+	} else
+		timeStamp = (int64_t)(*time / timeBase / 1000000.0);
 
-//		format-&gt;require_flags = 
-//		format-&gt;deny_flags = 
+	TRACE(&quot;  time: %.2fs -&gt; %lld (time_base: %f)\n&quot;, *time / 1000000.0,
+		timeStamp, timeBase);
 
-		format-&gt;user_data_type = B_CODEC_TYPE_INFO;
-		*(uint32*)format-&gt;user_data = codecContext-&gt;codec_tag;
-		format-&gt;user_data[4] = 0;
+	int searchFlags = AVSEEK_FLAG_BACKWARD;
+	if ((flags &amp; B_MEDIA_SEEK_CLOSEST_FORWARD) != 0)
+		searchFlags = 0;
 
-		// TODO: We don't actually know the bitrate for this stream,
-		// only the total bitrate!
-		format-&gt;u.encoded_video.avg_bit_rate = codecContext-&gt;bit_rate; 
-		format-&gt;u.encoded_video.max_bit_rate = codecContext-&gt;bit_rate
-			+ codecContext-&gt;bit_rate_tolerance;
+	int index = av_index_search_timestamp(fStream, timeStamp, searchFlags);
+	if (index &lt; 0) {
+		TRACE(&quot;  av_index_search_timestamp() failed.\n&quot;);
+		// Just seek to the beginning of the stream and assume it is a
+		// keyframe...
+		*frame = 0;
+		*time = 0;
+		return B_OK;
+	}
 
-		format-&gt;u.encoded_video.encoding = media_encoded_video_format::B_ANY;
+	const AVIndexEntry&amp; entry = fStream-&gt;index_entries[index];
+	timeStamp = entry.timestamp;
+	*time = (bigtime_t)(timeStamp * 1000000.0 * timeBase);
 
-		format-&gt;u.encoded_video.frame_size = 1;
-//		format-&gt;u.encoded_video.forward_history = 0;
-//		format-&gt;u.encoded_video.backward_history = 0;
+	TRACE(&quot;  seeked time: %.2fs (%lld)\n&quot;, *time / 1000000.0, timeStamp);
+	if ((flags &amp; B_MEDIA_SEEK_TO_FRAME) != 0) {
+		*frame = timeStamp;//*time * frameRate / 1000000LL;
+		TRACE(&quot;  seeked frame: %lld\n&quot;, *frame);
+	}
 
-		format-&gt;u.encoded_video.output.field_rate
-			= av_q2d(stream-&gt;r_frame_rate);
-		format-&gt;u.encoded_video.output.interlace = 1;
-			// TODO: Fix up for interlaced video
-		format-&gt;u.encoded_video.output.first_active = 0;
-		format-&gt;u.encoded_video.output.last_active = 0;
-			// TODO: Maybe libavformat actually provides that info somewhere...
-		format-&gt;u.encoded_video.output.orientation = B_VIDEO_TOP_LEFT_RIGHT;
+	return B_OK;
+}
 
-		// TODO: Implement aspect ratio for real
-		format-&gt;u.encoded_video.output.pixel_width_aspect
-			= 1;//stream-&gt;sample_aspect_ratio.num;
-		format-&gt;u.encoded_video.output.pixel_height_aspect
-			= 1;//stream-&gt;sample_aspect_ratio.den;
 
-		TRACE(&quot;  pixel width/height aspect: %d/%d or %.4f\n&quot;,
-			stream-&gt;sample_aspect_ratio.num,
-			stream-&gt;sample_aspect_ratio.den,
-			av_q2d(stream-&gt;sample_aspect_ratio));
+status_t
+AVFormatReader::StreamCookie::GetNextChunk(const void** chunkBuffer,
+	size_t* chunkSize, media_header* mediaHeader)
+{
+	TRACE_PACKET(&quot;AVFormatReader::StreamCookie::GetNextChunk()\n&quot;);
 
-		format-&gt;u.encoded_video.output.display.format
-			= pixfmt_to_colorspace(codecContext-&gt;pix_fmt);
-		format-&gt;u.encoded_video.output.display.line_width = codecContext-&gt;width;
-		format-&gt;u.encoded_video.output.display.line_count = codecContext-&gt;height;
-		format-&gt;u.encoded_video.output.display.bytes_per_row = 0;
-		format-&gt;u.encoded_video.output.display.pixel_offset = 0;
-		format-&gt;u.encoded_video.output.display.line_offset = 0;
-		format-&gt;u.encoded_video.output.display.flags = 0; // TODO
+	status_t ret = _NextPacket(false);
+	if (ret != B_OK)
+		return ret;
 
-		uint32 encoding = format-&gt;Encoding();
-		TRACE(&quot;  encoding '%.4s'\n&quot;, (char*)&amp;encoding);
+	// According to libavformat documentation, fPacket is valid until the
+	// next call to av_read_frame(). This is what we want and we can share
+	// the memory with the least overhead.
+	*chunkBuffer = fPacket.data;
+	*chunkSize = fPacket.size;
 
-	} else if (stream-&gt;codec-&gt;codec_type == CODEC_TYPE_AUDIO) {
-		format-&gt;type = B_MEDIA_ENCODED_AUDIO;
-//		format-&gt;require_flags = 
-//		format-&gt;deny_flags = 
+	if (mediaHeader != NULL) {
+		mediaHeader-&gt;type = fFormat.type;
+		mediaHeader-&gt;buffer = 0;
+		mediaHeader-&gt;destination = -1;
+		mediaHeader-&gt;time_source = -1;
+		mediaHeader-&gt;size_used = fPacket.size;
+		mediaHeader-&gt;start_time = (bigtime_t)(1000000.0 * fPacket.pts
+			/ av_q2d(fStream-&gt;time_base));
+		mediaHeader-&gt;file_pos = fPacket.pos;
+		mediaHeader-&gt;data_offset = 0;
+		switch (mediaHeader-&gt;type) {
+			case B_MEDIA_RAW_AUDIO:
+				break;
+			case B_MEDIA_ENCODED_AUDIO:
+				mediaHeader-&gt;u.encoded_audio.buffer_flags
+					= (fPacket.flags &amp; PKT_FLAG_KEY) ? B_MEDIA_KEY_FRAME : 0;
+				break;
+			case B_MEDIA_RAW_VIDEO:
+				mediaHeader-&gt;u.raw_video.line_count
+					= fFormat.u.raw_video.display.line_count;
+				break;
+			case B_MEDIA_ENCODED_VIDEO:
+				mediaHeader-&gt;u.encoded_video.field_flags
+					= (fPacket.flags &amp; PKT_FLAG_KEY) ? B_MEDIA_KEY_FRAME : 0;
+				mediaHeader-&gt;u.encoded_video.line_count
+					= fFormat.u.encoded_video.output.display.line_count;
+				break;
+			default:
+				break;
+		}
+	}
 
-//		format-&gt;u.encoded_audio.
-	} else {
-		return B_NOT_SUPPORTED;
+	return B_OK;
+}
+
+
+// #pragma mark -
+
+
+/*static*/ int
+AVFormatReader::StreamCookie::_Read(void* cookie, uint8* buffer,
+	int bufferSize)
+{
+	TRACE_IO(&quot;AVFormatReader::StreamCookie::_Read(%p, %p, %d)\n&quot;,
+		cookie, buffer, whence);
+
+	StreamCookie* stream = reinterpret_cast&lt;StreamCookie*&gt;(cookie);
+
+	BAutolock _(stream-&gt;fStreamLock);
+
+	if (stream-&gt;fPosition != stream-&gt;fSource-&gt;Position()) {
+		off_t position
+			= stream-&gt;fSource-&gt;Seek(stream-&gt;fPosition, SEEK_SET);
+		if (position != stream-&gt;fPosition)
+			return -1;
 	}
 
-	*_cookie = cookie;
+	ssize_t read = stream-&gt;fSource-&gt;Read(buffer, bufferSize);
+	if (read &gt; 0)
+		stream-&gt;fPosition += read;
 
-	return B_OK;
+	TRACE_IO(&quot;  read: %ld\n&quot;, read);
+	return (int)read;
+
 }
 
 
+/*static*/ off_t
+AVFormatReader::StreamCookie::_Seek(void* cookie, off_t offset, int whence)
+{
+	TRACE_IO(&quot;AVFormatReader::StreamCookie::_Seek(%p, %lld, %d)\n&quot;,
+		cookie, offset, whence);
+
+	StreamCookie* stream = reinterpret_cast&lt;StreamCookie*&gt;(cookie);
+
+	BAutolock _(stream-&gt;fStreamLock);
+
+	// Support for special file size retrieval API without seeking
+	// anywhere:
+	if (whence == AVSEEK_SIZE) {
+		off_t size;
+		if (stream-&gt;fSource-&gt;GetSize(&amp;size) == B_OK)
+			return size;
+		return -1;
+	}
+
+	off_t position = stream-&gt;fSource-&gt;Seek(offset, whence);
+	stream-&gt;fPosition = position;
+
+	TRACE_IO(&quot;  position: %lld\n&quot;, position);
+	return position;
+}
+
+
 status_t
-AVFormatReader::FreeCookie(void *_cookie)
+AVFormatReader::StreamCookie::_NextPacket(bool reuse)
 {
-	StreamCookie* cookie = reinterpret_cast&lt;StreamCookie*&gt;(_cookie);
+	TRACE_PACKET(&quot;AVFormatReader::StreamCookie::_NextPacket(%d)\n&quot;, reuse);
 
-	avcodec_close(cookie-&gt;codecContext);
-	delete cookie;
+	if (fReusePacket) {
+		// The last packet was marked for reuse, so we keep using it.
+		TRACE_PACKET(&quot;  re-using last packet\n&quot;);
+		return B_OK;
+	}
 
+	av_free_packet(&amp;fPacket);
+
+	while (true) {
+		if (av_read_frame(fContext, &amp;fPacket) &lt; 0) {
+			fReusePacket = false;
+			return B_LAST_BUFFER_ERROR;
+		}
+
+		if (fPacket.stream_index == Index())
+			break;
+
+		// This is a packet from another stream, ignore it.
+		av_free_packet(&amp;fPacket);
+	}
+
+	// Mark this packet with the new reuse flag.
+	fReusePacket = reuse;
 	return B_OK;
 }
 
 
+// #pragma mark - AVFormatReader
+
+
+AVFormatReader::AVFormatReader()
+	:
+	fStreams(NULL),
+	fStreamLock(&quot;stream lock&quot;)
+{
+	TRACE(&quot;AVFormatReader::AVFormatReader\n&quot;);
+}
+
+
+AVFormatReader::~AVFormatReader()
+{
+	TRACE(&quot;AVFormatReader::~AVFormatReader\n&quot;);
+	delete[] fStreams;
+}
+
+
 // #pragma mark -
 
 
+const char*
+AVFormatReader::Copyright()
+{
+	// TODO: Return copyright of the file instead!
+	return &quot;Copyright 2009, Stephan A&#223;mus&quot;;
+}
+
+	
 status_t
-AVFormatReader::GetStreamInfo(void* _cookie, int64* frameCount,
-	bigtime_t* duration, media_format* format, const void** infoBuffer,
-	size_t* infoSize)
+AVFormatReader::Sniff(int32* _streamCount)
 {
-	TRACE(&quot;AVFormatReader::GetStreamInfo()\n&quot;);
+	TRACE(&quot;AVFormatReader::Sniff\n&quot;);
 
-	StreamCookie* cookie = reinterpret_cast&lt;StreamCookie*&gt;(_cookie);
-	AVStream* stream = cookie-&gt;stream;
+	BPositionIO* source = dynamic_cast&lt;BPositionIO*&gt;(Source());
+	if (source == NULL) {
+		TRACE(&quot;  not a BPositionIO, but we need it to be one.\n&quot;);
+		return B_NOT_SUPPORTED;
+	}
 
-	double frameRate = av_q2d(stream-&gt;r_frame_rate);

[... truncated: 495 lines follow ...]

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="017747.html">[Haiku-commits] r31420 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg
</A></li>
	<LI>Next message: <A HREF="017801.html">[Haiku-commits] r31421 - haiku/trunk/src/add-ons/media/plugins/ffmpeg
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#17748">[ date ]</a>
              <a href="thread.html#17748">[ thread ]</a>
              <a href="subject.html#17748">[ subject ]</a>
              <a href="author.html#17748">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
