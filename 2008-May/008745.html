<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r25450 - in haiku/trunk: headers/private/kernel	src/system/kernel/vm
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2008-May/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r25450%20-%20in%20haiku/trunk%3A%20headers/private/kernel%0A%09src/system/kernel/vm&In-Reply-To=%3C200805111602.m4BG2ELt001836%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="008743.html">
   <LINK REL="Next"  HREF="008757.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r25450 - in haiku/trunk: headers/private/kernel	src/system/kernel/vm</H1>
    <B>bonefish at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r25450%20-%20in%20haiku/trunk%3A%20headers/private/kernel%0A%09src/system/kernel/vm&In-Reply-To=%3C200805111602.m4BG2ELt001836%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r25450 - in haiku/trunk: headers/private/kernel	src/system/kernel/vm">bonefish at mail.berlios.de
       </A><BR>
    <I>Sun May 11 18:02:14 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="008743.html">[Haiku-commits] r25449 - haiku/trunk/src/tests/system/libroot/posix
</A></li>
        <LI>Next message: <A HREF="008757.html">[Haiku-commits] r25450 - in haiku/trunk: headers/private/kernel src/system/kernel/vm
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#8745">[ date ]</a>
              <a href="thread.html#8745">[ thread ]</a>
              <a href="subject.html#8745">[ subject ]</a>
              <a href="author.html#8745">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: bonefish
Date: 2008-05-11 18:02:13 +0200 (Sun, 11 May 2008)
New Revision: 25450
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=25450&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=25450&amp;view=rev</A>

Modified:
   haiku/trunk/headers/private/kernel/vm.h
   haiku/trunk/src/system/kernel/vm/vm.cpp
Log:
Added new private area protection flag B_KERNEL_AREA, which prevents all
changes to the area (delete, resize, clone) from userland.


Modified: haiku/trunk/headers/private/kernel/vm.h
===================================================================
--- haiku/trunk/headers/private/kernel/vm.h	2008-05-11 15:56:42 UTC (rev 25449)
+++ haiku/trunk/headers/private/kernel/vm.h	2008-05-11 16:02:13 UTC (rev 25450)
@@ -44,14 +44,16 @@
 	(B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA | B_KERNEL_EXECUTE_AREA \
 	| B_KERNEL_STACK_AREA)
 
+// TODO: These aren't really a protection flags, but since the &quot;protection&quot;
+//	field is the only flag field, we currently use it for this.
+//	A cleaner approach would be appreciated - maybe just an official generic
+//	flags region in the protection field.
 #define B_OVERCOMMITTING_AREA	0x1000
 #define B_SHARED_AREA			0x2000
-	// TODO: These aren't really a protection flags, but since the &quot;protection&quot;
-	//	field is the only flag field, we currently use it for this.
-	//	A cleaner approach would be appreciated - maybe just an official generic
-	//	flags region in the protection field.
+#define B_KERNEL_AREA			0x4000
+	// Usable from userland according to its protection flags, but the area
+	// itself is not deletable, resizable, etc from userland.
 
-
 #define B_USER_AREA_FLAGS		(B_USER_PROTECTION)
 #define B_KERNEL_AREA_FLAGS \
 	(B_KERNEL_PROTECTION | B_USER_CLONEABLE_AREA | B_OVERCOMMITTING_AREA \
@@ -110,7 +112,7 @@
 			uint32 addressSpec, addr_t size, uint32 flags);
 area_id vm_create_anonymous_area(team_id team, const char *name, void **address,
 			uint32 addressSpec, addr_t size, uint32 wiring, uint32 protection,
-			bool unmapAddressRange);
+			bool unmapAddressRange, bool kernel);
 area_id vm_map_physical_memory(team_id team, const char *name, void **address,
 			uint32 addressSpec, addr_t size, uint32 protection, addr_t phys_addr);
 area_id vm_map_file(team_id aid, const char *name, void **address,
@@ -124,8 +126,8 @@
 			uint32 addressSpec, uint32 protection, area_id sourceID);
 area_id vm_clone_area(team_id team, const char *name, void **address,
 			uint32 addressSpec, uint32 protection, uint32 mapping,
-			area_id sourceArea);
-status_t vm_delete_area(team_id teamID, area_id areaID);
+			area_id sourceArea, bool kernel);
+status_t vm_delete_area(team_id teamID, area_id areaID, bool kernel);
 status_t vm_create_vnode_cache(struct vnode *vnode, struct vm_cache **_cache);
 struct vm_area *vm_area_lookup(struct vm_address_space *addressSpace,
 			addr_t address);

Modified: haiku/trunk/src/system/kernel/vm/vm.cpp
===================================================================
--- haiku/trunk/src/system/kernel/vm/vm.cpp	2008-05-11 15:56:42 UTC (rev 25449)
+++ haiku/trunk/src/system/kernel/vm/vm.cpp	2008-05-11 16:02:13 UTC (rev 25450)
@@ -1194,7 +1194,8 @@
 	NOTE: At the moment deleting only complete areas is supported.
 */
 static status_t
-unmap_address_range(vm_address_space *addressSpace, addr_t address, addr_t size)
+unmap_address_range(vm_address_space *addressSpace, addr_t address, addr_t size,
+	bool kernel)
 {
 	// TODO: Support deleting partial areas!
 
@@ -1210,7 +1211,24 @@
 	if (area != NULL &amp;&amp; lastAddress - area-&gt;base &lt; area-&gt;size - 1)
 		return B_UNSUPPORTED;
 
-	// all areas (if any) are fully covered; let's delete them
+	// all areas (if any) are fully covered; we can delete them,
+	// but first we need to check, whether the caller is allowed to do that
+	if (!kernel) {
+		area = addressSpace-&gt;areas;
+		while (area != NULL) {
+			vm_area* nextArea = area-&gt;address_space_next;
+	
+			if (area-&gt;id != RESERVED_AREA_ID) {
+				if (area-&gt;base &gt;= address &amp;&amp; area-&gt;base &lt; lastAddress) {
+					if ((area-&gt;protection &amp; B_KERNEL_AREA) != 0)
+						return B_NOT_ALLOWED;
+				}
+			}
+	
+			area = nextArea;
+		}
+	}
+
 	area = addressSpace-&gt;areas;
 	while (area != NULL) {
 		vm_area* nextArea = area-&gt;address_space_next;
@@ -1235,7 +1253,7 @@
 map_backing_store(vm_address_space *addressSpace, vm_cache *cache,
 	void **_virtualAddress, off_t offset, addr_t size, uint32 addressSpec,
 	int wiring, int protection, int mapping, vm_area **_area,
-	const char *areaName, bool unmapAddressRange)
+	const char *areaName, bool unmapAddressRange, bool kernel)
 {
 	TRACE((&quot;map_backing_store: aspace %p, cache %p, *vaddr %p, offset 0x%Lx, size %lu, addressSpec %ld, wiring %d, protection %d, _area %p, area_name '%s'\n&quot;,
 		addressSpace, cache, *_virtualAddress, offset, size, addressSpec,
@@ -1298,7 +1316,7 @@
 
 	if (addressSpec == B_EXACT_ADDRESS &amp;&amp; unmapAddressRange) {
 		status = unmap_address_range(addressSpace, (addr_t)*_virtualAddress,
-			size);
+			size, kernel);
 		if (status != B_OK)
 			goto err2;
 	}
@@ -1429,7 +1447,7 @@
 area_id
 vm_create_anonymous_area(team_id team, const char *name, void **address,
 	uint32 addressSpec, addr_t size, uint32 wiring, uint32 protection,
-	bool unmapAddressRange)
+	bool unmapAddressRange, bool kernel)
 {
 	vm_area *area;
 	vm_cache *cache;
@@ -1533,7 +1551,7 @@
 
 	status = map_backing_store(addressSpace, cache, address, 0, size,
 		addressSpec, wiring, protection, REGION_NO_PRIVATE_MAP, &amp;area, name,
-		unmapAddressRange);
+		unmapAddressRange, kernel);
 
 	mutex_unlock(&amp;cache-&gt;lock);
 
@@ -1747,7 +1765,7 @@
 
 	status_t status = map_backing_store(locker.AddressSpace(), cache, _address,
 		0, size, addressSpec &amp; ~B_MTR_MASK, B_FULL_LOCK, protection,
-		REGION_NO_PRIVATE_MAP, &amp;area, name, false);
+		REGION_NO_PRIVATE_MAP, &amp;area, name, false, true);
 
 	mutex_unlock(&amp;cache-&gt;lock);
 
@@ -1829,7 +1847,7 @@
 
 	status = map_backing_store(locker.AddressSpace(), cache, address, 0, size,
 		addressSpec, 0, B_KERNEL_READ_AREA, REGION_NO_PRIVATE_MAP, &amp;area, name,
-		false);
+		false, true);
 
 	mutex_unlock(&amp;cache-&gt;lock);
 
@@ -1897,7 +1915,7 @@
 
 	if (fd &lt; 0) {
 		return vm_create_anonymous_area(team, name, _address, addressSpec, size,
-			B_NO_LOCK, protection, addressSpec == B_EXACT_ADDRESS);
+			B_NO_LOCK, protection, addressSpec == B_EXACT_ADDRESS, kernel);
 	}
 
 	// get the open flags of the FD
@@ -1938,7 +1956,7 @@
 	vm_area *area;
 	status = map_backing_store(locker.AddressSpace(), cache, _address,
 		offset, size, addressSpec, 0, protection, mapping, &amp;area, name,
-		addressSpec == B_EXACT_ADDRESS);
+		addressSpec == B_EXACT_ADDRESS, kernel);
 
 	mutex_unlock(&amp;cache-&gt;lock);
 
@@ -1998,7 +2016,8 @@
 
 area_id
 vm_clone_area(team_id team, const char *name, void **address,
-	uint32 addressSpec, uint32 protection, uint32 mapping, area_id sourceID)
+	uint32 addressSpec, uint32 protection, uint32 mapping, area_id sourceID,
+	bool kernel)
 {
 	vm_area *newArea = NULL;
 	vm_area *sourceArea;
@@ -2022,6 +2041,9 @@
 	if (sourceArea == NULL)
 		return B_BAD_VALUE;
 
+	if (!kernel &amp;&amp; (sourceArea-&gt;protection &amp; B_KERNEL_AREA) != 0)
+		return B_NOT_ALLOWED;
+
 	vm_cache *cache = vm_area_get_locked_cache(sourceArea);
 
 	// ToDo: for now, B_USER_CLONEABLE is disabled, until all drivers
@@ -2040,7 +2062,8 @@
 	else {
 		status = map_backing_store(targetAddressSpace, cache, address,
 			sourceArea-&gt;cache_offset, sourceArea-&gt;size, addressSpec,
-			sourceArea-&gt;wiring, protection, mapping, &amp;newArea, name, false);
+			sourceArea-&gt;wiring, protection, mapping, &amp;newArea, name, false,
+			kernel);
 	}
 	if (status == B_OK &amp;&amp; mapping != REGION_PRIVATE_MAP) {
 		// If the mapping is REGION_PRIVATE_MAP, map_backing_store() needed
@@ -2164,7 +2187,7 @@
 
 
 status_t
-vm_delete_area(team_id team, area_id id)
+vm_delete_area(team_id team, area_id id, bool kernel)
 {
 	TRACE((&quot;vm_delete_area(team = 0x%lx, area = 0x%lx)\n&quot;, team, id));
 
@@ -2174,6 +2197,9 @@
 	if (status &lt; B_OK)
 		return status;
 
+	if (!kernel &amp;&amp; (area-&gt;protection &amp; B_KERNEL_AREA) != 0)
+		return B_NOT_ALLOWED;
+
 	delete_area(locker.AddressSpace(), area);
 	return B_OK;
 }
@@ -2303,7 +2329,7 @@
 	status = map_backing_store(targetAddressSpace, cache, _address,
 		source-&gt;cache_offset, source-&gt;size, addressSpec, source-&gt;wiring,
 		protection, sharedArea ? REGION_NO_PRIVATE_MAP : REGION_PRIVATE_MAP,
-		&amp;target, name, false);
+		&amp;target, name, false, true);
 	if (status &lt; B_OK)
 		return status;
 
@@ -2346,7 +2372,8 @@
 
 
 static status_t
-vm_set_area_protection(team_id team, area_id areaID, uint32 newProtection)
+vm_set_area_protection(team_id team, area_id areaID, uint32 newProtection,
+	bool kernel)
 {
 	TRACE((&quot;vm_set_area_protection(team = %#lx, area = %#lx, protection = %#lx)\n&quot;,
 		team, areaID, newProtection));
@@ -2362,6 +2389,9 @@
 		&amp;cache, true);
 	AreaCacheLocker cacheLocker(cache);	// already locked
 
+	if (!kernel &amp;&amp; (area-&gt;protection &amp; B_KERNEL_AREA) != 0)
+		return B_NOT_ALLOWED;
+
 	if (area-&gt;protection == newProtection)
 		return B_OK;
 
@@ -4597,6 +4627,112 @@
 }
 
 
+static status_t
+vm_resize_area(area_id areaID, size_t newSize, bool kernel)
+{
+	// is newSize a multiple of B_PAGE_SIZE?
+	if (newSize &amp; (B_PAGE_SIZE - 1))
+		return B_BAD_VALUE;
+
+	// lock all affected address spaces and the cache
+	vm_area* area;
+	vm_cache* cache;
+
+	MultiAddressSpaceLocker locker;
+	status_t status = locker.AddAreaCacheAndLock(areaID, true, true, area,
+		&amp;cache);
+	if (status != B_OK)
+		return status;
+	AreaCacheLocker cacheLocker(cache);	// already locked
+
+	// enforce restrictions
+	if (!kernel) {
+		if ((area-&gt;protection &amp; B_KERNEL_AREA) != 0)
+			return B_NOT_ALLOWED;
+		// TODO: Enforce all restrictions (team, etc.)!
+	}
+
+	size_t oldSize = area-&gt;size;
+	if (newSize == oldSize)
+		return B_OK;
+
+	// Resize all areas of this area's cache
+
+	if (cache-&gt;type != CACHE_TYPE_RAM)
+		return B_NOT_ALLOWED;
+
+	if (oldSize &lt; newSize) {
+		// We need to check if all areas of this cache can be resized
+
+		for (vm_area* current = cache-&gt;areas; current != NULL;
+				current = current-&gt;cache_next) {
+			if (current-&gt;address_space_next
+				&amp;&amp; current-&gt;address_space_next-&gt;base &lt;= (current-&gt;base
+					+ newSize)) {
+				// If the area was created inside a reserved area, it can
+				// also be resized in that area
+				// ToDo: if there is free space after the reserved area, it could be used as well...
+				vm_area *next = current-&gt;address_space_next;
+				if (next-&gt;id == RESERVED_AREA_ID
+					&amp;&amp; next-&gt;cache_offset &lt;= current-&gt;base
+					&amp;&amp; next-&gt;base - 1 + next-&gt;size &gt;= current-&gt;base - 1 + newSize)
+					continue;
+
+				return B_ERROR;
+			}
+		}
+	}
+
+	// Okay, looks good so far, so let's do it
+
+	for (vm_area* current = cache-&gt;areas; current != NULL;
+			current = current-&gt;cache_next) {
+		if (current-&gt;address_space_next
+			&amp;&amp; current-&gt;address_space_next-&gt;base &lt;= (current-&gt;base + newSize)) {
+			vm_area *next = current-&gt;address_space_next;
+			if (next-&gt;id == RESERVED_AREA_ID
+				&amp;&amp; next-&gt;cache_offset &lt;= current-&gt;base
+				&amp;&amp; next-&gt;base - 1 + next-&gt;size &gt;= current-&gt;base - 1 + newSize) {
+				// resize reserved area
+				addr_t offset = current-&gt;base + newSize - next-&gt;base;
+				if (next-&gt;size &lt;= offset) {
+					current-&gt;address_space_next = next-&gt;address_space_next;
+					free(next);
+				} else {
+					next-&gt;size -= offset;
+					next-&gt;base += offset;
+				}
+			} else {
+				status = B_ERROR;
+				break;
+			}
+		}
+
+		current-&gt;size = newSize;
+
+		// we also need to unmap all pages beyond the new size, if the area has shrinked
+		if (newSize &lt; oldSize) {
+			vm_unmap_pages(current, current-&gt;base + newSize, oldSize - newSize,
+				false);
+		}
+	}
+
+	if (status == B_OK)
+		status = vm_cache_resize(cache, newSize);
+
+	if (status &lt; B_OK) {
+		// This shouldn't really be possible, but hey, who knows
+		for (vm_area* current = cache-&gt;areas; current != NULL;
+				current = current-&gt;cache_next) {
+			current-&gt;size = oldSize;
+		}
+	}
+
+	// TODO: we must honour the lock restrictions of this area
+	return status;
+}
+
+
 //	#pragma mark - kernel public API
 
 
@@ -4980,106 +5116,14 @@
 	fix_protection(&amp;newProtection);
 
 	return vm_set_area_protection(vm_kernel_address_space_id(), area,
-		newProtection);
+		newProtection, true);
 }
 
 
 status_t
 resize_area(area_id areaID, size_t newSize)
 {
-	// is newSize a multiple of B_PAGE_SIZE?
-	if (newSize &amp; (B_PAGE_SIZE - 1))
-		return B_BAD_VALUE;
-
-	// lock all affected address spaces and the cache
-	vm_area* area;
-	vm_cache* cache;
-
-	MultiAddressSpaceLocker locker;
-	status_t status = locker.AddAreaCacheAndLock(areaID, true, true, area,
-		&amp;cache);
-	if (status != B_OK)
-		return status;
-	AreaCacheLocker cacheLocker(cache);	// already locked
-
-	size_t oldSize = area-&gt;size;
-	if (newSize == oldSize)
-		return B_OK;
-
-	// Resize all areas of this area's cache
-
-	if (cache-&gt;type != CACHE_TYPE_RAM)
-		return B_NOT_ALLOWED;
-
-	if (oldSize &lt; newSize) {
-		// We need to check if all areas of this cache can be resized
-
-		for (vm_area* current = cache-&gt;areas; current != NULL;
-				current = current-&gt;cache_next) {
-			if (current-&gt;address_space_next
-				&amp;&amp; current-&gt;address_space_next-&gt;base &lt;= (current-&gt;base
-					+ newSize)) {
-				// If the area was created inside a reserved area, it can
-				// also be resized in that area
-				// ToDo: if there is free space after the reserved area, it could be used as well...
-				vm_area *next = current-&gt;address_space_next;
-				if (next-&gt;id == RESERVED_AREA_ID
-					&amp;&amp; next-&gt;cache_offset &lt;= current-&gt;base
-					&amp;&amp; next-&gt;base - 1 + next-&gt;size &gt;= current-&gt;base - 1 + newSize)
-					continue;
-
-				return B_ERROR;
-			}
-		}
-	}
-
-	// Okay, looks good so far, so let's do it
-
-	for (vm_area* current = cache-&gt;areas; current != NULL;
-			current = current-&gt;cache_next) {
-		if (current-&gt;address_space_next
-			&amp;&amp; current-&gt;address_space_next-&gt;base &lt;= (current-&gt;base + newSize)) {
-			vm_area *next = current-&gt;address_space_next;
-			if (next-&gt;id == RESERVED_AREA_ID
-				&amp;&amp; next-&gt;cache_offset &lt;= current-&gt;base
-				&amp;&amp; next-&gt;base - 1 + next-&gt;size &gt;= current-&gt;base - 1 + newSize) {
-				// resize reserved area
-				addr_t offset = current-&gt;base + newSize - next-&gt;base;
-				if (next-&gt;size &lt;= offset) {
-					current-&gt;address_space_next = next-&gt;address_space_next;
-					free(next);
-				} else {
-					next-&gt;size -= offset;
-					next-&gt;base += offset;
-				}
-			} else {
-				status = B_ERROR;
-				break;
-			}
-		}
-
-		current-&gt;size = newSize;
-
-		// we also need to unmap all pages beyond the new size, if the area has shrinked
-		if (newSize &lt; oldSize) {
-			vm_unmap_pages(current, current-&gt;base + newSize, oldSize - newSize,
-				false);
-		}
-	}
-
-	if (status == B_OK)
-		status = vm_cache_resize(cache, newSize);
-
-	if (status &lt; B_OK) {
-		// This shouldn't really be possible, but hey, who knows
-		for (vm_area* current = cache-&gt;areas; current != NULL;
-				current = current-&gt;cache_next) {
-			current-&gt;size = oldSize;
-		}
-	}
-
-	// ToDo: we must honour the lock restrictions of this area
-	return status;
+	return vm_resize_area(areaID, newSize, true);
 }
 
 
@@ -5090,7 +5134,8 @@
  */
 
 static area_id
-transfer_area(area_id id, void **_address, uint32 addressSpec, team_id target)
+transfer_area(area_id id, void **_address, uint32 addressSpec, team_id target,
+	bool kernel)
 {
 	area_info info;
 	status_t status = get_area_info(id, &amp;info);
@@ -5098,13 +5143,13 @@
 		return status;
 
 	area_id clonedArea = vm_clone_area(target, info.name, _address,
-		addressSpec, info.protection, REGION_NO_PRIVATE_MAP, id);
+		addressSpec, info.protection, REGION_NO_PRIVATE_MAP, id, kernel);
 	if (clonedArea &lt; B_OK)
 		return clonedArea;
 
-	status = vm_delete_area(info.team, id);
+	status = vm_delete_area(info.team, id, kernel);
 	if (status &lt; B_OK) {
-		vm_delete_area(target, clonedArea);
+		vm_delete_area(target, clonedArea, kernel);
 		return status;
 	}
 
@@ -5134,7 +5179,7 @@
 		protection |= B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA;
 
 	return vm_clone_area(vm_kernel_address_space_id(), name, _address,
-		addressSpec, protection, REGION_NO_PRIVATE_MAP, source);
+		addressSpec, protection, REGION_NO_PRIVATE_MAP, source, true);
 }
 
 
@@ -5145,7 +5190,7 @@
 	fix_protection(&amp;protection);
 
 	return vm_create_anonymous_area(team-&gt;id, (char *)name, address,
-		addressSpec, size, lock, protection, false);
+		addressSpec, size, lock, protection, false, true);
 }
 
 
@@ -5156,21 +5201,21 @@
 	fix_protection(&amp;protection);
 
 	return vm_create_anonymous_area(vm_kernel_address_space_id(), (char *)name, _address,
-		addressSpec, size, lock, protection, false);
+		addressSpec, size, lock, protection, false, true);
 }
 
 
 status_t
 delete_area_etc(struct team *team, area_id area)
 {
-	return vm_delete_area(team-&gt;id, area);
+	return vm_delete_area(team-&gt;id, area, true);
 }
 
 
 status_t
 delete_area(area_id area)
 {
-	return vm_delete_area(vm_kernel_address_space_id(), area);
+	return vm_delete_area(vm_kernel_address_space_id(), area, true);
 }
 
 
@@ -5283,7 +5328,7 @@
 	fix_protection(&amp;newProtection);
 
 	return vm_set_area_protection(vm_current_user_address_space_id(), area,
-		newProtection);
+		newProtection, false);
 }
 
 
@@ -5292,7 +5337,7 @@
 {
 	// ToDo: Since we restrict deleting of areas to those owned by the team,
 	// we should also do that for resizing (check other functions, too).
-	return resize_area(area, newSize);
+	return vm_resize_area(area, newSize, false);
 }
 
 
@@ -5311,7 +5356,7 @@
 		|| user_memcpy(&amp;address, userAddress, sizeof(address)) &lt; B_OK)
 		return B_BAD_ADDRESS;
 
-	area_id newArea = transfer_area(area, &amp;address, addressSpec, target);
+	area_id newArea = transfer_area(area, &amp;address, addressSpec, target, false);
 	if (newArea &lt; B_OK)
 		return newArea;
 
@@ -5347,7 +5392,7 @@
 	fix_protection(&amp;protection);
 
 	area_id clonedArea = vm_clone_area(vm_current_user_address_space_id(), name, &amp;address,
-		addressSpec, protection, REGION_NO_PRIVATE_MAP, sourceArea);
+		addressSpec, protection, REGION_NO_PRIVATE_MAP, sourceArea, false);
 	if (clonedArea &lt; B_OK)
 		return clonedArea;
 
@@ -5389,7 +5434,8 @@
 	fix_protection(&amp;protection);
 
 	area_id area = vm_create_anonymous_area(vm_current_user_address_space_id(),
-		(char *)name, &amp;address, addressSpec, size, lock, protection, false);
+		(char *)name, &amp;address, addressSpec, size, lock, protection, false,
+		false);
 
 	if (area &gt;= B_OK &amp;&amp; user_memcpy(userAddress, &amp;address, sizeof(address)) &lt; B_OK) {
 		delete_area(area);
@@ -5407,7 +5453,7 @@
 	// that you have created yourself from userland.
 	// The documentation to delete_area() explicetly states that this
 	// will be restricted in the future, and so it will.
-	return vm_delete_area(vm_current_user_address_space_id(), area);
+	return vm_delete_area(vm_current_user_address_space_id(), area, false);
 }
 
 
@@ -5470,5 +5516,5 @@
 		return status;
 
 	// unmap
-	return unmap_address_range(locker.AddressSpace(), address, size);
+	return unmap_address_range(locker.AddressSpace(), address, size, false);
 }


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="008743.html">[Haiku-commits] r25449 - haiku/trunk/src/tests/system/libroot/posix
</A></li>
	<LI>Next message: <A HREF="008757.html">[Haiku-commits] r25450 - in haiku/trunk: headers/private/kernel src/system/kernel/vm
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#8745">[ date ]</a>
              <a href="thread.html#8745">[ thread ]</a>
              <a href="subject.html#8745">[ subject ]</a>
              <a href="author.html#8745">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
