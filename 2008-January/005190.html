<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r23246 - in	haiku/branches/developer/axeld/slab_heap:	headers_private_kernel headers_private_kernel/slab	headers_private_kernel/util src_system_kernel	src_system_kernel/arch/x86 src_system_kernel/slab	src_system_kernel/util src_system_kernel/vm
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2008-January/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r23246%20-%20in%0A%09haiku/branches/developer/axeld/slab_heap%3A%0A%09headers_private_kernel%20headers_private_kernel/slab%0A%09headers_private_kernel/util%20src_system_kernel%0A%09src_system_kernel/arch/x86%20src_system_kernel/slab%0A%09src_system_kernel/util%20src_system_kernel/vm&In-Reply-To=%3C200801041722.m04HMqEY014862%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="005189.html">
   <LINK REL="Next"  HREF="005192.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r23246 - in	haiku/branches/developer/axeld/slab_heap:	headers_private_kernel headers_private_kernel/slab	headers_private_kernel/util src_system_kernel	src_system_kernel/arch/x86 src_system_kernel/slab	src_system_kernel/util src_system_kernel/vm</H1>
    <B>axeld at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r23246%20-%20in%0A%09haiku/branches/developer/axeld/slab_heap%3A%0A%09headers_private_kernel%20headers_private_kernel/slab%0A%09headers_private_kernel/util%20src_system_kernel%0A%09src_system_kernel/arch/x86%20src_system_kernel/slab%0A%09src_system_kernel/util%20src_system_kernel/vm&In-Reply-To=%3C200801041722.m04HMqEY014862%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r23246 - in	haiku/branches/developer/axeld/slab_heap:	headers_private_kernel headers_private_kernel/slab	headers_private_kernel/util src_system_kernel	src_system_kernel/arch/x86 src_system_kernel/slab	src_system_kernel/util src_system_kernel/vm">axeld at mail.berlios.de
       </A><BR>
    <I>Fri Jan  4 18:22:52 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="005189.html">[Haiku-commits] r23245 - haiku/branches/developer/axeld/slab_heap
</A></li>
        <LI>Next message: <A HREF="005192.html">[Haiku-commits] r23247 -	haiku/trunk/src/add-ons/kernel/busses/scsi/ahci
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5190">[ date ]</a>
              <a href="thread.html#5190">[ thread ]</a>
              <a href="subject.html#5190">[ subject ]</a>
              <a href="author.html#5190">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: axeld
Date: 2008-01-04 18:22:51 +0100 (Fri, 04 Jan 2008)
New Revision: 23246
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=23246&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=23246&amp;view=rev</A>

Modified:
   haiku/branches/developer/axeld/slab_heap/headers_private_kernel/memheap.h
   haiku/branches/developer/axeld/slab_heap/headers_private_kernel/slab/Slab.h
   haiku/branches/developer/axeld/slab_heap/headers_private_kernel/util/khash.h
   haiku/branches/developer/axeld/slab_heap/headers_private_kernel/vm_cache.h
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/arch/x86/arch_vm_translation_map.cpp
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/heap.c
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/Slab.cpp
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/allocator.cpp
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/slab_private.h
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/util/khash.c
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/vm/vm.cpp
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/vm/vm_address_space.cpp
   haiku/branches/developer/axeld/slab_heap/src_system_kernel/vm/vm_cache.cpp
Log:
Work in progress, so that I can continue with this at a later point, and still
be able to test Haiku (this currently crashes very early in the boot process).


Modified: haiku/branches/developer/axeld/slab_heap/headers_private_kernel/memheap.h
===================================================================
--- haiku/branches/developer/axeld/slab_heap/headers_private_kernel/memheap.h	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/headers_private_kernel/memheap.h	2008-01-04 17:22:51 UTC (rev 23246)
@@ -1,5 +1,5 @@
 /*
- * Copyright 2002-2006, Axel D&#246;rfler, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de.</A>
+ * Copyright 2002-2007, Axel D&#246;rfler, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de.</A>
  * Distributed under the terms of the MIT License.
  *
  * Copyright 2001-2002, Travis Geiselbrecht. All rights reserved.
@@ -22,6 +22,9 @@
 extern &quot;C&quot; {
 #endif
 
+void *malloc_early(struct kernel_args *args, size_t size, size_t *_areaSize);
+void malloc_early_create_area(void *address, const char *name);
+
 void *memalign(size_t alignment, size_t size);
 
 status_t heap_init(addr_t heapBase, size_t heapSize);

Modified: haiku/branches/developer/axeld/slab_heap/headers_private_kernel/slab/Slab.h
===================================================================
--- haiku/branches/developer/axeld/slab_heap/headers_private_kernel/slab/Slab.h	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/headers_private_kernel/slab/Slab.h	2008-01-04 17:22:51 UTC (rev 23246)
@@ -20,9 +20,6 @@
 
 	/* object_cache_alloc flags */
 	CACHE_DONT_SLEEP		= 1 &lt;&lt; 8,
-
-	/* internal */
-	CACHE_DURING_BOOT		= 1 &lt;&lt; 31
 };
 
 typedef struct object_cache object_cache;

Modified: haiku/branches/developer/axeld/slab_heap/headers_private_kernel/util/khash.h
===================================================================
--- haiku/branches/developer/axeld/slab_heap/headers_private_kernel/util/khash.h	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/headers_private_kernel/util/khash.h	2008-01-04 17:22:51 UTC (rev 23246)
@@ -24,10 +24,13 @@
 extern &quot;C&quot; {
 #endif
 
-struct hash_table *hash_init(uint32 table_size, int next_ptr_offset,
-	int compare_func(void *element, const void *key),
-	uint32 hash_func(void *element, const void *key, uint32 range));
-int hash_uninit(struct hash_table *table);
+struct hash_table *hash_init_etc(void *table, uint32 tableSize,
+	uint32 nextOffset, int compareFunc(void *e, const void *key),
+	uint32 hashFunc(void *e, const void *key, uint32 range));
+struct hash_table *hash_init(uint32 tableSize, uint32 nextOffset,
+	int compareFunc(void *element, const void *key),
+	uint32 hashFunc(void *element, const void *key, uint32 range));
+void hash_uninit(struct hash_table *table);
 status_t hash_grow(struct hash_table *table, uint32 newSize);
 status_t hash_insert(struct hash_table *table, void *_element);
 status_t hash_remove(struct hash_table *table, void *_element);
@@ -41,6 +44,7 @@
 void hash_rewind(struct hash_table *table, struct hash_iterator *i);
 uint32 hash_count_elements(struct hash_table *table);
 uint32 hash_count_used_slots(struct hash_table *table);
+uint32 get_prime_table_size(uint32 size);
 
 /* function pointers must look like this:
  *

Modified: haiku/branches/developer/axeld/slab_heap/headers_private_kernel/vm_cache.h
===================================================================
--- haiku/branches/developer/axeld/slab_heap/headers_private_kernel/vm_cache.h	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/headers_private_kernel/vm_cache.h	2008-01-04 17:22:51 UTC (rev 23246)
@@ -22,7 +22,7 @@
 extern &quot;C&quot; {
 #endif
 
-status_t vm_cache_init(struct kernel_args *args);
+status_t vm_cache_init(struct kernel_args *args, void *table, uint32 tableSize);
 struct vm_cache *vm_cache_create(struct vm_store *store);
 void vm_cache_acquire_ref(struct vm_cache *cache);
 void vm_cache_release_ref(struct vm_cache *cache);

Modified: haiku/branches/developer/axeld/slab_heap/src_system_kernel/arch/x86/arch_vm_translation_map.cpp
===================================================================
--- haiku/branches/developer/axeld/slab_heap/src_system_kernel/arch/x86/arch_vm_translation_map.cpp	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/src_system_kernel/arch/x86/arch_vm_translation_map.cpp	2008-01-04 17:22:51 UTC (rev 23246)
@@ -784,14 +784,17 @@
 			return map-&gt;lock.sem;
 	}
 
-	map-&gt;arch_data = (vm_translation_map_arch_info *)malloc(sizeof(vm_translation_map_arch_info));
+dprintf(&quot;aa+++\n&quot;);
+	map-&gt;arch_data = (vm_translation_map_arch_info *)malloc(
+		sizeof(vm_translation_map_arch_info));
+dprintf(&quot;aa---\n&quot;);
 	if (map == NULL) {
 		recursive_lock_destroy(&amp;map-&gt;lock);
 		return B_NO_MEMORY;
 	}
 
 	map-&gt;arch_data-&gt;num_invalidate_pages = 0;
-
+dprintf(&quot;bb\n&quot;);
 	if (!kernel) {
 		// user
 		// allocate a pgdir
@@ -810,11 +813,13 @@
 		map-&gt;arch_data-&gt;pgdir_virt = sKernelVirtualPageDirectory;
 		map-&gt;arch_data-&gt;pgdir_phys = sKernelPhysicalPageDirectory;
 	}
+dprintf(&quot;cc\n&quot;);
 
 	// zero out the bottom portion of the new pgdir
 	memset(map-&gt;arch_data-&gt;pgdir_virt + FIRST_USER_PGDIR_ENT, 0,
 		NUM_USER_PGDIR_ENTS * sizeof(page_directory_entry));
 
+dprintf(&quot;dd\n&quot;);
 	// insert this new map into the map list
 	{
 		int state = disable_interrupts();
@@ -831,6 +836,7 @@
 		release_spinlock(&amp;tmap_list_lock);
 		restore_interrupts(state);
 	}
+dprintf(&quot;ee\n&quot;);
 
 	return B_OK;
 }

Modified: haiku/branches/developer/axeld/slab_heap/src_system_kernel/heap.c
===================================================================
--- haiku/branches/developer/axeld/slab_heap/src_system_kernel/heap.c	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/src_system_kernel/heap.c	2008-01-04 17:22:51 UTC (rev 23246)
@@ -421,7 +421,7 @@
 
 //	#pragma mark -
 
-
+#if 0
 void *
 memalign(size_t alignment, size_t size)
 {
@@ -762,4 +762,4 @@
 
 	return address;
 }
-
+#endif

Modified: haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/Slab.cpp
===================================================================
--- haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/Slab.cpp	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/Slab.cpp	2008-01-04 17:22:51 UTC (rev 23246)
@@ -1,9 +1,6 @@
 /*
  * Copyright 2007, Hugo Santos. All Rights Reserved.
  * Distributed under the terms of the MIT License.
- *
- * Authors:
- *      Hugo Santos, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">hugosantos at gmail.com</A>
  */
 
 
@@ -30,7 +27,7 @@
 // TODO kMagazineCapacity should be dynamically tuned per cache.
 
 
-//#define TRACE_SLAB
+#define TRACE_SLAB
 
 #ifdef TRACE_SLAB
 #define TRACE_CACHE(cache, format, args...) \
@@ -73,10 +70,6 @@
 	object_cache_destructor destructor;
 	object_cache_reclaimer reclaimer;
 
-	status_t (*allocate_pages)(object_cache *cache, void **pages,
-		uint32 flags);
-	void (*free_pages)(object_cache *cache, void *pages);
-
 	object_depot depot;
 
 	virtual slab *CreateSlab(uint32 flags) = 0;
@@ -100,7 +93,6 @@
 	slab *ObjectSlab(void *object) const;
 };
 
-
 struct HashedObjectCache : object_cache {
 	struct Link : HashTableLink&lt;Link&gt; {
 		const void *buffer;
@@ -144,14 +136,12 @@
 	size_t lower_boundary;
 };
 
-
 struct depot_magazine {
 	struct depot_magazine *next;
 	uint16 current_round, round_count;
 	void *rounds[0];
 };
 
-
 struct depot_cpu_store {
 	benaphore lock;
 	struct depot_magazine *loaded, *previous;
@@ -163,6 +153,7 @@
 
 static uint8 *sInitialBegin, *sInitialLimit, *sInitialPointer;
 static kernel_args *sKernelArgs;
+static bool sDuringBoot = true;
 
 
 static status_t object_cache_reserve_internal(object_cache *cache,
@@ -226,7 +217,8 @@
 static void *
 internal_alloc(size_t size, uint32 flags)
 {
-	if (flags &amp; CACHE_DURING_BOOT) {
+dprintf(&quot;internal alloc size %lu, flags %lx\n&quot;, size, flags);
+	if (sDuringBoot) {
 		if ((sInitialPointer + size) &gt; sInitialLimit)
 			panic(&quot;internal_alloc: ran out of initial space&quot;);
 
@@ -235,7 +227,7 @@
 		return buffer;
 	}
 
-	return block_alloc(size);
+	return malloc/*block_alloc*/(size);
 }
 
 
@@ -247,14 +239,14 @@
 	if (buffer &gt;= sInitialBegin &amp;&amp; buffer &lt; sInitialLimit)
 		return;
 
-	block_free(buffer);
+	/*block_*/free(buffer);
 }
 
 
 static status_t
 benaphore_boot_init(benaphore *lock, const char *name, uint32 flags)
 {
-	if (flags &amp; CACHE_DURING_BOOT) {
+	if (sDuringBoot) {
 		lock-&gt;sem = -1;
 		lock-&gt;count = 1;
 		return B_OK;
@@ -265,10 +257,21 @@
 
 
 static status_t
-area_allocate_pages(object_cache *cache, void **pages, uint32 flags)
+allocate_pages(object_cache *cache, void **pages, uint32 flags)
 {
 	TRACE_CACHE(cache, &quot;allocate pages (%lu, 0x0%lx)&quot;, cache-&gt;slab_size, flags);
 
+	if (sDuringBoot) {
+		addr_t base = vm_allocate_early(sKernelArgs, cache-&gt;slab_size,
+			cache-&gt;slab_size, B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA);
+
+		*pages = (void *)base;
+		cache-&gt;usage += cache-&gt;slab_size;
+
+		TRACE_CACHE(cache, &quot;  ... = { %p }&quot;, *pages);
+		return B_OK;
+	}
+
 	uint32 lock = B_FULL_LOCK;
 	if (cache-&gt;flags &amp; CACHE_UNLOCKED_PAGES)
 		lock = B_NO_LOCK;
@@ -284,14 +287,16 @@
 	cache-&gt;usage += cache-&gt;slab_size;
 
 	TRACE_CACHE(cache, &quot;  ... = { %ld, %p }&quot;, areaId, *pages);
-
 	return B_OK;
 }
 
 
 static void
-area_free_pages(object_cache *cache, void *pages)
+free_pages(object_cache *cache, void *pages)
 {
+	if (sDuringBoot)
+		panic(&quot;memory pressure on bootup?&quot;);
+
 	area_id id = area_for(pages);
 
 	TRACE_CACHE(cache, &quot;delete pages %p (%ld)&quot;, pages, id);
@@ -305,33 +310,7 @@
 }
 
 
-static status_t
-early_allocate_pages(object_cache *cache, void **pages, uint32 flags)
-{
-	TRACE_CACHE(cache, &quot;early allocate pages (%lu, 0x0%lx)&quot;, cache-&gt;slab_size,
-		flags);
-
-	addr_t base = vm_allocate_early(sKernelArgs, cache-&gt;slab_size,
-		cache-&gt;slab_size, B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA);
-
-	*pages = (void *)base;
-
-	cache-&gt;usage += cache-&gt;slab_size;
-
-	TRACE_CACHE(cache, &quot;  ... = { %p }&quot;, *pages);
-
-	return B_OK;
-}
-
-
 static void
-early_free_pages(object_cache *cache, void *pages)
-{
-	panic(&quot;memory pressure on bootup?&quot;);
-}
-
-
-static void
 object_cache_low_memory(void *_self, int32 level)
 {
 	if (level == B_NO_LOW_MEMORY)
@@ -442,16 +421,9 @@
 	cache-&gt;destructor = destructor;
 	cache-&gt;reclaimer = reclaimer;
 
-	if (cache-&gt;flags &amp; CACHE_DURING_BOOT) {
-		cache-&gt;allocate_pages = early_allocate_pages;
-		cache-&gt;free_pages = early_free_pages;
-	} else {
-		cache-&gt;allocate_pages = area_allocate_pages;
-		cache-&gt;free_pages = area_free_pages;
-	}
+	if (!sDuringBoot)
+		register_low_memory_handler(object_cache_low_memory, cache, 5);
 
-	register_low_memory_handler(object_cache_low_memory, cache, 5);
-
 	BenaphoreLocker _(sObjectCacheListLock);
 	sObjectCaches.Add(cache);
 
@@ -478,7 +450,7 @@
 {
 	void *pages = (void *)ROUNDOWN((addr_t)slab-&gt;pages, B_PAGE_SIZE);
 	if (create_area(cache-&gt;name, &amp;pages, B_EXACT_ADDRESS, cache-&gt;slab_size,
-		B_ALREADY_WIRED, B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA) &lt; B_OK)
+			B_ALREADY_WIRED, B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA) &lt; B_OK)
 		panic(&quot;failed to create_area()&quot;);
 }
 
@@ -497,9 +469,6 @@
 	it = cache-&gt;empty.GetIterator();
 	while (it.HasNext())
 		object_cache_commit_slab(cache, it.Next());
-
-	cache-&gt;allocate_pages = area_allocate_pages;
-	cache-&gt;free_pages = area_free_pages;
 }
 
 
@@ -512,7 +481,7 @@
 
 
 static SmallObjectCache *
-create_small_object_cache(const char *name, size_t object_size,
+create_small_object_cache(const char *name, size_t objectSize,
 	size_t alignment, size_t maximum, uint32 flags, void *cookie,
 	object_cache_constructor constructor, object_cache_destructor destructor,
 	object_cache_reclaimer reclaimer)
@@ -523,7 +492,7 @@
 
 	SmallObjectCache *cache = new (buffer) SmallObjectCache();
 
-	if (object_cache_init(cache, name, object_size, alignment, maximum, flags,
+	if (object_cache_init(cache, name, objectSize, alignment, maximum, flags,
 		cookie, constructor, destructor, reclaimer) &lt; B_OK) {
 		delete_cache(cache);
 		return NULL;
@@ -536,7 +505,7 @@
 
 
 static HashedObjectCache *
-create_hashed_object_cache(const char *name, size_t object_size,
+create_hashed_object_cache(const char *name, size_t objectSize,
 	size_t alignment, size_t maximum, uint32 flags, void *cookie,
 	object_cache_constructor constructor, object_cache_destructor destructor,
 	object_cache_reclaimer reclaimer)
@@ -547,13 +516,13 @@
 
 	HashedObjectCache *cache = new (buffer) HashedObjectCache();
 
-	if (object_cache_init(cache, name, object_size, alignment, maximum, flags,
+	if (object_cache_init(cache, name, objectSize, alignment, maximum, flags,
 		cookie, constructor, destructor, reclaimer) &lt; B_OK) {
 		delete_cache(cache);
 		return NULL;
 	}
 
-	cache-&gt;slab_size = max_c(16 * B_PAGE_SIZE, 8 * object_size);
+	cache-&gt;slab_size = max_c(16 * B_PAGE_SIZE, 8 * objectSize);
 	cache-&gt;lower_boundary = __fls0(cache-&gt;object_size);
 
 	return cache;
@@ -578,9 +547,11 @@
 {
 	if (object_size == 0)
 		return NULL;
-	else if (object_size &lt;= 256)
+	
+	if (object_size &lt;= 256) {
 		return create_small_object_cache(name, object_size, alignment,
 			maximum, flags, cookie, constructor, destructor, reclaimer);
+	}
 
 	return create_hashed_object_cache(name, object_size, alignment,
 		maximum, flags, cookie, constructor, destructor, reclaimer);
@@ -707,11 +678,12 @@
 
 
 static status_t
-object_cache_reserve_internal(object_cache *cache, size_t object_count,
+object_cache_reserve_internal(object_cache *cache, size_t objectCount,
 	uint32 flags)
 {
-	size_t numBytes = object_count * cache-&gt;object_size;
+	size_t numBytes = objectCount * cache-&gt;object_size;
 	size_t slabCount = ((numBytes - 1) / cache-&gt;slab_size) + 1;
+dprintf(&quot;RESERVE INTERNAL %lu\n&quot;, slabCount);
 
 	while (slabCount &gt; 0) {
 		slab *newSlab = cache-&gt;CreateSlab(flags);
@@ -728,13 +700,13 @@
 
 
 status_t
-object_cache_reserve(object_cache *cache, size_t object_count, uint32 flags)
+object_cache_reserve(object_cache *cache, size_t objectCount, uint32 flags)
 {
-	if (object_count == 0)
+	if (objectCount == 0)
 		return B_OK;
 
 	BenaphoreLocker _(cache-&gt;lock);
-	return object_cache_reserve_internal(cache, object_count, flags);
+	return object_cache_reserve_internal(cache, objectCount, flags);
 }
 
 
@@ -813,9 +785,9 @@
 
 
 static inline slab *
-slab_in_pages(const void *pages, size_t slab_size)
+slab_in_pages(const void *pages, size_t slabSize)
 {
-	return (slab *)(((uint8 *)pages) + slab_size - sizeof(slab));
+	return (slab *)(((uint8 *)pages) + slabSize - sizeof(slab));
 }
 
 
@@ -844,7 +816,6 @@
 		return NULL;
 
 	void *pages;
-
 	if (allocate_pages(this, &amp;pages, flags) &lt; B_OK)
 		return NULL;
 
@@ -1281,12 +1252,13 @@
 	sInitialBegin = (uint8 *)initialBase;
 	sInitialLimit = sInitialBegin + initialSize;
 	sInitialPointer = sInitialBegin;
+	sDuringBoot = true;
 
 	sKernelArgs = args;
 
 	new (&amp;sObjectCaches) ObjectCacheList();
 
-	block_allocator_init_boot();
+	block_allocator_init();
 
 	add_debugger_command(&quot;slabs&quot;, dump_slabs, &quot;list all object caches&quot;);
 	add_debugger_command(&quot;cache_info&quot;, dump_cache_info,
@@ -1307,10 +1279,12 @@
 		object_cache *cache = it.Next();
 		if (object_cache_init_locks(cache) &lt; B_OK)
 			panic(&quot;slab_init: failed to create sems&quot;);
-		if (cache-&gt;allocate_pages == early_allocate_pages)
-			object_cache_commit_pre_pages(cache);
+
+		register_low_memory_handler(object_cache_low_memory, cache, 5);
+		object_cache_commit_pre_pages(cache);
 	}
 
-	block_allocator_init_rest();
+	sDuringBoot = false;
+	block_allocator_init_post_sem();
 }
 

Modified: haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/allocator.cpp
===================================================================
--- haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/allocator.cpp	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/allocator.cpp	2008-01-04 17:22:51 UTC (rev 23246)
@@ -1,18 +1,21 @@
 /*
- * Copyright 2007, Hugo Santos. All Rights Reserved.
+ * Copyright 2007, Axel D&#246;rfler, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de.</A> All rights reserved.
+ * Copyright 2007, Hugo Santos, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">hugosantos at gmail.com.</A> All Rights Reserved.
+ *
  * Distributed under the terms of the MIT License.
- *
- * Authors:
- *      Hugo Santos, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">hugosantos at gmail.com</A>
  */
 
+
 #include &lt;Slab.h&gt;
 
 #include &quot;slab_private.h&quot;
 
-#include &lt;kernel.h&gt; // for ROUNDUP
+#include &lt;int.h&gt;
+#include &lt;kernel.h&gt;
+#include &lt;vm.h&gt;
 
 #include &lt;stdio.h&gt;
+#include &lt;stdlib.h&gt;
 #include &lt;string.h&gt;
 
 #define DEBUG_ALLOCATOR
@@ -41,6 +44,7 @@
 
 struct area_boundary_tag {
 	area_id area;
+	size_t	area_size;
 	boundary_tag tag;
 };
 
@@ -72,33 +76,157 @@
 }
 
 
-void *
-block_alloc(size_t size)
+static void
+block_create_cache(size_t index, bool boot)
 {
+	char name[32];
+	snprintf(name, sizeof(name), &quot;block cache: %lu&quot;, kBlockSizes[index]);
+
+	sBlockCaches[index] = create_object_cache_etc(name, kBlockSizes[index],
+		0, 0, 0, NULL, NULL, NULL, NULL);
+	if (sBlockCaches[index] == NULL)
+		panic(&quot;allocator: failed to init block cache&quot;);
+
+	sBlockCacheWaste[index] = 0;
+}
+
+
+static int
+show_waste(int argc, char *argv[])
+{
+	size_t total = 0;
+
+	for (size_t index = 0; index &lt; kNumBlockSizes; index++) {
+		if (sBlockCacheWaste[index] &gt; 0) {
+			kprintf(&quot;%lu: %lu\n&quot;, kBlockSizes[index], sBlockCacheWaste[index]);
+			total += sBlockCacheWaste[index];
+		}
+	}
+
+	kprintf(&quot;total waste: %lu\n&quot;, total);
+
+	return 0;
+}
+
+
+void
+block_allocator_init()
+{
+	for (int index = 0; kBlockSizes[index] != 0; index++) {
+		block_create_cache(index, true);
+	}
+dprintf(&quot;HELLO\n&quot;);
+	object_cache_reserve(sBlockCaches[1], 50, 0);
+	object_cache_reserve(sBlockCaches[2], 50, 0);
+	object_cache_reserve(sBlockCaches[13], 50, 0);
+dprintf(&quot;HELLO usta\n&quot;);
+
+	add_debugger_command(&quot;show_waste&quot;, show_waste,
+		&quot;show cache allocator's memory waste&quot;);
+}
+
+
+void
+block_allocator_init_post_sem()
+{
+#ifdef TEST_ALL_CACHES_DURING_BOOT
+	for (int index = 0; kBlockSizes[index] != 0; index++) {
+		block_free(block_alloc(kBlockSizes[index] - sizeof(boundary_tag)));
+	}
+#endif
+}
+
+
+//	#pragma mark -
+
+
+extern &quot;C&quot; void *
+malloc_early(struct kernel_args *args, size_t size, size_t *_areaSize)
+{
+	size_t areaSize = ROUNDUP(size + sizeof(area_boundary_tag), B_PAGE_SIZE);
+
+	addr_t address = vm_allocate_early(args, areaSize, areaSize,
+		B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA);
+	if (address == NULL)
+		return NULL;
+
+	area_boundary_tag *areaTag = (area_boundary_tag *)address;
+	areaTag-&gt;area = -1;
+dprintf(&quot;area tag %p\n&quot;, areaTag);
+	areaTag-&gt;area_size = areaSize;
+	areaTag-&gt;tag.size = size;
+	*_areaSize = areaSize;
+
+#ifdef DEBUG_ALLOCATOR
+	areaTag-&gt;tag.magic = kBoundaryMagic;
+#endif
+
+	return areaTag + 1;
+}
+
+
+extern &quot;C&quot; void
+malloc_early_create_area(void *address, const char *name)
+{
+	area_boundary_tag *areaTag = (area_boundary_tag *)((uint8 *)address
+		- sizeof(area_boundary_tag));
+dprintf(&quot;2. area tag %p\n&quot;, areaTag);
+
+	address = (void *)areaTag;
+	areaTag-&gt;area = create_area(&quot;page cache table&quot;, &amp;address, B_EXACT_ADDRESS,
+		areaTag-&gt;area_size, B_ALREADY_WIRED,
+		B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA);
+dprintf(&quot;************************ ASDFSF ***********************\n&quot;);
+}
+
+
+extern &quot;C&quot; void *
+memalign(size_t alignment, size_t size)
+{
+dprintf(&quot;memalign(alignment %lu, size %lu)\n&quot;, alignment, size);
+	if (!kernel_startup &amp;&amp; !are_interrupts_enabled())
+		panic(&quot;realloc(): called with interrupts disabled\n&quot;);
+
+	// ToDo: that code &quot;aligns&quot; the buffer because the bins are always
+	//	aligned on their bin size
+//	if (size &lt; alignment)
+//		size = alignment;
+	if (alignment != 0)
+		panic(&quot;alignment not yet supported!&quot;);
+
 	int index = size_to_index(size + sizeof(boundary_tag));
-
-	void *block;
+dprintf(&quot;index: %d, size %lu\n&quot;, index, size);
+	void *address;
 	boundary_tag *tag;
 
 	if (index &lt; 0) {
 		void *pages;
-		area_id area = create_area(&quot;alloc'ed block&quot;, &amp;pages,
+		area_id area = create_area(&quot;heap block&quot;, &amp;pages,
 			B_ANY_KERNEL_ADDRESS, ROUNDUP(size + sizeof(area_boundary_tag),
-				B_PAGE_SIZE), B_NO_LOCK, B_READ_AREA | B_WRITE_AREA);
+				B_PAGE_SIZE), B_FULL_LOCK,
+				B_KERNEL_READ_AREA | B_KERNEL_WRITE_AREA);
+dprintf(&quot;new area %ld, pages %p\n&quot;, area, pages);
 		if (area &lt; B_OK)
 			return NULL;
 
 		area_boundary_tag *areaTag = (area_boundary_tag *)pages;
 		areaTag-&gt;area = area;
+		areaTag-&gt;area_size = ROUNDUP(size + sizeof(area_boundary_tag),
+			B_PAGE_SIZE);
 		tag = &amp;areaTag-&gt;tag;
-		block = areaTag + 1;
+		address = areaTag + 1;
 	} else {
+		if (sBlockCaches[index] == NULL) {
+			panic(&quot;HERE&quot;);
+dprintf(&quot;no init!\n&quot;);
+			return NULL;
+		}
 		tag = (boundary_tag *)object_cache_alloc(sBlockCaches[index], 0);
 		if (tag == NULL)
 			return NULL;
 		atomic_add(&amp;sBlockCacheWaste[index], kBlockSizes[index] - size
 			- sizeof(boundary_tag));
-		block = tag + 1;
+		address = tag + 1;
 	}
 
 	tag-&gt;size = size;
@@ -107,14 +235,21 @@
 	tag-&gt;magic = kBoundaryMagic;
 #endif
 
-	return block;
+	return address;
 }
 
 
-void
-block_free(void *block)
+extern &quot;C&quot; void *
+malloc(size_t size)
 {
-	boundary_tag *tag = (boundary_tag *)(((uint8 *)block)
+	return memalign(0, size);
+}
+
+
+extern &quot;C&quot; void
+free(void *address)
+{
+	boundary_tag *tag = (boundary_tag *)(((uint8 *)address)
 		- sizeof(boundary_tag));
 
 #ifdef DEBUG_ALLOCATOR
@@ -125,7 +260,7 @@
 	int index = size_to_index(tag-&gt;size + sizeof(boundary_tag));
 
 	if (index &lt; 0) {
-		area_boundary_tag *areaTag = (area_boundary_tag *)(((uint8 *)block)
+		area_boundary_tag *areaTag = (area_boundary_tag *)((uint8 *)address
 			- sizeof(area_boundary_tag));
 		delete_area(areaTag-&gt;area);
 	} else {
@@ -136,57 +271,67 @@
 }
 
 
-static void
-block_create_cache(size_t index, bool boot)
+extern &quot;C&quot; void *
+realloc(void *address, size_t newSize)
 {
-	char name[32];
-	snprintf(name, sizeof(name), &quot;block cache: %lu&quot;, kBlockSizes[index]);
+	void *newAddress = NULL;
+	size_t oldSize = 0;
 
-	sBlockCaches[index] = create_object_cache_etc(name, kBlockSizes[index],
-		0, 0, boot ? CACHE_DURING_BOOT : 0, NULL, NULL, NULL, NULL);
-	if (sBlockCaches[index] == NULL)
-		panic(&quot;allocator: failed to init block cache&quot;);
+	if (!kernel_startup &amp;&amp; !are_interrupts_enabled())
+		panic(&quot;realloc(): called with interrupts disabled\n&quot;);
 
-	sBlockCacheWaste[index] = 0;
-}
+	if (newSize == 0) {
+		free(address);
+		return NULL;
+	}
 
+	// find out the size of the old allocation first
 
-static int
-show_waste(int argc, char *argv[])
-{
-	size_t total = 0;
+	if (address != NULL) {
+		boundary_tag *tag = (boundary_tag *)((uint8 *)address
+			- sizeof(boundary_tag));
+		int index = size_to_index(tag-&gt;size + sizeof(boundary_tag));
 
-	for (size_t index = 0; index &lt; kNumBlockSizes; index++) {
-		if (sBlockCacheWaste[index] &gt; 0) {
-			kprintf(&quot;%lu: %lu\n&quot;, kBlockSizes[index], sBlockCacheWaste[index]);
-			total += sBlockCacheWaste[index];
-		}
+		if (index &lt; 0) {
+			// it was an allocated area
+			area_boundary_tag *areaTag = (area_boundary_tag *)((uint8 *)address
+				- sizeof(area_boundary_tag));
+			if (areaTag-&gt;area_size - sizeof(area_boundary_tag) &gt; newSize) {
+				tag-&gt;size = newSize;
+				return address;
+			} else
+				oldSize = tag-&gt;size;
+		} else if (kBlockSizes[index] &gt;= newSize) {
+			tag-&gt;size = newSize;
+			return address;
+		} else
+			oldSize = tag-&gt;size;
 	}
 
-	kprintf(&quot;total waste: %lu\n&quot;, total);
+	// we need to allocate new space
 
-	return 0;
-}
+	newAddress = malloc(newSize);
+	if (newAddress == NULL)
+		return NULL;
 
+	// copy the old data and free the old allocation
+	if (address != NULL) {
+		// we do have the maxSize of the bin at this point
+		memcpy(newAddress, address, min_c(oldSize, newSize));
+		free(address);
+	}
 
-void
-block_allocator_init_boot()
-{
-	for (int index = 0; kBlockSizes[index] != 0; index++)
-		block_create_cache(index, true);
-
-	add_debugger_command(&quot;show_waste&quot;, show_waste,
-		&quot;show cache allocator's memory waste&quot;);
+	return newAddress;
 }
 
 
-void
-block_allocator_init_rest()
+extern &quot;C&quot; void *
+calloc(size_t numElements, size_t size)
 {
-#ifdef TEST_ALL_CACHES_DURING_BOOT
-	for (int index = 0; kBlockSizes[index] != 0; index++) {
-		block_free(block_alloc(kBlockSizes[index] - sizeof(boundary_tag)));
-	}
-#endif
+	void *address = malloc(numElements * size);
+	if (address != NULL)
+		memset(address, 0, numElements * size);
+
+	return address;
 }
 

Modified: haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/slab_private.h
===================================================================
--- haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/slab_private.h	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/src_system_kernel/slab/slab_private.h	2008-01-04 17:22:51 UTC (rev 23246)
@@ -1,19 +1,15 @@
 /*
  * Copyright 2007, Hugo Santos. All Rights Reserved.
  * Distributed under the terms of the MIT License.
- *
- * Authors:
- *      Hugo Santos, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">hugosantos at gmail.com</A>
  */
 #ifndef _SLAB_PRIVATE_H_
 #define _SLAB_PRIVATE_H_
 
+
 #include &lt;stddef.h&gt;
 
-void *block_alloc(size_t size);
-void block_free(void *block);
-void block_allocator_init_boot();
-void block_allocator_init_rest();
 
-#endif
+void block_allocator_init();
+void block_allocator_init_post_sem();
 
+#endif	/* _SLAB_PRIVATE_H_ */

Modified: haiku/branches/developer/axeld/slab_heap/src_system_kernel/util/khash.c
===================================================================
--- haiku/branches/developer/axeld/slab_heap/src_system_kernel/util/khash.c	2008-01-04 17:18:34 UTC (rev 23245)
+++ haiku/branches/developer/axeld/slab_heap/src_system_kernel/util/khash.c	2008-01-04 17:22:51 UTC (rev 23246)
@@ -51,7 +51,15 @@
 };
 
 
-static uint32
+static inline void *
+next_element(hash_table *table, void *element)
+{
+	// ToDo: should we use this instead of the NEXT() macro?
+	return (void *)(*(unsigned long *)NEXT_ADDR(table, element));
+}
+
+
+uint32
 get_prime_table_size(uint32 size)
 {
 	int i;
@@ -64,26 +72,16 @@
 }
 
 
-static inline void *
-next_element(hash_table *table, void *element)
-{
-	// ToDo: should we use this instead of the NEXT() macro?
-	return (void *)(*(unsigned long *)NEXT_ADDR(table, element));
-}
-
-
 struct hash_table *
-hash_init(uint32 table_size, int next_ptr_offset,
-	int compare_func(void *e, const void *key),
-	uint32 hash_func(void *e, const void *key, uint32 range))
+hash_init_etc(void *table, uint32 tableSize, uint32 nextOffset,
+	int compareFunc(void *e, const void *key),
+	uint32 hashFunc(void *e, const void *key, uint32 range))
 {
 	struct hash_table *t;
 	unsigned int i;
 
-	table_size = get_prime_table_size(table_size);
-
-	if (compare_func == NULL || hash_func == NULL) {
-		dprintf(&quot;hash_init() called with NULL function pointer\n&quot;);
+	if (compareFunc == NULL || hashFunc == NULL || table == NULL) {
+		dprintf(&quot;hash_init_etc() called with NULL pointer\n&quot;);
 		return NULL;
 	}
 
@@ -91,38 +89,54 @@
 	if (t == NULL)
 		return NULL;
 
-	t-&gt;table = (struct hash_element **)malloc(sizeof(void *) * table_size);
-	if (t-&gt;table == NULL) {
-		free(t);
-		return NULL;
-	}
-
-	for (i = 0; i &lt; table_size; i++)
-		t-&gt;table[i] = NULL;
-
-	t-&gt;table_size = table_size;
-	t-&gt;next_ptr_offset = next_ptr_offset;
+	t-&gt;table = table;
+	t-&gt;table_size = tableSize;
+	t-&gt;next_ptr_offset = nextOffset;
 	t-&gt;flags = 0;
 	t-&gt;num_elements = 0;
-	t-&gt;compare_func = compare_func;
-	t-&gt;hash_func = hash_func;
+	t-&gt;compare_func = compareFunc;
+	t-&gt;hash_func = hashFunc;
 
-	TRACE((&quot;hash_init: created table %p, next_ptr_offset %d, compare_func %p, hash_func %p\n&quot;,
-		t, next_ptr_offset, compare_func, hash_func));
+	TRACE((&quot;hash_init_etc: created table %p, next_ptr_offset %d, compare_func &quot;
+		&quot;%p, hash_func %p\n&quot;, t, nextOffset, compareFunc, hashFunc));
 
 	return t;
 }
 
 
-int
+struct hash_table *
+hash_init(uint32 tableSize, uint32 nextOffset,
+	int compareFunc(void *e, const void *key),
+	uint32 hashFunc(void *e, const void *key, uint32 range))
+{
+	struct hash_table *hashTable;
+	void *table;
+
+	tableSize = get_prime_table_size(tableSize);
+
+	table = (struct hash_element **)malloc(sizeof(void *) * tableSize);
+	if (table == NULL)
+		return NULL;
+
+	hashTable = hash_init_etc(table, tableSize, nextOffset, compareFunc,
+		hashFunc);
+	if (hashTable == NULL) {
+		free(table);
+		return NULL;
+	}
+
+	memset(table, 0, sizeof(void *) * tableSize);
+	return hashTable;
+}
+
+
+void
 hash_uninit(struct hash_table *table)
 {
 	ASSERT(table-&gt;num_elements == 0);
 
 	free(table-&gt;table);
 	free(table);

[... truncated: 200 lines follow ...]

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="005189.html">[Haiku-commits] r23245 - haiku/branches/developer/axeld/slab_heap
</A></li>
	<LI>Next message: <A HREF="005192.html">[Haiku-commits] r23247 -	haiku/trunk/src/add-ons/kernel/busses/scsi/ahci
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#5190">[ date ]</a>
              <a href="thread.html#5190">[ thread ]</a>
              <a href="subject.html#5190">[ subject ]</a>
              <a href="author.html#5190">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
