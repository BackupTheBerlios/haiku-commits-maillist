<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r28111 -	haiku/trunk/src/add-ons/kernel/file_systems/bfs
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2008-October/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r28111%20-%0A%09haiku/trunk/src/add-ons/kernel/file_systems/bfs&In-Reply-To=%3C200810142214.m9EMEBWb001816%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="012723.html">
   <LINK REL="Next"  HREF="012728.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r28111 -	haiku/trunk/src/add-ons/kernel/file_systems/bfs</H1>
    <B>axeld at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r28111%20-%0A%09haiku/trunk/src/add-ons/kernel/file_systems/bfs&In-Reply-To=%3C200810142214.m9EMEBWb001816%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r28111 -	haiku/trunk/src/add-ons/kernel/file_systems/bfs">axeld at mail.berlios.de
       </A><BR>
    <I>Wed Oct 15 00:14:11 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="012723.html">[Haiku-commits] r28110 - haiku/trunk/src/tools/vmdkimage
</A></li>
        <LI>Next message: <A HREF="012728.html">[Haiku-commits] r28111 -	haiku/trunk/src/add-ons/kernel/file_systems/bfs
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12724">[ date ]</a>
              <a href="thread.html#12724">[ thread ]</a>
              <a href="subject.html#12724">[ subject ]</a>
              <a href="author.html#12724">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: axeld
Date: 2008-10-15 00:14:10 +0200 (Wed, 15 Oct 2008)
New Revision: 28111
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=28111&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=28111&amp;view=rev</A>

Modified:
   haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.cpp
   haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.h
   haiku/trunk/src/add-ons/kernel/file_systems/bfs/Debug.cpp
Log:
* Each allocation group now lazily maintains the largest free block separately,
  so that allocations can be directly fulfilled from that block without having
  to search for it.
* This should further improve the allocator's performance, but it could need
  more tuning (ie. when to rebuild the free block).
* Added debugging code to check if the largest block is maintained correctly;
  it's currently turned on (DEBUG_ALLOCATION_GROUPS) which makes allocations
  actually pretty slow - I'll disable it again after it has been tested a bit
  more.
* Added a &quot;bfs_allocator_blocks&quot; KDL command that allows you to show all
  tracing entries that affect a specific block (only available if BFS has
  been compiled with tracing support).


Modified: haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.cpp
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.cpp	2008-10-14 21:47:05 UTC (rev 28110)
+++ haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.cpp	2008-10-14 22:14:10 UTC (rev 28111)
@@ -35,7 +35,7 @@
 // be improved a lot. Furthermore, the allocation policies used here should
 // have some real world tests.
 
-#if BFS_TRACING &amp;&amp; !defined(BFS_SHELL) &amp;&amp; !defined(_BOOT_MODE)
+#if BFS_TRACING &amp;&amp; !defined(BFS_SHELL)
 namespace BFSBlockTracing {
 
 class Allocate : public AbstractTraceEntry {
@@ -53,6 +53,8 @@
 			fRun.Start(), fRun.Length());
 	}
 
+	const block_run&amp; Run() const { return fRun; }
+
 private:
 	block_run	fRun;
 };
@@ -72,6 +74,8 @@
 			fRun.Start(), fRun.Length());
 	}
 
+	const block_run&amp; Run() const { return fRun; }
+
 private:
 	block_run	fRun;
 };
@@ -128,7 +132,13 @@
 #	define T(x) ;
 #endif
 
+#ifdef DEBUG_ALLOCATION_GROUPS
+#	define CHECK_ALLOCATION_GROUP(group) _CheckGroup(group)
+#else
+#	define CHECK_ALLOCATION_GROUP(group) ;
+#endif
 
+
 struct check_cookie {
 	check_cookie() {}
 
@@ -184,10 +194,12 @@
 	uint32	fNumBits;
 	uint32	fNumBlocks;
 	int32	fStart;
-	int32	fFirstFree, fLargest, fLargestFirst;
-		// TODO: fLargest &amp; fLargestFirst are not maintained
-		// (and therefore used) yet!
+	int32	fFirstFree;
 	int32	fFreeBits;
+
+	int32	fLargestStart;
+	int32	fLargestLength;
+	bool	fLargestValid;
 };
 
 
@@ -252,7 +264,8 @@
 #endif
 
 	if (uint32(start + numBlocks) &gt; fNumBits) {
-		FATAL((&quot;Allocation::Allocate(): tried to allocate too many blocks: %u (numBlocks = %u)!\n&quot;, numBlocks, (unsigned)fNumBits));
+		FATAL((&quot;Allocation::Allocate(): tried to allocate too many blocks: %u &quot;
+			&quot;(numBlocks = %u)!\n&quot;, numBlocks, (unsigned)fNumBits));
 		DIE((&quot;Allocation::Allocate(): tried to allocate too many blocks&quot;));
 	}
 
@@ -268,7 +281,8 @@
 #ifdef DEBUG
 		// check for already set blocks
 		if (HOST_ENDIAN_TO_BFS_INT32(mask) &amp; ((uint32*)fBlock)[block]) {
-			FATAL((&quot;AllocationBlock::Allocate(): some blocks are already allocated, start = %u, numBlocks = %u\n&quot;, start, numBlocks));
+			FATAL((&quot;AllocationBlock::Allocate(): some blocks are already &quot;
+				&quot;allocated, start = %u, numBlocks = %u\n&quot;, start, numBlocks));
 			DEBUGGER((&quot;blocks already set!&quot;));
 		}
 #endif
@@ -290,7 +304,8 @@
 #endif
 
 	if (uint32(start + numBlocks) &gt; fNumBits) {
-		FATAL((&quot;Allocation::Free(): tried to free too many blocks: %u (numBlocks = %u)!\n&quot;, numBlocks, (unsigned)fNumBits));
+		FATAL((&quot;Allocation::Free(): tried to free too many blocks: %u &quot;
+			&quot;(numBlocks = %u)!\n&quot;, numBlocks, (unsigned)fNumBits));
 		DIE((&quot;Allocation::Free(): tried to free too many blocks&quot;));
 	}
 
@@ -317,9 +332,8 @@
 AllocationGroup::AllocationGroup()
 	:
 	fFirstFree(-1),
-	fLargest(-1),
-	fLargestFirst(-1),
-	fFreeBits(0)
+	fFreeBits(0),
+	fLargestValid(false)
 {
 }
 
@@ -333,9 +347,10 @@
 	if (fFirstFree == -1)
 		fFirstFree = start;
 
-	if (fLargest &lt; blocks) {
-		fLargest = blocks;
-		fLargestFirst = start;
+	if (!fLargestValid || fLargestLength &lt; blocks) {
+		fLargestStart = start;
+		fLargestLength = blocks;
+		fLargestValid = true;
 	}
 
 	fFreeBits += blocks;
@@ -361,6 +376,21 @@
 		fFirstFree = start + length;
 	fFreeBits -= length;
 
+	if (fLargestValid) {
+		if (fLargestStart == start) {
+			fLargestStart += length;
+			fLargestLength -= length;
+		} else if (start &gt; fLargestStart
+			&amp;&amp; start &lt; fLargestStart + fLargestLength) {
+			fLargestLength = start - fLargestStart;
+		}
+		if (fLargestLength &lt; fLargestStart
+			|| fLargestLength
+					&lt; (int32)fNumBits - (fLargestStart + fLargestLength)) {
+			fLargestValid = false;
+		}
+	}
+
 	Volume* volume = transaction.GetVolume();
 
 	// calculate block in the block bitmap and position within
@@ -371,8 +401,10 @@
 	AllocationBlock cached(volume);
 
 	while (length &gt; 0) {
-		if (cached.SetToWritable(transaction, *this, block) &lt; B_OK)
+		if (cached.SetToWritable(transaction, *this, block) &lt; B_OK) {
+			fLargestValid = false;
 			RETURN_ERROR(B_IO_ERROR);
+		}
 
 		uint32 numBlocks = length;
 		if (start + numBlocks &gt; cached.NumBlockBits())
@@ -407,6 +439,20 @@
 		fFirstFree = start;
 	fFreeBits += length;
 
+	// The range to be freed cannot be part of the valid largest range
+	ASSERT(!fLargestValid || start &lt; fLargestStart
+		|| start &gt; fLargestStart + fLargestLength);
+
+	if (fLargestValid
+		&amp;&amp; (start + length == fLargestStart
+			|| fLargestStart + fLargestLength == start
+			|| (start &lt; fLargestStart &amp;&amp; fLargestStart &gt; fLargestLength)
+			|| (start &gt; fLargestStart
+				&amp;&amp; (int32)fNumBits - (fLargestStart + fLargestLength)
+						&gt; fLargestLength))) {
+		fLargestValid = false;
+	}
+
 	Volume* volume = transaction.GetVolume();
 
 	// calculate block in the block bitmap and position within
@@ -518,8 +564,9 @@
 			fGroups[i].fNumBlocks = blocks;
 		}
 		fGroups[i].fStart = offset;
-		fGroups[i].fFirstFree = fGroups[i].fLargestFirst = 0;
-		fGroups[i].fFreeBits = fGroups[i].fLargest = fGroups[i].fNumBits;
+		fGroups[i].fFirstFree = fGroups[i].fLargestStart = 0;
+		fGroups[i].fFreeBits = fGroups[i].fLargestLength = fGroups[i].fNumBits;
+		fGroups[i].fLargestValid = true;
 
 		offset += blocks;
 	}
@@ -609,7 +656,8 @@
 	if (allocator-&gt;CheckBlockRun(block_run::Run(0, 0, reservedBlocks)) &lt; B_OK) {
 		Transaction transaction(volume, 0);
 		if (groups[0].Allocate(transaction, 0, reservedBlocks) &lt; B_OK) {
-			FATAL((&quot;could not allocate reserved space for block bitmap/log!\n&quot;));
+			FATAL((&quot;could not allocate reserved space for block &quot;
+				&quot;bitmap/log!\n&quot;));
 			volume-&gt;Panic();
 		} else {
 			FATAL((&quot;space for block bitmap or log area was not reserved!\n&quot;));
@@ -622,7 +670,8 @@
 	if (volume-&gt;UsedBlocks() != usedBlocks) {
 		// If the disk in a dirty state at mount time, it's
 		// normal that the values don't match
-		INFORM((&quot;volume reports %Ld used blocks, correct is %Ld\n&quot;, volume-&gt;UsedBlocks(), usedBlocks));
+		INFORM((&quot;volume reports %Ld used blocks, correct is %Ld\n&quot;,
+			volume-&gt;UsedBlocks(), usedBlocks));
 		volume-&gt;SuperBlock().used_blocks = HOST_ENDIAN_TO_BFS_INT64(usedBlocks);
 	}
 
@@ -647,7 +696,8 @@
 	if (maximum == 0)
 		return B_BAD_VALUE;
 
-	FUNCTION_START((&quot;group = %ld, start = %u, maximum = %u, minimum = %u\n&quot;, group, start, maximum, minimum));
+	FUNCTION_START((&quot;group = %ld, start = %u, maximum = %u, minimum = %u\n&quot;,
+		group, start, maximum, minimum));
 
 	AllocationBlock cached(fVolume);
 	MutexLocker lock(fLock);
@@ -659,8 +709,9 @@
 	int32 bestStart = -1;
 	int32 bestLength = -1;
 
-	for (int32 i = 0; i &lt; fNumGroups; i++, group++, start = 0) {
+	for (int32 i = 0; i &lt; fNumGroups + 1; i++, group++, start = 0) {
 		group = group % fNumGroups;
+		CHECK_ALLOCATION_GROUP(group);
 
 		if (start &gt;= fGroups[group].NumBits() || fGroups[group].IsFull())
 			continue;
@@ -669,18 +720,43 @@
 		// group or already smaller than the minimum
 		// TODO: disabled because it's currently not maintained after the first
 		// allocation
+
 		//if (numBlocks &gt; fGroups[group].fLargest)
 		//	continue;
 
 		if (start &lt; fGroups[group].fFirstFree)
 			start = fGroups[group].fFirstFree;
 
+		if (fGroups[group].fLargestValid) {
+			if (fGroups[group].fLargestLength &lt; bestLength)
+				continue;
+
+			if (fGroups[group].fLargestStart &gt;= start) {
+				if (fGroups[group].fLargestLength &gt;= bestLength) {
+					bestGroup = group;
+					bestStart = fGroups[group].fLargestStart;
+					bestLength = fGroups[group].fLargestLength;
+
+					if (bestLength &gt;= maximum)
+						break;
+				}
+
+				// We know everything about this group we have to, let's skip
+				// to the next
+				continue;
+			}
+		}
+
 		// There may be more than one block per allocation group - and
 		// we iterate through it to find a place for the allocation.
 		// (one allocation can't exceed one allocation group)
 
 		uint32 block = start / (fVolume-&gt;BlockSize() &lt;&lt; 3);
 		int32 range = 0, rangeStart = 0;
+		int32 groupLargestStart = -1;
+		int32 groupLargest = -1;
+		int32 current = block * bitsPerFullBlock + start;
+		bool canUseLargest = start == 0;
 
 		for (; block &lt; fGroups[group].NumBlocks(); block++) {
 			if (cached.SetTo(fGroups[group], block) &lt; B_OK)
@@ -695,7 +771,7 @@
 				if (!cached.IsUsed(bit)) {
 					if (range == 0) {
 						// start new range
-						rangeStart = block * bitsPerFullBlock + bit;
+						rangeStart = current;
 					}
 
 					// have we found a range large enough to hold numBlocks?
@@ -706,26 +782,61 @@
 						break;
 					}
 				} else {
-					// end of a range
-					if (range &gt; bestLength) {
-						bestGroup = group;
-						bestStart = rangeStart;
-						bestLength = range;
+					if (range) {
+						// end of a range
+						if (range &gt; bestLength) {
+							bestGroup = group;
+							bestStart = rangeStart;
+							bestLength = range;
+						}
+						if (range &gt; groupLargest) {
+							groupLargestStart = rangeStart;
+							groupLargest = range;
+						}
+						range = 0;
 					}
-					range = 0;
+					if ((int32)fGroups[group].NumBits() - current
+							&lt;= groupLargest) {
+						// We can't find a bigger block in this group anymore,
+						// let's skip the rest.
+						block = fGroups[group].NumBlocks();
+						break;
+					}
 				}
+				current++;
 			}
 
 			T(Block(&quot;alloc-out&quot;, block, cached.Block(),
 				fVolume-&gt;BlockSize(), group, rangeStart));
 
-			if (bestLength &gt;= maximum)
+			if (bestLength &gt;= maximum) {
+				canUseLargest = false;
 				break;
+			}
 
 			// start from the beginning of the next block
 			start = 0;
 		}
 
+		if (current == fGroups[group].NumBits()) {
+			if (range &gt; bestLength) {
+				bestGroup = group;
+				bestStart = rangeStart;
+				bestLength = range;
+			}
+			if (canUseLargest &amp;&amp; range &gt; groupLargest) {
+				groupLargestStart = rangeStart;
+				groupLargest = range;
+			}
+		}
+
+		if (canUseLargest &amp;&amp; !fGroups[group].fLargestValid
+			&amp;&amp; groupLargest &gt;= 0) {
+			fGroups[group].fLargestStart = groupLargestStart;
+			fGroups[group].fLargestLength = groupLargest;
+			fGroups[group].fLargestValid = true;
+		}
+
 		if (bestLength &gt;= maximum)
 			break;
 	}
@@ -734,11 +845,15 @@
 	// write the updated block bitmap back to disk
 	if (bestLength &lt; minimum)
 		return B_DEVICE_FULL;
+	if (bestLength &gt; maximum)
+		bestLength = maximum;
 
 	if (fGroups[bestGroup].Allocate(transaction, bestStart, bestLength)
 			&lt; B_OK)
 		RETURN_ERROR(B_IO_ERROR);
 
+	CHECK_ALLOCATION_GROUP(bestGroup);
+
 	run.allocation_group = HOST_ENDIAN_TO_BFS_INT32(bestGroup);
 	run.start = HOST_ENDIAN_TO_BFS_INT16(bestStart);
 	run.length = HOST_ENDIAN_TO_BFS_INT16(bestLength);
@@ -872,9 +987,13 @@
 		return B_BAD_DATA;
 #endif
 
+	CHECK_ALLOCATION_GROUP(group);
+
 	if (fGroups[group].Free(transaction, start, length) &lt; B_OK)
 		RETURN_ERROR(B_IO_ERROR);
 
+	CHECK_ALLOCATION_GROUP(group);
+
 #ifdef DEBUG
 	if (CheckBlockRun(run, NULL, NULL, false) &lt; B_OK) {
 		DEBUGGER((&quot;CheckBlockRun() reports allocated blocks (which were just &quot;
@@ -895,6 +1014,76 @@
 }
 
 
+void
+BlockAllocator::_CheckGroup(int32 groupIndex) const
+{
+	AllocationBlock cached(fVolume);
+	ASSERT_LOCKED_MUTEX(&amp;fLock);
+
+	AllocationGroup&amp; group = fGroups[groupIndex];
+
+	int32 currentStart = 0, currentLength = 0;
+	int32 firstFree = -1;
+	int32 largestStart = -1;
+	int32 largestLength = 0;
+	int32 currentBit = 0;
+
+	for (uint32 block = 0; block &lt; group.NumBlocks(); block++) {
+		if (cached.SetTo(group, block) &lt; B_OK) {
+			panic(&quot;setting group block %d failed\n&quot;, (int)block);
+			return;
+		}
+
+		for (uint32 bit = 0; bit &lt; cached.NumBlockBits(); bit++) {
+			if (!cached.IsUsed(bit)) {
+				if (firstFree &lt; 0) {
+					firstFree = currentBit;
+					if (!group.fLargestValid) {
+						if (firstFree &lt; group.fFirstFree) {
+							// mostly harmless but noteworthy
+							dprintf(&quot;group %d first free too late\n&quot;,
+								(int)groupIndex);
+						}
+						return;
+					}
+				}
+
+				if (currentLength == 0) {
+					// start new range
+					currentStart = currentBit;
+				}
+				currentLength++;
+			} else if (currentLength) {
+				// end of a range
+				if (currentLength &gt; largestLength) {
+					largestStart = currentStart;
+					largestLength = currentLength;
+				}
+				currentLength = 0;
+			}
+			currentBit++;
+		}
+	}
+
+	if (currentLength &gt; largestLength) {
+		largestStart = currentStart;
+		largestLength = currentLength;
+	}
+
+	if (firstFree &lt; group.fFirstFree) {
+		// mostly harmless but noteworthy
+		dprintf(&quot;group %d first free too late\n&quot;,
+			(int)groupIndex);
+	}
+	if (largestStart != group.fLargestStart
+		|| largestLength != group.fLargestLength) {
+		panic(&quot;bfs %p: group %d largest differs: %d.%d, checked %d.%d.\n&quot;,
+			fVolume, (int)groupIndex, (int)group.fLargestStart,
+			(int)group.fLargestLength, (int)largestStart, (int)largestLength);
+	}
+}
+
+
 //	#pragma mark - Bitmap validity checking
 
 // TODO: implement new FS checking API
@@ -1486,18 +1675,65 @@
 
 		AllocationGroup&amp; group = fGroups[i];
 
-		kprintf(&quot;[%3ld] num bits:      %lu\n&quot;, i, group.NumBits());
-		kprintf(&quot;      num blocks:    %lu\n&quot;, group.NumBlocks());
-		kprintf(&quot;      start:         %ld\n&quot;, group.Start());
-		kprintf(&quot;      first free:    %ld\n&quot;, group.fFirstFree);
-		kprintf(&quot;      largest:       %ld\n&quot;, group.fLargest);
-		kprintf(&quot;      largest first: %ld\n&quot;, group.fLargestFirst);
-		kprintf(&quot;      free bits:     %ld\n&quot;, group.fFreeBits);
+		kprintf(&quot;[%3ld] num bits:       %lu\n&quot;, i, group.NumBits());
+		kprintf(&quot;      num blocks:     %lu\n&quot;, group.NumBlocks());
+		kprintf(&quot;      start:          %ld\n&quot;, group.Start());
+		kprintf(&quot;      first free:     %ld\n&quot;, group.fFirstFree);
+		kprintf(&quot;      largest start:  %ld%s\n&quot;, group.fLargestStart,
+			group.fLargestValid ? &quot;&quot; : &quot;  (invalid)&quot;);
+		kprintf(&quot;      largest length: %ld\n&quot;, group.fLargestLength);
+		kprintf(&quot;      free bits:      %ld\n&quot;, group.fFreeBits);
 	}
 }
 
 
+#if BFS_TRACING
+static char kTraceBuffer[256];
+
+
 int
+dump_block_allocator_blocks(int argc, char** argv)
+{
+	if (argc != 3 || !strcmp(argv[1], &quot;--help&quot;)) {
+		kprintf(&quot;usage: %s &lt;ptr-to-volume&gt; &lt;block&gt;\n&quot;, argv[0]);
+		return 0;
+	}
+
+	Volume* volume = (Volume*)parse_expression(argv[1]);
+	off_t block = parse_expression(argv[2]);
+
+	// iterate over all tracing entries to find overlapping actions
+
+	using namespace BFSBlockTracing;
+
+	LazyTraceOutput out(kTraceBuffer, sizeof(kTraceBuffer), 0);
+	TraceEntryIterator iterator;
+	while (TraceEntry* _entry = iterator.Next()) {
+		if (Allocate* entry = dynamic_cast&lt;Allocate*&gt;(_entry)) {
+			off_t first = volume-&gt;ToBlock(entry-&gt;Run());
+			off_t last = first - 1 + entry-&gt;Run().Length();
+			if (block &gt;= first &amp;&amp; block &lt;= last) {
+				out.Clear();
+				const char* dump = out.DumpEntry(entry);
+				kprintf(&quot;%5ld. %s\n&quot;, iterator.Index(), dump);
+			}
+		} else if (Free* entry = dynamic_cast&lt;Free*&gt;(_entry)) {
+			off_t first = volume-&gt;ToBlock(entry-&gt;Run());
+			off_t last = first - 1 + entry-&gt;Run().Length();
+			if (block &gt;= first &amp;&amp; block &lt;= last) {
+				out.Clear();
+				const char* dump = out.DumpEntry(entry);
+				kprintf(&quot;%5ld. %s\n&quot;, iterator.Index(), dump);
+			}
+		}
+	}
+
+	return 0;
+}
+#endif
+
+
+int
 dump_block_allocator(int argc, char** argv)
 {
 	int32 group = -1;

Modified: haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.h
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.h	2008-10-14 21:47:05 UTC (rev 28110)
+++ haiku/trunk/src/add-ons/kernel/file_systems/bfs/BlockAllocator.h	2008-10-14 22:14:10 UTC (rev 28111)
@@ -19,6 +19,9 @@
 struct check_cookie;
 
 
+#define DEBUG_ALLOCATION_GROUPS
+
+
 class BlockAllocator {
 public:
 							BlockAllocator(Volume* volume);
@@ -59,6 +62,9 @@
 #endif
 
 private:
+#ifdef DEBUG_ALLOCATION_GROUPS
+			void			_CheckGroup(int32 group) const;
+#endif
 			bool			_IsValidCheckControl(check_control* control);
 			bool			_CheckBitmapIsUsedAt(off_t block) const;
 			void			_SetCheckBitmapAt(off_t block);
@@ -76,6 +82,9 @@
 };
 
 #ifdef BFS_DEBUGGER_COMMANDS
+#if BFS_TRACING
+int dump_block_allocator_blocks(int argc, char** argv);
+#endif
 int dump_block_allocator(int argc, char** argv);
 #endif
 

Modified: haiku/trunk/src/add-ons/kernel/file_systems/bfs/Debug.cpp
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/bfs/Debug.cpp	2008-10-14 21:47:05 UTC (rev 28110)
+++ haiku/trunk/src/add-ons/kernel/file_systems/bfs/Debug.cpp	2008-10-14 22:14:10 UTC (rev 28111)
@@ -423,6 +423,10 @@
 {
 	remove_debugger_command(&quot;bfs_inode&quot;, dump_inode);
 	remove_debugger_command(&quot;bfs_allocator&quot;, dump_block_allocator);
+#if BFS_TRACING
+	remove_debugger_command(&quot;bfs_allocator_blocks&quot;,
+		dump_block_allocator_blocks);
+#endif
 	remove_debugger_command(&quot;bfs_journal&quot;, dump_journal);
 	remove_debugger_command(&quot;bfs_btree_header&quot;, dump_bplustree_header);
 	remove_debugger_command(&quot;bfs_btree_node&quot;, dump_bplustree_node);
@@ -437,6 +441,10 @@
 	add_debugger_command(&quot;bfs_inode&quot;, dump_inode, &quot;dump an Inode object&quot;);
 	add_debugger_command(&quot;bfs_allocator&quot;, dump_block_allocator,
 		&quot;dump a BFS block allocator&quot;);
+#if BFS_TRACING
+	add_debugger_command(&quot;bfs_allocator_blocks&quot;, dump_block_allocator_blocks,
+		&quot;dump a BFS block allocator actions that affected a certain block&quot;);
+#endif
 	add_debugger_command(&quot;bfs_journal&quot;, dump_journal,
 		&quot;dump the journal log entries&quot;);
 	add_debugger_command(&quot;bfs_btree_header&quot;, dump_bplustree_header,


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="012723.html">[Haiku-commits] r28110 - haiku/trunk/src/tools/vmdkimage
</A></li>
	<LI>Next message: <A HREF="012728.html">[Haiku-commits] r28111 -	haiku/trunk/src/add-ons/kernel/file_systems/bfs
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12724">[ date ]</a>
              <a href="thread.html#12724">[ thread ]</a>
              <a href="subject.html#12724">[ subject ]</a>
              <a href="author.html#12724">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
