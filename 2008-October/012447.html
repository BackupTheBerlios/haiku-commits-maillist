<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r27910 - in haiku/trunk: headers/private/kernel	src/system/kernel
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2008-October/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r27910%20-%20in%20haiku/trunk%3A%20headers/private/kernel%0A%09src/system/kernel&In-Reply-To=%3C200810072114.m97LEsiI009261%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="012446.html">
   <LINK REL="Next"  HREF="012443.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r27910 - in haiku/trunk: headers/private/kernel	src/system/kernel</H1>
    <B>bonefish at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r27910%20-%20in%20haiku/trunk%3A%20headers/private/kernel%0A%09src/system/kernel&In-Reply-To=%3C200810072114.m97LEsiI009261%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r27910 - in haiku/trunk: headers/private/kernel	src/system/kernel">bonefish at mail.berlios.de
       </A><BR>
    <I>Tue Oct  7 23:14:54 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="012446.html">[Haiku-commits] r27909 - haiku/trunk/src/add-ons/tracker/zipomatic
</A></li>
        <LI>Next message: <A HREF="012443.html">[Haiku-commits] r27911 - haiku/trunk/data/artwork
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12447">[ date ]</a>
              <a href="thread.html#12447">[ thread ]</a>
              <a href="subject.html#12447">[ subject ]</a>
              <a href="author.html#12447">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: bonefish
Date: 2008-10-07 23:14:24 +0200 (Tue, 07 Oct 2008)
New Revision: 27910
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=27910&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=27910&amp;view=rev</A>

Added:
   haiku/trunk/src/system/kernel/smp.cpp
Removed:
   haiku/trunk/src/system/kernel/smp.c
Modified:
   haiku/trunk/headers/private/kernel/smp.h
   haiku/trunk/src/system/kernel/Jamfile
Log:
* smp.c -&gt; smp.cpp
* Added smp_send_multicast_ici(), which sends the message to all CPUs
  specified via a mask.


Modified: haiku/trunk/headers/private/kernel/smp.h
===================================================================
--- haiku/trunk/headers/private/kernel/smp.h	2008-10-07 21:13:04 UTC (rev 27909)
+++ haiku/trunk/headers/private/kernel/smp.h	2008-10-07 21:14:24 UTC (rev 27910)
@@ -31,6 +31,8 @@
 	SMP_MSG_FLAG_FREE_ARG	= 0x2,
 };
 
+typedef uint32 cpu_mask_t;
+
 typedef void (*smp_call_func)(uint32 data1, int32 currentCPU, uint32 data2, uint32 data3);
 
 
@@ -46,6 +48,8 @@
 void smp_cpu_rendezvous(volatile uint32 *var, int current_cpu);
 void smp_send_ici(int32 targetCPU, int32 message, uint32 data, uint32 data2, uint32 data3,
 		void *data_ptr, uint32 flags);
+void smp_send_multicast_ici(cpu_mask_t cpuMask, int32 message, uint32 data,
+		uint32 data2, uint32 data3, void *data_ptr, uint32 flags);
 void smp_send_broadcast_ici(int32 message, uint32 data, uint32 data2, uint32 data3,
 		void *data_ptr, uint32 flags);
 

Modified: haiku/trunk/src/system/kernel/Jamfile
===================================================================
--- haiku/trunk/src/system/kernel/Jamfile	2008-10-07 21:13:04 UTC (rev 27909)
+++ haiku/trunk/src/system/kernel/Jamfile	2008-10-07 21:14:24 UTC (rev 27910)
@@ -40,7 +40,7 @@
 	shutdown.c
 	signal.cpp
 	system_info.cpp
-	smp.c
+	smp.cpp
 	syscalls.cpp
 	team.cpp
 	thread.cpp

Deleted: haiku/trunk/src/system/kernel/smp.c

Copied: haiku/trunk/src/system/kernel/smp.cpp (from rev 27878, haiku/trunk/src/system/kernel/smp.c)
===================================================================
--- haiku/trunk/src/system/kernel/smp.c	2008-10-05 15:17:31 UTC (rev 27878)
+++ haiku/trunk/src/system/kernel/smp.cpp	2008-10-07 21:14:24 UTC (rev 27910)
@@ -0,0 +1,844 @@
+/*
+ * Copyright 2002-2008, Axel D&#246;rfler, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de.</A>
+ * Distributed under the terms of the MIT License.
+ *
+ * Copyright 2001-2002, Travis Geiselbrecht. All rights reserved.
+ * Distributed under the terms of the NewOS License.
+ */
+
+/* Functionality for symetrical multi-processors */
+
+#include &lt;smp.h&gt;
+
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+
+#include &lt;arch/cpu.h&gt;
+#include &lt;arch/debug.h&gt;
+#include &lt;arch/int.h&gt;
+#include &lt;arch/smp.h&gt;
+#include &lt;cpu.h&gt;
+#include &lt;generic_syscall.h&gt;
+#include &lt;int.h&gt;
+#include &lt;spinlock_contention.h&gt;
+#include &lt;thread.h&gt;
+
+
+#define DEBUG_SPINLOCKS 1
+//#define TRACE_SMP
+
+#ifdef TRACE_SMP
+#	define TRACE(x) dprintf x
+#else
+#	define TRACE(x) ;
+#endif
+
+#if __INTEL__
+#	define PAUSE() asm volatile (&quot;pause;&quot;)
+#else
+#	define PAUSE()
+#endif
+
+#define MSG_POOL_SIZE (SMP_MAX_CPUS * 4)
+
+struct smp_msg {
+	struct smp_msg	*next;
+	int32			message;
+	uint32			data;
+	uint32			data2;
+	uint32			data3;
+	void			*data_ptr;
+	uint32			flags;
+	int32			ref_count;
+	volatile bool	done;
+	uint32			proc_bitmap;
+};
+
+#define MAILBOX_LOCAL 1
+#define MAILBOX_BCAST 2
+
+static spinlock boot_cpu_spin[SMP_MAX_CPUS] = { };
+
+static struct smp_msg *sFreeMessages = NULL;
+static volatile int sFreeMessageCount = 0;
+static spinlock sFreeMessageSpinlock = B_SPINLOCK_INITIALIZER;
+
+static struct smp_msg *sCPUMessages[SMP_MAX_CPUS] = { NULL, };
+static spinlock sCPUMessageSpinlock[SMP_MAX_CPUS];
+
+static struct smp_msg *sBroadcastMessages = NULL;
+static spinlock sBroadcastMessageSpinlock = B_SPINLOCK_INITIALIZER;
+
+static bool sICIEnabled = false;
+static int32 sNumCPUs = 1;
+
+static int32 process_pending_ici(int32 currentCPU);
+
+
+#if DEBUG_SPINLOCKS
+#define NUM_LAST_CALLERS	32
+
+static struct {
+	void		*caller;
+	spinlock	*lock;
+} sLastCaller[NUM_LAST_CALLERS];
+static int32 sLastIndex = 0;
+
+
+static void
+push_lock_caller(void *caller, spinlock *lock)
+{
+	sLastCaller[sLastIndex].caller = caller;
+	sLastCaller[sLastIndex].lock = lock;
+
+	if (++sLastIndex &gt;= NUM_LAST_CALLERS)
+		sLastIndex = 0;
+}
+
+
+static void *
+find_lock_caller(spinlock *lock)
+{
+	int32 i;
+
+	for (i = 0; i &lt; NUM_LAST_CALLERS; i++) {
+		int32 index = (NUM_LAST_CALLERS + sLastIndex - 1 - i) % NUM_LAST_CALLERS;
+		if (sLastCaller[index].lock == lock)
+			return sLastCaller[index].caller;
+	}
+
+	return NULL;
+}
+#endif	// DEBUG_SPINLOCKS
+
+
+void
+acquire_spinlock(spinlock *lock)
+{
+	if (sNumCPUs &gt; 1) {
+		int currentCPU = smp_get_current_cpu();
+		if (are_interrupts_enabled())
+			panic(&quot;acquire_spinlock: attempt to acquire lock %p with interrupts enabled\n&quot;, lock);
+#if B_DEBUG_SPINLOCK_CONTENTION
+		while (atomic_add(&amp;lock-&gt;lock, 1) != 0)
+			process_pending_ici(currentCPU);
+#else
+		while (1) {
+			while (*lock != 0) {
+				process_pending_ici(currentCPU);
+				PAUSE();
+			}
+			if (atomic_set((int32 *)lock, 1) == 0)
+				break;
+		}
+#endif
+	} else {
+#if DEBUG_SPINLOCKS
+		int32 oldValue;
+		if (are_interrupts_enabled())
+			panic(&quot;acquire_spinlock: attempt to acquire lock %p with interrupts enabled\n&quot;, lock);
+		oldValue = atomic_set((int32 *)lock, 1);
+		if (oldValue != 0) {
+			panic(&quot;acquire_spinlock: attempt to acquire lock %p twice on non-SMP system (last caller: %p, value %ld)\n&quot;,
+				lock, find_lock_caller(lock), oldValue);
+		}
+
+		push_lock_caller(arch_debug_get_caller(), lock);
+#endif
+	}
+}
+
+
+static void
+acquire_spinlock_nocheck(spinlock *lock)
+{
+	if (sNumCPUs &gt; 1) {
+#if DEBUG_SPINLOCKS
+		if (are_interrupts_enabled())
+			panic(&quot;acquire_spinlock_nocheck: attempt to acquire lock %p with interrupts enabled\n&quot;, lock);
+#endif
+#if B_DEBUG_SPINLOCK_CONTENTION
+		while (atomic_add(&amp;lock-&gt;lock, 1) != 0) {
+		}
+#else
+		while (1) {
+			while(*lock != 0)
+				PAUSE();
+			if (atomic_set((int32 *)lock, 1) == 0)
+				break;
+		}
+#endif
+	} else {
+#if DEBUG_SPINLOCKS
+		if (are_interrupts_enabled())
+			panic(&quot;acquire_spinlock_nocheck: attempt to acquire lock %p with interrupts enabled\n&quot;, lock);
+		if (atomic_set((int32 *)lock, 1) != 0)
+			panic(&quot;acquire_spinlock_nocheck: attempt to acquire lock %p twice on non-SMP system\n&quot;, lock);
+#endif
+	}
+}
+
+
+void
+release_spinlock(spinlock *lock)
+{
+	if (sNumCPUs &gt; 1) {
+		if (are_interrupts_enabled())
+			panic(&quot;release_spinlock: attempt to release lock %p with interrupts enabled\n&quot;, lock);
+#if B_DEBUG_SPINLOCK_CONTENTION
+		{
+			int32 count = atomic_set(&amp;lock-&gt;lock, 0) - 1;
+			if (count &lt; 0) {
+				panic(&quot;release_spinlock: lock %p was already released\n&quot;, lock);
+			} else {
+				// add to the total count -- deal with carry manually
+				if ((uint32)atomic_add(&amp;lock-&gt;count_low, count) + count
+						&lt; (uint32)count) {
+					atomic_add(&amp;lock-&gt;count_high, 1);
+				}
+			}
+		}
+#else
+		if (atomic_set((int32 *)lock, 0) != 1)
+			panic(&quot;release_spinlock: lock %p was already released\n&quot;, lock);
+#endif
+	} else {
+		#if DEBUG_SPINLOCKS
+			if (are_interrupts_enabled())
+				panic(&quot;release_spinlock: attempt to release lock %p with interrupts enabled\n&quot;, lock);
+			if (atomic_set((int32 *)lock, 0) != 1)
+				panic(&quot;release_spinlock: lock %p was already released\n&quot;, lock);
+		#endif
+	}
+}
+
+
+/** Finds a free message and gets it.
+ *	NOTE: has side effect of disabling interrupts
+ *	return value is the former interrupt state
+ */
+
+static cpu_status
+find_free_message(struct smp_msg **msg)
+{
+	cpu_status state;
+
+	TRACE((&quot;find_free_message: entry\n&quot;));
+
+retry:
+	while (sFreeMessageCount &lt;= 0)
+		PAUSE();
+	state = disable_interrupts();
+	acquire_spinlock(&amp;sFreeMessageSpinlock);
+
+	if (sFreeMessageCount &lt;= 0) {
+		// someone grabbed one while we were getting the lock,
+		// go back to waiting for it
+		release_spinlock(&amp;sFreeMessageSpinlock);
+		restore_interrupts(state);
+		goto retry;
+	}
+
+	*msg = sFreeMessages;
+	sFreeMessages = (*msg)-&gt;next;
+	sFreeMessageCount--;
+
+	release_spinlock(&amp;sFreeMessageSpinlock);
+
+	TRACE((&quot;find_free_message: returning msg %p\n&quot;, *msg));
+
+	return state;
+}
+
+
+static void
+return_free_message(struct smp_msg *msg)
+{
+	TRACE((&quot;return_free_message: returning msg %p\n&quot;, msg));
+
+	acquire_spinlock_nocheck(&amp;sFreeMessageSpinlock);
+	msg-&gt;next = sFreeMessages;
+	sFreeMessages = msg;
+	sFreeMessageCount++;
+	release_spinlock(&amp;sFreeMessageSpinlock);
+}
+
+
+static struct smp_msg *
+check_for_message(int currentCPU, int *source_mailbox)
+{
+	struct smp_msg *msg;
+
+	if (!sICIEnabled)
+		return NULL;
+
+	acquire_spinlock_nocheck(&amp;sCPUMessageSpinlock[currentCPU]);
+	msg = sCPUMessages[currentCPU];
+	if (msg != NULL) {
+		sCPUMessages[currentCPU] = msg-&gt;next;
+		release_spinlock(&amp;sCPUMessageSpinlock[currentCPU]);
+		TRACE((&quot; cpu %d: found msg %p in cpu mailbox\n&quot;, currentCPU, msg));
+		*source_mailbox = MAILBOX_LOCAL;
+	} else {
+		// try getting one from the broadcast mailbox
+
+		release_spinlock(&amp;sCPUMessageSpinlock[currentCPU]);
+		acquire_spinlock_nocheck(&amp;sBroadcastMessageSpinlock);
+
+		msg = sBroadcastMessages;
+		while (msg != NULL) {
+			if (CHECK_BIT(msg-&gt;proc_bitmap, currentCPU) != 0) {
+				// we have handled this one already
+				msg = msg-&gt;next;
+				continue;
+			}
+
+			// mark it so we wont try to process this one again
+			msg-&gt;proc_bitmap = SET_BIT(msg-&gt;proc_bitmap, currentCPU);
+			*source_mailbox = MAILBOX_BCAST;
+			break;
+		}
+		release_spinlock(&amp;sBroadcastMessageSpinlock);
+		TRACE((&quot; cpu %d: found msg %p in broadcast mailbox\n&quot;, currentCPU, msg));
+	}
+	return msg;
+}
+
+
+static void
+finish_message_processing(int currentCPU, struct smp_msg *msg, int source_mailbox)
+{
+	int old_refcount;
+
+	old_refcount = atomic_add(&amp;msg-&gt;ref_count, -1);
+	if (old_refcount == 1) {
+		// we were the last one to decrement the ref_count
+		// it's our job to remove it from the list &amp; possibly clean it up
+		struct smp_msg **mbox = NULL;
+		spinlock *spinlock = NULL;
+
+		// clean up the message from one of the mailboxes
+		switch (source_mailbox) {
+			case MAILBOX_BCAST:
+				mbox = &sBroadcastMessages;
+				spinlock = &sBroadcastMessageSpinlock;
+				break;
+			case MAILBOX_LOCAL:
+				mbox = &amp;sCPUMessages[currentCPU];
+				spinlock = &amp;sCPUMessageSpinlock[currentCPU];
+				break;
+		}
+
+		acquire_spinlock_nocheck(spinlock);
+
+		TRACE((&quot;cleaning up message %p\n&quot;, msg));
+
+		if (msg == *mbox) {
+			(*mbox) = msg-&gt;next;
+		} else {
+			// we need to walk to find the message in the list.
+			// we can't use any data found when previously walking through
+			// the list, since the list may have changed. But, we are guaranteed
+			// to at least have msg in it.
+			struct smp_msg *last = NULL;
+			struct smp_msg *msg1;
+
+			msg1 = *mbox;
+			while (msg1 != NULL &amp;&amp; msg1 != msg) {
+				last = msg1;
+				msg1 = msg1-&gt;next;
+			}
+
+			// by definition, last must be something
+			if (msg1 == msg &amp;&amp; last != NULL)
+				last-&gt;next = msg-&gt;next;
+			else
+				dprintf(&quot;last == NULL or msg != msg1!!!\n&quot;);
+		}
+
+		release_spinlock(spinlock);
+
+		if ((msg-&gt;flags &amp; SMP_MSG_FLAG_FREE_ARG) != 0 &amp;&amp; msg-&gt;data_ptr != NULL)
+			free(msg-&gt;data_ptr);
+
+		if (msg-&gt;flags &amp; SMP_MSG_FLAG_SYNC) {
+			msg-&gt;done = true;
+			// the caller cpu should now free the message
+		} else {
+			// in the !SYNC case, we get to free the message
+			return_free_message(msg);
+		}
+	}
+}
+
+
+static int32
+process_pending_ici(int32 currentCPU)
+{
+	struct smp_msg *msg;
+	vint32 *haltValue = NULL;
+	int sourceMailbox = 0;
+	int retval = B_HANDLED_INTERRUPT;
+
+	msg = check_for_message(currentCPU, &amp;sourceMailbox);
+	if (msg == NULL)
+		return retval;
+
+	TRACE((&quot;  cpu %ld message = %ld\n&quot;, currentCPU, msg-&gt;message));
+
+	switch (msg-&gt;message) {
+		case SMP_MSG_INVALIDATE_PAGE_RANGE:
+			arch_cpu_invalidate_TLB_range((addr_t)msg-&gt;data, (addr_t)msg-&gt;data2);
+			break;
+		case SMP_MSG_INVALIDATE_PAGE_LIST:
+			arch_cpu_invalidate_TLB_list((addr_t *)msg-&gt;data, (int)msg-&gt;data2);
+			break;
+		case SMP_MSG_USER_INVALIDATE_PAGES:
+			arch_cpu_user_TLB_invalidate();
+			break;
+		case SMP_MSG_GLOBAL_INVALIDATE_PAGES:
+			arch_cpu_global_TLB_invalidate();
+			break;
+		case SMP_MSG_RESCHEDULE:
+			retval = B_INVOKE_SCHEDULER;
+			break;
+		case SMP_MSG_CPU_HALT:
+			haltValue = (vint32 *)msg-&gt;data_ptr;
+			dprintf(&quot;CPU %ld halted!\n&quot;, currentCPU);
+			break;
+		case SMP_MSG_CALL_FUNCTION:
+		{
+			smp_call_func func = (smp_call_func)msg-&gt;data_ptr;
+			func(msg-&gt;data, currentCPU, msg-&gt;data2, msg-&gt;data3);
+			break;
+		}
+
+		default:
+			dprintf(&quot;smp_intercpu_int_handler: got unknown message %ld\n&quot;, msg-&gt;message);
+	}
+
+	// finish dealing with this message, possibly removing it from the list
+	finish_message_processing(currentCPU, msg, sourceMailbox);
+
+	// special case for the halt message
+	if (haltValue) {
+		cpu_status state = disable_interrupts();
+
+		while (*haltValue != 0)
+			PAUSE();
+
+		restore_interrupts(state);
+	}
+
+	return retval;
+}
+
+
+#if B_DEBUG_SPINLOCK_CONTENTION
+
+static uint64
+get_spinlock_counter(spinlock* lock)
+{
+	uint32 high;
+	uint32 low;
+	do {
+		high = (uint32)atomic_get(&amp;lock-&gt;count_high);
+		low = (uint32)atomic_get(&amp;lock-&gt;count_low);
+	} while (high != atomic_get(&amp;lock-&gt;count_high));
+
+	return ((uint64)high &lt;&lt; 32) | low;
+}
+
+
+static status_t
+spinlock_contention_syscall(const char* subsystem, uint32 function,
+	void* buffer, size_t bufferSize)
+{
+	spinlock_contention_info info;
+
+	if (function != GET_SPINLOCK_CONTENTION_INFO)
+		return B_BAD_VALUE;
+
+	if (bufferSize &lt; sizeof(spinlock_contention_info))
+		return B_BAD_VALUE;
+
+	info.thread_spinlock_counter = get_spinlock_counter(&amp;gThreadSpinlock);
+	info.team_spinlock_counter = get_spinlock_counter(&amp;gTeamSpinlock);
+
+	if (!IS_USER_ADDRESS(buffer)
+		|| user_memcpy(buffer, &amp;info, sizeof(info)) != B_OK) {
+		return B_BAD_ADDRESS;
+	}
+
+	return B_OK;
+}
+
+#endif	// B_DEBUG_SPINLOCK_CONTENTION
+
+
+//	#pragma mark -
+
+
+int
+smp_intercpu_int_handler(void)
+{
+	int retval;
+	int currentCPU = smp_get_current_cpu();
+
+	TRACE((&quot;smp_intercpu_int_handler: entry on cpu %d\n&quot;, currentCPU));
+
+	retval = process_pending_ici(currentCPU);
+
+	TRACE((&quot;smp_intercpu_int_handler: done\n&quot;));
+
+	return retval;
+}
+
+
+void
+smp_send_ici(int32 targetCPU, int32 message, uint32 data, uint32 data2, uint32 data3,
+	void *data_ptr, uint32 flags)
+{
+	struct smp_msg *msg;
+
+	TRACE((&quot;smp_send_ici: target 0x%lx, mess 0x%lx, data 0x%lx, data2 0x%lx, data3 0x%lx, ptr %p, flags 0x%lx\n&quot;,
+		targetCPU, message, data, data2, data3, data_ptr, flags));
+
+	if (sICIEnabled) {
+		int state;
+		int currentCPU;
+
+		// find_free_message leaves interrupts disabled
+		state = find_free_message(&amp;msg);
+
+		currentCPU = smp_get_current_cpu();
+		if (targetCPU == currentCPU) {
+			return_free_message(msg);
+			restore_interrupts(state);
+			return; // nope, cant do that
+		}
+
+		// set up the message
+		msg-&gt;message = message;
+		msg-&gt;data = data;
+		msg-&gt;data2 = data2;
+		msg-&gt;data3 = data3;
+		msg-&gt;data_ptr = data_ptr;
+		msg-&gt;ref_count = 1;
+		msg-&gt;flags = flags;
+		msg-&gt;done = false;
+
+		// stick it in the appropriate cpu's mailbox
+		acquire_spinlock_nocheck(&amp;sCPUMessageSpinlock[targetCPU]);
+		msg-&gt;next = sCPUMessages[targetCPU];
+		sCPUMessages[targetCPU] = msg;
+		release_spinlock(&amp;sCPUMessageSpinlock[targetCPU]);
+
+		arch_smp_send_ici(targetCPU);
+
+		if (flags &amp; SMP_MSG_FLAG_SYNC) {
+			// wait for the other cpu to finish processing it
+			// the interrupt handler will ref count it to &lt;0
+			// if the message is sync after it has removed it from the mailbox
+			while (msg-&gt;done == false) {
+				process_pending_ici(currentCPU);
+				PAUSE();
+			}
+			// for SYNC messages, it's our responsibility to put it
+			// back into the free list
+			return_free_message(msg);
+		}
+
+		restore_interrupts(state);
+	}
+}
+
+
+void
+smp_send_multicast_ici(cpu_mask_t cpuMask, int32 message, uint32 data,
+	uint32 data2, uint32 data3, void *data_ptr, uint32 flags)
+{
+	if (!sICIEnabled)
+		return;
+
+	int currentCPU = smp_get_current_cpu();
+	cpuMask &amp;= ~((cpu_mask_t)1 &lt;&lt; currentCPU);
+	if (cpuMask == 0)
+		return;
+
+	// count target CPUs
+	int32 targetCPUs = 0;
+	for (int32 i = 0; i &lt; sNumCPUs; i++) {
+		if ((cpuMask &amp; (cpu_mask_t)1 &lt;&lt; i) != 0)
+			targetCPUs++;
+	}
+
+	// find_free_message leaves interrupts disabled
+	struct smp_msg *msg;
+	int state = find_free_message(&amp;msg);
+
+	msg-&gt;message = message;
+	msg-&gt;data = data;
+	msg-&gt;data2 = data2;
+	msg-&gt;data3 = data3;
+	msg-&gt;data_ptr = data_ptr;
+	msg-&gt;ref_count = targetCPUs;
+	msg-&gt;flags = flags;
+	msg-&gt;proc_bitmap = ~cpuMask;
+	msg-&gt;done = false;
+
+	// stick it in the broadcast mailbox
+	acquire_spinlock_nocheck(&amp;sBroadcastMessageSpinlock);
+	msg-&gt;next = sBroadcastMessages;
+	sBroadcastMessages = msg;
+	release_spinlock(&amp;sBroadcastMessageSpinlock);
+
+	arch_smp_send_broadcast_ici();
+		// TODO: Introduce a call that only bothers the target CPUs!
+
+	if (flags &amp; SMP_MSG_FLAG_SYNC) {
+		// wait for the other cpus to finish processing it
+		// the interrupt handler will ref count it to &lt;0
+		// if the message is sync after it has removed it from the mailbox
+		while (msg-&gt;done == false) {
+			process_pending_ici(currentCPU);
+			PAUSE();
+		}
+
+		// for SYNC messages, it's our responsibility to put it
+		// back into the free list
+		return_free_message(msg);
+	}
+
+	restore_interrupts(state);
+}
+
+
+void
+smp_send_broadcast_ici(int32 message, uint32 data, uint32 data2, uint32 data3,
+	void *data_ptr, uint32 flags)
+{
+	struct smp_msg *msg;
+
+	TRACE((&quot;smp_send_broadcast_ici: cpu %ld mess 0x%lx, data 0x%lx, data2 0x%lx, data3 0x%lx, ptr %p, flags 0x%lx\n&quot;,
+		smp_get_current_cpu(), message, data, data2, data3, data_ptr, flags));
+
+	if (sICIEnabled) {
+		int state;
+		int currentCPU;
+
+		// find_free_message leaves interrupts disabled
+		state = find_free_message(&amp;msg);
+
+		currentCPU = smp_get_current_cpu();
+
+		msg-&gt;message = message;
+		msg-&gt;data = data;
+		msg-&gt;data2 = data2;
+		msg-&gt;data3 = data3;
+		msg-&gt;data_ptr = data_ptr;
+		msg-&gt;ref_count = sNumCPUs - 1;
+		msg-&gt;flags = flags;
+		msg-&gt;proc_bitmap = SET_BIT(0, currentCPU);
+		msg-&gt;done = false;
+
+		TRACE((&quot;smp_send_broadcast_ici%d: inserting msg %p into broadcast mbox\n&quot;,
+			currentCPU, msg));
+
+		// stick it in the appropriate cpu's mailbox
+		acquire_spinlock_nocheck(&amp;sBroadcastMessageSpinlock);
+		msg-&gt;next = sBroadcastMessages;
+		sBroadcastMessages = msg;
+		release_spinlock(&amp;sBroadcastMessageSpinlock);
+
+		arch_smp_send_broadcast_ici();
+
+		TRACE((&quot;smp_send_broadcast_ici: sent interrupt\n&quot;));
+
+		if (flags &amp; SMP_MSG_FLAG_SYNC) {
+			// wait for the other cpus to finish processing it
+			// the interrupt handler will ref count it to &lt;0
+			// if the message is sync after it has removed it from the mailbox
+			TRACE((&quot;smp_send_broadcast_ici: waiting for ack\n&quot;));
+
+			while (msg-&gt;done == false) {
+				process_pending_ici(currentCPU);
+				PAUSE();
+			}
+
+			TRACE((&quot;smp_send_broadcast_ici: returning message to free list\n&quot;));
+
+			// for SYNC messages, it's our responsibility to put it
+			// back into the free list
+			return_free_message(msg);
+		}
+
+		restore_interrupts(state);
+	}
+
+	TRACE((&quot;smp_send_broadcast_ici: done\n&quot;));
+}
+
+
+bool
+smp_trap_non_boot_cpus(int32 cpu)
+{
+	if (cpu &gt; 0) {
+#if B_DEBUG_SPINLOCK_CONTENTION
+		boot_cpu_spin[cpu].lock = 1;
+#else
+		boot_cpu_spin[cpu] = 1;
+#endif
+		acquire_spinlock_nocheck(&amp;boot_cpu_spin[cpu]);
+		return false;
+	}
+
+	return true;
+}
+
+
+void
+smp_wake_up_non_boot_cpus()
+{
+	int i;
+
+	// ICIs were previously being ignored
+	if (sNumCPUs &gt; 1)
+		sICIEnabled = true;
+
+	// resume non boot CPUs
+	for (i = 1; i &lt; sNumCPUs; i++) {
+		release_spinlock(&amp;boot_cpu_spin[i]);
+	}
+}
+
+/* have all cpus spin until all have run */
+void
+smp_cpu_rendezvous(volatile uint32 *var, int current_cpu)
+{
+	atomic_or((vint32*)var, 1 &lt;&lt; current_cpu);
+
+	while (*var != (((uint32)1 &lt;&lt; sNumCPUs) - 1))
+		PAUSE();
+}
+
+status_t
+smp_init(kernel_args *args)
+{
+	struct smp_msg *msg;
+	int i;
+
+	TRACE((&quot;smp_init: entry\n&quot;));
+
+	if (args-&gt;num_cpus &gt; 1) {
+		sFreeMessages = NULL;
+		sFreeMessageCount = 0;
+		for (i = 0; i &lt; MSG_POOL_SIZE; i++) {
+			msg = (struct smp_msg *)malloc(sizeof(struct smp_msg));
+			if (msg == NULL) {
+				panic(&quot;error creating smp mailboxes\n&quot;);
+				return B_ERROR;
+			}
+			memset(msg, 0, sizeof(struct smp_msg));
+			msg-&gt;next = sFreeMessages;
+			sFreeMessages = msg;
+			sFreeMessageCount++;
+		}
+		sNumCPUs = args-&gt;num_cpus;
+	}
+	TRACE((&quot;smp_init: calling arch_smp_init\n&quot;));
+
+	return arch_smp_init(args);
+}
+
+
+status_t
+smp_per_cpu_init(kernel_args *args, int32 cpu)
+{
+	return arch_smp_per_cpu_init(args, cpu);
+}
+
+
+status_t
+smp_init_post_generic_syscalls(void)
+{
+#if B_DEBUG_SPINLOCK_CONTENTION
+	return register_generic_syscall(SPINLOCK_CONTENTION,
+		&amp;spinlock_contention_syscall, 0, 0);
+#else
+	return B_OK;
+#endif
+}
+
+
+void
+smp_set_num_cpus(int32 numCPUs)
+{
+	sNumCPUs = numCPUs;
+}
+
+
+int32
+smp_get_num_cpus()
+{
+	return sNumCPUs;
+}
+
+
+int32
+smp_get_current_cpu(void)
+{
+	return thread_get_current_thread()-&gt;cpu-&gt;cpu_num;
+}
+
+
+//	#pragma mark -
+//	public exported functions
+
+
+void
+call_all_cpus(void (*func)(void *, int), void *cookie)
+{
+	cpu_status state = disable_interrupts();
+
+	if (smp_get_num_cpus() &gt; 1) {
+		smp_send_broadcast_ici(SMP_MSG_CALL_FUNCTION, (uint32)cookie,
+			0, 0, (void *)func, SMP_MSG_FLAG_ASYNC);
+	}
+
+	// we need to call this function ourselves as well
+	func(cookie, smp_get_current_cpu());
+
+	restore_interrupts(state);
+}
+
+void
+call_all_cpus_sync(void (*func)(void *, int), void *cookie)
+{
+	cpu_status state = disable_interrupts();
+
+	if (smp_get_num_cpus() &gt; 1) {
+		smp_send_broadcast_ici(SMP_MSG_CALL_FUNCTION, (uint32)cookie,
+			0, 0, (void *)func, SMP_MSG_FLAG_SYNC);
+	}
+
+	// we need to call this function ourselves as well
+	func(cookie, smp_get_current_cpu());
+
+	restore_interrupts(state);
+}
+
+
+void
+memory_read_barrier(void)
+{
+	arch_cpu_memory_read_barrier();
+}
+
+
+void
+memory_write_barrier(void)
+{
+	arch_cpu_memory_write_barrier();
+}
+


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="012446.html">[Haiku-commits] r27909 - haiku/trunk/src/add-ons/tracker/zipomatic
</A></li>
	<LI>Next message: <A HREF="012443.html">[Haiku-commits] r27911 - haiku/trunk/data/artwork
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#12447">[ date ]</a>
              <a href="thread.html#12447">[ thread ]</a>
              <a href="subject.html#12447">[ subject ]</a>
              <a href="author.html#12447">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
