<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r22391 - in haiku/trunk: headers/private/kernel	headers/private/kernel/fs src/system/kernel/fs
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2007-October/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r22391%20-%20in%20haiku/trunk%3A%20headers/private/kernel%0A%09headers/private/kernel/fs%20src/system/kernel/fs&In-Reply-To=%3C200710010137.l911bUIY015123%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="004078.html">
   <LINK REL="Next"  HREF="004080.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r22391 - in haiku/trunk: headers/private/kernel	headers/private/kernel/fs src/system/kernel/fs</H1>
    <B>bonefish at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r22391%20-%20in%20haiku/trunk%3A%20headers/private/kernel%0A%09headers/private/kernel/fs%20src/system/kernel/fs&In-Reply-To=%3C200710010137.l911bUIY015123%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r22391 - in haiku/trunk: headers/private/kernel	headers/private/kernel/fs src/system/kernel/fs">bonefish at mail.berlios.de
       </A><BR>
    <I>Mon Oct  1 03:37:30 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="004078.html">[Haiku-commits] r22390 - haiku/trunk/src/tests/system/kernel
</A></li>
        <LI>Next message: <A HREF="004080.html">[Haiku-commits] r22392 - haiku/trunk/src/add-ons/kernel/drivers/tty
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4079">[ date ]</a>
              <a href="thread.html#4079">[ thread ]</a>
              <a href="subject.html#4079">[ subject ]</a>
              <a href="author.html#4079">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: bonefish
Date: 2007-10-01 03:37:28 +0200 (Mon, 01 Oct 2007)
New Revision: 22391
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=22391&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=22391&amp;view=rev</A>

Added:
   haiku/trunk/src/system/kernel/fs/fd.cpp
Removed:
   haiku/trunk/src/system/kernel/fs/fd.c
Modified:
   haiku/trunk/headers/private/kernel/fs/fd.h
   haiku/trunk/headers/private/kernel/vfs.h
   haiku/trunk/src/system/kernel/fs/Jamfile
   haiku/trunk/src/system/kernel/fs/vfs.cpp
   haiku/trunk/src/system/kernel/fs/vfs_select.cpp
   haiku/trunk/src/system/kernel/fs/vfs_select.h
Log:
* fd.c -&gt; fd.cpp
* Reworked the select support:
  - The io_context additionally stores a table of lists of select_infos,
    which enables it to deselect events of a pending select() when
    closing a FD. This prevents a race condition potentially causing a
    write to stale memory.
  - The opaque selectsync* passed to FSs is now actually a select_info*.
    This was necessary, since the FDs deselect() hook (unlike the
    select() hook) doesn't take a &quot;ref&quot; argument and deselecting a
    single info (e.g. caused by a premature close()) was not possible.
    The select() hook's &quot;ref&quot; argument has become superfluous.
  - It should now be relatively easy to implement a poll_on_steroids()
    that can also wait for objects other than FDs (e.g. semaphores,
    ports, threads etc.). 
* Set/reset the signal mask in common_select(). This makes pselect()
  work as required.
* Reorganized vfs_resize_fd_table().



Modified: haiku/trunk/headers/private/kernel/fs/fd.h
===================================================================
--- haiku/trunk/headers/private/kernel/fs/fd.h	2007-10-01 00:39:38 UTC (rev 22390)
+++ haiku/trunk/headers/private/kernel/fs/fd.h	2007-10-01 01:37:28 UTC (rev 22391)
@@ -16,6 +16,7 @@
 #endif
 
 struct file_descriptor;
+struct selectsync;
 struct select_sync;
 
 struct fd_ops {
@@ -23,8 +24,10 @@
 	status_t	(*fd_write)(struct file_descriptor *, off_t pos, const void *buffer, size_t *length);
 	off_t		(*fd_seek)(struct file_descriptor *, off_t pos, int seekType);
 	status_t	(*fd_ioctl)(struct file_descriptor *, ulong op, void *buffer, size_t length);
-	status_t	(*fd_select)(struct file_descriptor *, uint8 event, uint32 ref, struct select_sync *sync);
-	status_t	(*fd_deselect)(struct file_descriptor *, uint8 event, struct select_sync *sync);
+	status_t	(*fd_select)(struct file_descriptor *, uint8 event, uint32 ref,
+						struct selectsync *sync);
+	status_t	(*fd_deselect)(struct file_descriptor *, uint8 event,
+						struct selectsync *sync);
 	status_t	(*fd_read_dir)(struct file_descriptor *, struct dirent *buffer, size_t bufferSize, uint32 *_count);
 	status_t	(*fd_rewind_dir)(struct file_descriptor *);
 	status_t	(*fd_read_stat)(struct file_descriptor *, struct stat *);
@@ -74,10 +77,10 @@
 extern void put_fd(struct file_descriptor *descriptor);
 extern void disconnect_fd(struct file_descriptor *descriptor);
 extern void inc_fd_ref_count(struct file_descriptor *descriptor);
-extern status_t select_fd(int fd, uint8 event, uint32 ref,
-					struct select_sync *sync, bool kernel);
-extern status_t deselect_fd(int fd, uint8 event, struct select_sync *sync,
+extern status_t select_fd(int fd, struct select_sync *sync, uint32 ref,
 					bool kernel);
+extern status_t deselect_fd(int fd, struct select_sync *sync, uint32 ref,
+					bool kernel);
 extern bool fd_is_valid(int fd, bool kernel);
 extern struct vnode *fd_vnode(struct file_descriptor *descriptor);
 

Modified: haiku/trunk/headers/private/kernel/vfs.h
===================================================================
--- haiku/trunk/headers/private/kernel/vfs.h	2007-10-01 00:39:38 UTC (rev 22390)
+++ haiku/trunk/headers/private/kernel/vfs.h	2007-10-01 01:37:28 UTC (rev 22391)
@@ -30,6 +30,7 @@
 struct vm_cache;
 struct file_descriptor;
 struct selectsync;
+struct select_info;
 struct pollfd;
 struct vnode;
 
@@ -41,6 +42,7 @@
 	uint32		table_size;
 	uint32		num_used_fds;
 	struct file_descriptor **fds;
+	struct select_info **select_infos;
 	uint8		*fds_close_on_exec;
 	struct list node_monitors;
 	uint32		num_monitors;

Modified: haiku/trunk/src/system/kernel/fs/Jamfile
===================================================================
--- haiku/trunk/src/system/kernel/fs/Jamfile	2007-10-01 00:39:38 UTC (rev 22390)
+++ haiku/trunk/src/system/kernel/fs/Jamfile	2007-10-01 01:37:28 UTC (rev 22391)
@@ -9,7 +9,7 @@
 	devfs.cpp
 	rootfs.c
 	pipefs.cpp
-	fd.c
+	fd.cpp
 	vfs.cpp
 	vfs_boot.cpp
 	vfs_net_boot.cpp
@@ -19,4 +19,4 @@
 	KPath.cpp
 
 	: $(TARGET_KERNEL_PIC_CCFLAGS) -Wno-unused
-	;
+;

Deleted: haiku/trunk/src/system/kernel/fs/fd.c

Copied: haiku/trunk/src/system/kernel/fs/fd.cpp (from rev 22363, haiku/trunk/src/system/kernel/fs/fd.c)
===================================================================
--- haiku/trunk/src/system/kernel/fs/fd.c	2007-09-29 00:34:09 UTC (rev 22363)
+++ haiku/trunk/src/system/kernel/fs/fd.cpp	2007-10-01 01:37:28 UTC (rev 22391)
@@ -0,0 +1,1188 @@
+/* Operations on file descriptors
+ *
+ * Copyright 2002-2007, Axel D&#246;rfler, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de.</A>
+ * Distributed under the terms of the MIT License.
+ */
+
+
+#include &lt;fd.h&gt;
+
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+
+#include &lt;OS.h&gt;
+
+#include &lt;syscalls.h&gt;
+#include &lt;util/AutoLock.h&gt;
+#include &lt;vfs.h&gt;
+
+#include &quot;vfs_select.h&quot;
+
+
+//#define TRACE_FD
+#ifdef TRACE_FD
+#	define TRACE(x) dprintf x
+#else
+#	define TRACE(x)
+#endif
+
+
+static void deselect_select_infos(file_descriptor* descriptor,
+	select_info* infos);
+
+
+/*** General fd routines ***/
+
+
+#ifdef DEBUG
+void dump_fd(int fd, struct file_descriptor *descriptor);
+
+void
+dump_fd(int fd,struct file_descriptor *descriptor)
+{
+	dprintf(&quot;fd[%d] = %p: type = %ld, ref_count = %ld, ops = %p, u.vnode = %p, u.mount = %p, cookie = %p, open_mode = %lx, pos = %Ld\n&quot;,
+		fd, descriptor, descriptor-&gt;type, descriptor-&gt;ref_count, descriptor-&gt;ops,
+		descriptor-&gt;u.vnode, descriptor-&gt;u.mount, descriptor-&gt;cookie, descriptor-&gt;open_mode, descriptor-&gt;pos);
+}
+#endif
+
+
+/** Allocates and initializes a new file_descriptor */
+
+struct file_descriptor *
+alloc_fd(void)
+{
+	file_descriptor *descriptor
+		= (file_descriptor*)malloc(sizeof(struct file_descriptor));
+	if (descriptor == NULL)
+		return NULL;
+
+	descriptor-&gt;u.vnode = NULL;
+	descriptor-&gt;cookie = NULL;
+	descriptor-&gt;ref_count = 1;
+	descriptor-&gt;open_count = 0;
+	descriptor-&gt;open_mode = 0;
+	descriptor-&gt;pos = 0;
+
+	return descriptor;
+}
+
+
+bool
+fd_close_on_exec(struct io_context *context, int fd)
+{
+	return CHECK_BIT(context-&gt;fds_close_on_exec[fd / 8], fd &amp; 7) ? true : false;
+}
+
+
+void
+fd_set_close_on_exec(struct io_context *context, int fd, bool closeFD)
+{
+	if (closeFD)
+		context-&gt;fds_close_on_exec[fd / 8] |= (1 &lt;&lt; (fd &amp; 7));
+	else
+		context-&gt;fds_close_on_exec[fd / 8] &amp;= ~(1 &lt;&lt; (fd &amp; 7));
+}
+
+
+/** Searches a free slot in the FD table of the provided I/O context, and inserts
+ *	the specified descriptor into it.
+ */
+
+int
+new_fd_etc(struct io_context *context, struct file_descriptor *descriptor, int firstIndex)
+{
+	int fd = -1;
+	uint32 i;
+
+	mutex_lock(&amp;context-&gt;io_mutex);
+
+	for (i = firstIndex; i &lt; context-&gt;table_size; i++) {
+		if (!context-&gt;fds[i]) {
+			fd = i;
+			break;
+		}
+	}
+	if (fd &lt; 0) {
+		fd = B_NO_MORE_FDS;
+		goto err;
+	}
+
+	context-&gt;fds[fd] = descriptor;
+	context-&gt;num_used_fds++;
+	atomic_add(&amp;descriptor-&gt;open_count, 1);
+
+err:
+	mutex_unlock(&amp;context-&gt;io_mutex);
+
+	return fd;
+}
+
+
+int
+new_fd(struct io_context *context, struct file_descriptor *descriptor)
+{
+	return new_fd_etc(context, descriptor, 0);
+}
+
+
+/**	Reduces the descriptor's reference counter, and frees all resources
+ *	when it's no longer used.
+ */
+
+void
+put_fd(struct file_descriptor *descriptor)
+{
+	int32 previous = atomic_add(&amp;descriptor-&gt;ref_count, -1);
+
+	TRACE((&quot;put_fd(descriptor = %p [ref = %ld, cookie = %p])\n&quot;,
+		descriptor, descriptor-&gt;ref_count, descriptor-&gt;cookie));
+
+	// free the descriptor if we don't need it anymore
+	if (previous == 1) {
+		// free the underlying object
+		if (descriptor-&gt;ops != NULL &amp;&amp; descriptor-&gt;ops-&gt;fd_free != NULL)
+			descriptor-&gt;ops-&gt;fd_free(descriptor);
+
+		free(descriptor);
+	} else if ((descriptor-&gt;open_mode &amp; O_DISCONNECTED) != 0
+		&amp;&amp; previous - 1 == descriptor-&gt;open_count
+		&amp;&amp; descriptor-&gt;ops != NULL) {
+		// the descriptor has been disconnected - it cannot
+		// be accessed anymore, let's close it (no one is
+		// currently accessing this descriptor)
+
+		if (descriptor-&gt;ops-&gt;fd_close)
+			descriptor-&gt;ops-&gt;fd_close(descriptor);
+		if (descriptor-&gt;ops-&gt;fd_free)
+			descriptor-&gt;ops-&gt;fd_free(descriptor);
+
+		// prevent this descriptor from being closed/freed again
+		descriptor-&gt;open_count = -1;
+		descriptor-&gt;ref_count = -1;
+		descriptor-&gt;ops = NULL;
+		descriptor-&gt;u.vnode = NULL;
+
+		// the file descriptor is kept intact, so that it's not
+		// reused until someone explicetly closes it
+	}
+}
+
+
+/**	Decrements the open counter of the file descriptor and invokes
+ *	its close hook when appropriate.
+ */
+
+void
+close_fd(struct file_descriptor *descriptor)
+{
+	if (atomic_add(&amp;descriptor-&gt;open_count, -1) == 1) {
+		vfs_unlock_vnode_if_locked(descriptor);
+
+		if (descriptor-&gt;ops != NULL &amp;&amp; descriptor-&gt;ops-&gt;fd_close != NULL)
+			descriptor-&gt;ops-&gt;fd_close(descriptor);
+	}
+}
+
+
+/**	This descriptor's underlying object will be closed and freed
+ *	as soon as possible (in one of the next calls to put_fd() -
+ *	get_fd() will no longer succeed on this descriptor).
+ *	This is useful if the underlying object is gone, for instance
+ *	when a (mounted) volume got removed unexpectedly.
+ */
+
+void
+disconnect_fd(struct file_descriptor *descriptor)
+{
+	descriptor-&gt;open_mode |= O_DISCONNECTED;
+}
+
+
+void
+inc_fd_ref_count(struct file_descriptor *descriptor)
+{
+	atomic_add(&amp;descriptor-&gt;ref_count, 1);
+}
+
+
+static struct file_descriptor *
+get_fd_locked(struct io_context *context, int fd)
+{
+	if (fd &lt; 0 || (uint32)fd &gt;= context-&gt;table_size)
+		return NULL;
+
+	struct file_descriptor *descriptor = context-&gt;fds[fd];
+
+	if (descriptor != NULL) {
+		// Disconnected descriptors cannot be accessed anymore
+		if (descriptor-&gt;open_mode &amp; O_DISCONNECTED)
+			descriptor = NULL;
+		else
+			inc_fd_ref_count(descriptor);
+	}
+
+	return descriptor;
+}
+
+
+struct file_descriptor *
+get_fd(struct io_context *context, int fd)
+{
+	MutexLocker(context-&gt;io_mutex);
+
+	return get_fd_locked(context, fd);
+}
+
+
+/**	Removes the file descriptor from the specified slot.
+ */
+
+static struct file_descriptor *
+remove_fd(struct io_context *context, int fd)
+{
+	struct file_descriptor *descriptor = NULL;
+
+	if (fd &lt; 0)
+		return NULL;
+
+	mutex_lock(&amp;context-&gt;io_mutex);
+
+	if ((uint32)fd &lt; context-&gt;table_size)
+		descriptor = context-&gt;fds[fd];
+
+	select_info* selectInfos = NULL;
+	bool disconnected = false;
+
+	if (descriptor)	{
+		// fd is valid
+		context-&gt;fds[fd] = NULL;
+		fd_set_close_on_exec(context, fd, false);
+		context-&gt;num_used_fds--;
+
+		selectInfos = context-&gt;select_infos[fd];
+		context-&gt;select_infos[fd] = NULL;
+
+		disconnected = (descriptor-&gt;open_mode &amp; O_DISCONNECTED);
+	}
+
+	mutex_unlock(&amp;context-&gt;io_mutex);
+
+	if (selectInfos != NULL)
+		deselect_select_infos(descriptor, selectInfos);
+
+	return disconnected ? NULL : descriptor;
+}
+
+
+static int
+dup_fd(int fd, bool kernel)
+{
+	struct io_context *context = get_current_io_context(kernel);
+	struct file_descriptor *descriptor;
+	int status;
+
+	TRACE((&quot;dup_fd: fd = %d\n&quot;, fd));
+
+	// Try to get the fd structure
+	descriptor = get_fd(context, fd);
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+	// now put the fd in place
+	status = new_fd(context, descriptor);
+	if (status &lt; 0)
+		put_fd(descriptor);
+	else {
+		mutex_lock(&amp;context-&gt;io_mutex);
+		fd_set_close_on_exec(context, status, false);
+		mutex_unlock(&amp;context-&gt;io_mutex);
+	}
+
+	return status;
+}
+
+
+/**	POSIX says this should be the same as:
+ *		close(newfd);
+ *		fcntl(oldfd, F_DUPFD, newfd);
+ *
+ *	We do dup2() directly to be thread-safe.
+ */
+static int
+dup2_fd(int oldfd, int newfd, bool kernel)
+{
+	struct file_descriptor *evicted = NULL;
+	struct io_context *context;
+
+	TRACE((&quot;dup2_fd: ofd = %d, nfd = %d\n&quot;, oldfd, newfd));
+
+	// quick check
+	if (oldfd &lt; 0 || newfd &lt; 0)
+		return B_FILE_ERROR;
+
+	// Get current I/O context and lock it
+	context = get_current_io_context(kernel);
+	mutex_lock(&amp;context-&gt;io_mutex);
+
+	// Check if the fds are valid (mutex must be locked because
+	// the table size could be changed)
+	if ((uint32)oldfd &gt;= context-&gt;table_size
+		|| (uint32)newfd &gt;= context-&gt;table_size
+		|| context-&gt;fds[oldfd] == NULL) {
+		mutex_unlock(&amp;context-&gt;io_mutex);
+		return B_FILE_ERROR;
+	}
+
+	// Check for identity, note that it cannot be made above
+	// because we always want to return an error on invalid
+	// handles
+	select_info* selectInfos = NULL;
+	if (oldfd != newfd) {
+		// Now do the work
+		evicted = context-&gt;fds[newfd];
+		selectInfos = context-&gt;select_infos[newfd];
+		context-&gt;select_infos[newfd] = NULL;
+		atomic_add(&amp;context-&gt;fds[oldfd]-&gt;ref_count, 1);
+		atomic_add(&amp;context-&gt;fds[oldfd]-&gt;open_count, 1);
+		context-&gt;fds[newfd] = context-&gt;fds[oldfd];
+
+		if (evicted == NULL)
+			context-&gt;num_used_fds++;
+	}
+
+	fd_set_close_on_exec(context, newfd, false);
+
+	mutex_unlock(&amp;context-&gt;io_mutex);
+
+	// Say bye bye to the evicted fd
+	if (evicted) {
+		deselect_select_infos(evicted, selectInfos);
+		close_fd(evicted);
+		put_fd(evicted);
+	}
+
+	return newfd;
+}
+
+
+static status_t
+fd_ioctl(bool kernelFD, int fd, ulong op, void *buffer, size_t length)
+{
+	struct file_descriptor *descriptor;
+	int status;
+
+	descriptor = get_fd(get_current_io_context(kernelFD), fd);
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+	if (descriptor-&gt;ops-&gt;fd_ioctl)
+		status = descriptor-&gt;ops-&gt;fd_ioctl(descriptor, op, buffer, length);
+	else
+		status = EOPNOTSUPP;
+
+	put_fd(descriptor);
+	return status;
+}
+
+
+static void
+deselect_select_infos(file_descriptor* descriptor, select_info* infos)
+{
+	TRACE((&quot;deselect_select_infos(%p, %p)\n&quot;, descriptor, infos));
+
+	select_info* info = infos;
+	while (info != NULL) {
+		select_sync* sync = info-&gt;sync;
+
+		// deselect the selected events
+		if (descriptor-&gt;ops-&gt;fd_deselect &amp;&amp; info-&gt;selected_events) {
+			for (uint16 event = 1; event &lt; 16; event++) {
+				if (info-&gt;selected_events &amp; SELECT_FLAG(event)) {
+					descriptor-&gt;ops-&gt;fd_deselect(descriptor, event,
+						(selectsync*)info);
+				}
+			}
+		}
+
+		info = info-&gt;next;
+		put_select_sync(sync);
+	}
+}
+
+
+status_t
+select_fd(int fd, struct select_sync* sync, uint32 ref, bool kernel)
+{
+	TRACE((&quot;select_fd(fd = %d, selectsync = %p, ref = %lu, 0x%x)\n&quot;, fd, sync, ref, sync-&gt;set[ref].selected_events));
+
+	select_info* info = &amp;sync-&gt;set[ref];
+	if (info-&gt;selected_events == 0)
+		return B_OK;
+
+	io_context* context = get_current_io_context(kernel);
+	MutexLocker locker(context-&gt;io_mutex);
+
+	struct file_descriptor* descriptor = get_fd_locked(context, fd);
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+	if (!descriptor-&gt;ops-&gt;fd_select) {
+		// if the I/O subsystem doesn't support select(), we will
+		// immediately notify the select call
+		locker.Unlock();
+		put_fd(descriptor);
+		return notify_select_events(info, info-&gt;selected_events);
+	}
+
+	// add the info to the IO context
+	info-&gt;next = context-&gt;select_infos[fd];
+	context-&gt;select_infos[fd] = info;
+
+	// as long as the info is in the list, we keep a reference to the sync
+	// object
+	atomic_add(&amp;sync-&gt;ref_count, 1);
+
+	locker.Unlock();
+
+	// select any events asked for
+	uint32 selectedEvents = 0;
+
+	for (uint16 event = 1; event &lt; 16; event++) {
+		if (info-&gt;selected_events &amp; SELECT_FLAG(event)
+			&amp;&amp; descriptor-&gt;ops-&gt;fd_select(descriptor, event, ref,
+				(selectsync*)info) == B_OK) {
+			selectedEvents |= SELECT_FLAG(event);
+		}
+	}
+	info-&gt;selected_events = selectedEvents;
+
+	// if nothing has been selected, we deselect immediately
+	if (selectedEvents == 0)
+		deselect_fd(fd, sync, ref, kernel);
+
+	put_fd(descriptor);
+	return B_OK;
+}
+
+
+status_t
+deselect_fd(int fd, struct select_sync* sync, uint32 ref, bool kernel)
+{
+	TRACE((&quot;deselect_fd(fd = %d, selectsync = %p, ref = %lu)\n&quot;, fd, sync, ref));
+
+	select_info* info = &amp;sync-&gt;set[ref];
+	if (info-&gt;selected_events == 0)
+		return B_OK;
+
+	io_context* context = get_current_io_context(kernel);
+	MutexLocker locker(context-&gt;io_mutex);
+
+	struct file_descriptor* descriptor = get_fd_locked(context, fd);
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+	// remove the info from the IO context
+
+	select_info** infoLocation = &amp;context-&gt;select_infos[fd];
+	while (*infoLocation != NULL &amp;&amp; *infoLocation != info)
+		infoLocation = &amp;(*infoLocation)-&gt;next;
+
+	// If not found, someone else beat us to it.
+	if (*infoLocation != info) {
+		locker.Unlock();
+		put_fd(descriptor);
+		return B_OK;
+	}
+
+	*infoLocation = info-&gt;next;
+
+	locker.Unlock();
+
+	// deselect the selected events
+	if (descriptor-&gt;ops-&gt;fd_deselect &amp;&amp; info-&gt;selected_events) {
+		for (uint16 event = 1; event &lt; 16; event++) {
+			if (info-&gt;selected_events &amp; SELECT_FLAG(event)) {
+				descriptor-&gt;ops-&gt;fd_deselect(descriptor, event,
+					(selectsync*)info);
+			}
+		}
+	}
+
+	put_select_sync(sync);
+
+	put_fd(descriptor);
+	return B_OK;
+}
+
+
+/** This function checks if the specified fd is valid in the current
+ *	context. It can be used for a quick check; the fd is not locked
+ *	so it could become invalid immediately after this check.
+ */
+
+bool
+fd_is_valid(int fd, bool kernel)
+{
+	struct file_descriptor *descriptor = get_fd(get_current_io_context(kernel), fd);
+	if (descriptor == NULL)
+		return false;
+
+	put_fd(descriptor);
+	return true;
+}
+
+
+struct vnode *
+fd_vnode(struct file_descriptor *descriptor)
+{
+	switch (descriptor-&gt;type) {
+		case FDTYPE_FILE:
+		case FDTYPE_DIR:
+		case FDTYPE_ATTR_DIR:
+		case FDTYPE_ATTR:
+			return descriptor-&gt;u.vnode;
+	}
+
+	return NULL;
+}
+
+
+static status_t
+common_close(int fd, bool kernel)
+{
+	struct io_context *io = get_current_io_context(kernel);
+	struct file_descriptor *descriptor = remove_fd(io, fd);
+
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+#ifdef TRACE_FD
+	if (!kernel)
+		TRACE((&quot;_user_close(descriptor = %p)\n&quot;, descriptor));
+#endif
+
+	close_fd(descriptor);
+	put_fd(descriptor);
+		// the reference associated with the slot
+
+	return B_OK;
+}
+
+
+//	#pragma mark -
+//	User syscalls
+
+
+ssize_t
+_user_read(int fd, off_t pos, void *buffer, size_t length)
+{
+	struct file_descriptor *descriptor;
+	ssize_t bytesRead;
+
+	/* This is a user_function, so abort if we have a kernel address */
+	if (!IS_USER_ADDRESS(buffer))
+		return B_BAD_ADDRESS;
+
+	if (pos &lt; -1)
+		return B_BAD_VALUE;
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (!descriptor)
+		return B_FILE_ERROR;
+	if ((descriptor-&gt;open_mode &amp; O_RWMASK) == O_WRONLY) {
+		put_fd(descriptor);
+		return B_FILE_ERROR;
+	}
+
+	if (pos == -1)
+		pos = descriptor-&gt;pos;
+
+	if (descriptor-&gt;ops-&gt;fd_read) {
+		bytesRead = descriptor-&gt;ops-&gt;fd_read(descriptor, pos, buffer, &amp;length);
+		if (bytesRead &gt;= B_OK) {
+			if (length &gt; SSIZE_MAX)
+				bytesRead = SSIZE_MAX;
+			else
+				bytesRead = (ssize_t)length;
+
+			descriptor-&gt;pos = pos + length;
+		}
+	} else
+		bytesRead = B_BAD_VALUE;
+
+	put_fd(descriptor);
+	return bytesRead;
+}
+
+
+ssize_t
+_user_readv(int fd, off_t pos, const iovec *userVecs, size_t count)
+{
+	struct file_descriptor *descriptor;
+	ssize_t bytesRead = 0;
+	status_t status;
+	iovec *vecs;
+	uint32 i;
+
+	/* This is a user_function, so abort if we have a kernel address */
+	if (!IS_USER_ADDRESS(userVecs))
+		return B_BAD_ADDRESS;
+
+	if (pos &lt; -1)
+		return B_BAD_VALUE;
+
+	/* prevent integer overflow exploit in malloc() */
+	if (count &gt; IOV_MAX)
+		return B_BAD_VALUE;
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (!descriptor)
+		return B_FILE_ERROR;
+	if ((descriptor-&gt;open_mode &amp; O_RWMASK) == O_WRONLY) {
+		status = B_FILE_ERROR;
+		goto err1;
+	}
+
+	vecs = (iovec*)malloc(sizeof(iovec) * count);
+	if (vecs == NULL) {
+		status = B_NO_MEMORY;
+		goto err1;
+	}
+
+	if (user_memcpy(vecs, userVecs, sizeof(iovec) * count) &lt; B_OK) {
+		status = B_BAD_ADDRESS;
+		goto err2;
+	}
+
+	if (pos == -1)
+		pos = descriptor-&gt;pos;
+
+	if (descriptor-&gt;ops-&gt;fd_read) {
+		for (i = 0; i &lt; count; i++) {
+			size_t length = vecs[i].iov_len;
+			status = descriptor-&gt;ops-&gt;fd_read(descriptor, pos, vecs[i].iov_base, &amp;length);
+			if (status &lt; B_OK) {
+				bytesRead = status;
+				break;
+			}
+
+			if ((uint64)bytesRead + length &gt; SSIZE_MAX)
+				bytesRead = SSIZE_MAX;
+			else
+				bytesRead += (ssize_t)length;
+
+			pos += vecs[i].iov_len;
+		}
+	} else
+		bytesRead = B_BAD_VALUE;
+
+	status = bytesRead;
+	descriptor-&gt;pos = pos;
+
+err2:
+	free(vecs);
+err1:
+	put_fd(descriptor);
+	return status;
+}
+
+
+ssize_t
+_user_write(int fd, off_t pos, const void *buffer, size_t length)
+{
+	struct file_descriptor *descriptor;
+	ssize_t bytesWritten = 0;
+
+	if (IS_KERNEL_ADDRESS(buffer))
+		return B_BAD_ADDRESS;
+
+	if (pos &lt; -1)
+		return B_BAD_VALUE;
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (!descriptor)
+		return B_FILE_ERROR;
+	if ((descriptor-&gt;open_mode &amp; O_RWMASK) == O_RDONLY) {
+		put_fd(descriptor);
+		return B_FILE_ERROR;
+	}
+
+	if (pos == -1)
+		pos = descriptor-&gt;pos;
+
+	if (descriptor-&gt;ops-&gt;fd_write) {
+		bytesWritten = descriptor-&gt;ops-&gt;fd_write(descriptor, pos, buffer, &amp;length);
+		if (bytesWritten &gt;= B_OK) {
+			if (length &gt; SSIZE_MAX)
+				bytesWritten = SSIZE_MAX;
+			else
+				bytesWritten = (ssize_t)length;
+
+			descriptor-&gt;pos = pos + length;
+		}
+	} else
+		bytesWritten = B_BAD_VALUE;
+
+	put_fd(descriptor);
+	return bytesWritten;
+}
+
+
+ssize_t
+_user_writev(int fd, off_t pos, const iovec *userVecs, size_t count)
+{
+	struct file_descriptor *descriptor;
+	ssize_t bytesWritten = 0;
+	status_t status;
+	iovec *vecs;
+	uint32 i;
+
+	/* This is a user_function, so abort if we have a kernel address */
+	if (!IS_USER_ADDRESS(userVecs))
+		return B_BAD_ADDRESS;
+
+	if (pos &lt; -1)
+		return B_BAD_VALUE;
+
+	/* prevent integer overflow exploit in malloc() */
+	if (count &gt; IOV_MAX)
+		return B_BAD_VALUE;
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (!descriptor)
+		return B_FILE_ERROR;
+	if ((descriptor-&gt;open_mode &amp; O_RWMASK) == O_RDONLY) {
+		status = B_FILE_ERROR;
+		goto err1;
+	}
+
+	vecs = (iovec*)malloc(sizeof(iovec) * count);
+	if (vecs == NULL) {
+		status = B_NO_MEMORY;
+		goto err1;
+	}
+
+	if (user_memcpy(vecs, userVecs, sizeof(iovec) * count) &lt; B_OK) {
+		status = B_BAD_ADDRESS;
+		goto err2;
+	}
+
+	if (pos == -1)
+		pos = descriptor-&gt;pos;
+
+	if (descriptor-&gt;ops-&gt;fd_write) {
+		for (i = 0; i &lt; count; i++) {
+			size_t length = vecs[i].iov_len;
+			status = descriptor-&gt;ops-&gt;fd_write(descriptor, pos, vecs[i].iov_base, &amp;length);
+			if (status &lt; B_OK) {
+				bytesWritten = status;
+				break;
+			}
+
+			if ((uint64)bytesWritten + length &gt; SSIZE_MAX)
+				bytesWritten = SSIZE_MAX;
+			else
+				bytesWritten += (ssize_t)length;
+
+			pos += vecs[i].iov_len;
+		}
+	} else
+		bytesWritten = B_BAD_VALUE;
+
+	status = bytesWritten;
+	descriptor-&gt;pos = pos;
+
+err2:
+	free(vecs);
+err1:
+	put_fd(descriptor);
+	return status;
+}
+
+
+off_t
+_user_seek(int fd, off_t pos, int seekType)
+{
+	struct file_descriptor *descriptor;
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (!descriptor)
+		return B_FILE_ERROR;
+
+	TRACE((&quot;user_seek(descriptor = %p)\n&quot;, descriptor));
+
+	if (descriptor-&gt;ops-&gt;fd_seek)
+		pos = descriptor-&gt;ops-&gt;fd_seek(descriptor, pos, seekType);
+	else
+		pos = ESPIPE;
+
+	put_fd(descriptor);
+	return pos;
+}
+
+
+status_t
+_user_ioctl(int fd, ulong op, void *buffer, size_t length)
+{
+	struct file_descriptor *descriptor;
+	int status;
+
+	if (IS_KERNEL_ADDRESS(buffer))
+		return B_BAD_ADDRESS;
+
+	TRACE((&quot;user_ioctl: fd %d\n&quot;, fd));
+
+	return fd_ioctl(false, fd, op, buffer, length);
+}
+
+
+ssize_t
+_user_read_dir(int fd, struct dirent *buffer, size_t bufferSize, uint32 maxCount)
+{
+	struct file_descriptor *descriptor;
+	ssize_t retval;
+
+	if (IS_KERNEL_ADDRESS(buffer))
+		return B_BAD_ADDRESS;
+
+	TRACE((&quot;user_read_dir(fd = %d, buffer = %p, bufferSize = %ld, count = %lu)\n&quot;, fd, buffer, bufferSize, maxCount));
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+	if (descriptor-&gt;ops-&gt;fd_read_dir) {
+		uint32 count = maxCount;
+		retval = descriptor-&gt;ops-&gt;fd_read_dir(descriptor, buffer, bufferSize, &amp;count);
+		if (retval &gt;= 0)
+			retval = count;
+	} else
+		retval = EOPNOTSUPP;
+
+	put_fd(descriptor);
+	return retval;
+}
+
+
+status_t
+_user_rewind_dir(int fd)
+{
+	struct file_descriptor *descriptor;
+	status_t status;
+
+	TRACE((&quot;user_rewind_dir(fd = %d)\n&quot;, fd));
+
+	descriptor = get_fd(get_current_io_context(false), fd);
+	if (descriptor == NULL)
+		return B_FILE_ERROR;
+
+	if (descriptor-&gt;ops-&gt;fd_rewind_dir)
+		status = descriptor-&gt;ops-&gt;fd_rewind_dir(descriptor);
+	else
+		status = EOPNOTSUPP;
+
+	put_fd(descriptor);
+	return status;
+}
+
+
+status_t
+_user_close(int fd)
+{
+	return common_close(fd, false);
+}
+
+
+int
+_user_dup(int fd)
+{
+	return dup_fd(fd, false);
+}
+
+
+int
+_user_dup2(int ofd, int nfd)
+{
+	return dup2_fd(ofd, nfd, false);
+}
+
+
+//	#pragma mark -
+//	Kernel calls

[... truncated: 955 lines follow ...]

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="004078.html">[Haiku-commits] r22390 - haiku/trunk/src/tests/system/kernel
</A></li>
	<LI>Next message: <A HREF="004080.html">[Haiku-commits] r22392 - haiku/trunk/src/add-ons/kernel/drivers/tty
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#4079">[ date ]</a>
              <a href="thread.html#4079">[ thread ]</a>
              <a href="subject.html#4079">[ subject ]</a>
              <a href="author.html#4079">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
