<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r32600 - in	haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale: .	ppc sparc x86
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2009-August/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r32600%20-%20in%0A%09haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale%3A%20.%0A%09ppc%20sparc%20x86&In-Reply-To=%3C200908221325.n7MDPeQH021102%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="019775.html">
   <LINK REL="Next"  HREF="019779.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r32600 - in	haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale: .	ppc sparc x86</H1>
    <B>korli at mail.berlios.de</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r32600%20-%20in%0A%09haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale%3A%20.%0A%09ppc%20sparc%20x86&In-Reply-To=%3C200908221325.n7MDPeQH021102%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r32600 - in	haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale: .	ppc sparc x86">korli at mail.berlios.de
       </A><BR>
    <I>Sat Aug 22 15:25:40 CEST 2009</I>
    <P><UL>
        <LI>Previous message: <A HREF="019775.html">[Haiku-commits] r32599 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale
</A></li>
        <LI>Next message: <A HREF="019779.html">[Haiku-commits] r32601 - haiku/trunk/src/kits/game
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#19777">[ date ]</a>
              <a href="thread.html#19777">[ thread ]</a>
              <a href="subject.html#19777">[ subject ]</a>
              <a href="author.html#19777">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: korli
Date: 2009-08-22 15:25:38 +0200 (Sat, 22 Aug 2009)
New Revision: 32600
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=32600&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=32600&amp;view=rev</A>

Added:
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/swscale_altivec_template.c
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/yuv2rgb_altivec.c
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/sparc/
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/sparc/yuv2rgb_vis.c
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/x86/
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/x86/yuv2rgb_mmx.c
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/x86/yuv2rgb_template.c
Modified:
   haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/Jamfile
Log:
add libswscale arch files, needed when INCLUDE_GPL_ADDONS is activated on x86


Modified: haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/Jamfile
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/Jamfile	2009-08-22 12:44:13 UTC (rev 32599)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/Jamfile	2009-08-22 13:25:38 UTC (rev 32600)
@@ -12,8 +12,14 @@
 archSources = ;
 
 if $(TARGET_ARCH) = x86 {
+	if $(INCLUDE_GPL_ADDONS) = 1 {
+		archSources += yuv2rgb_mmx.c ;
+		SubDirHdrs [ FDirName $(SUBDIR) $(TARGET_ARCH) ] ;
+	}
 } else if $(TARGET_ARCH) = ppc {
+	archSources += swscale_altivec_template.c  yuv2rgb_altivec.c ;
 } else if $(TARGET_ARCH) = sparc {
+	archSources += yuv2rgb_vis.cyuv2rgb_vis.c ;
 }
 
 SubDirCcFlags $(HAIKU_FFMPEG_GCC_EXTRA_FLAGS) ;
@@ -26,5 +32,7 @@
 	swscale.c
 	yuv2rgb.c
 
-    $(archSources)
+	$(archSources)
 ;
+
+SEARCH on [ FGristFiles $(archSources) ] += [ FDirName $(SUBDIR) $(TARGET_ARCH) ] ;

Added: haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/swscale_altivec_template.c
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/swscale_altivec_template.c	2009-08-22 12:44:13 UTC (rev 32599)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/swscale_altivec_template.c	2009-08-22 13:25:38 UTC (rev 32600)
@@ -0,0 +1,545 @@
+/*
+ * AltiVec-enhanced yuv2yuvX
+ *
+ * Copyright (C) 2004 Romain Dolbeau &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">romain at dolbeau.org</A>&gt;
+ * based on the equivalent C code in swscale.c
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#define vzero vec_splat_s32(0)
+
+static inline void
+altivec_packIntArrayToCharArray(int *val, uint8_t* dest, int dstW)
+{
+    register int i;
+    vector unsigned int altivec_vectorShiftInt19 =
+        vec_add(vec_splat_u32(10), vec_splat_u32(9));
+    if ((unsigned long)dest % 16) {
+        /* badly aligned store, we force store alignment */
+        /* and will handle load misalignment on val w/ vec_perm */
+        vector unsigned char perm1;
+        vector signed int v1;
+        for (i = 0 ; (i &lt; dstW) &amp;&amp;
+            (((unsigned long)dest + i) % 16) ; i++) {
+                int t = val[i] &gt;&gt; 19;
+                dest[i] = (t &lt; 0) ? 0 : ((t &gt; 255) ? 255 : t);
+        }
+        perm1 = vec_lvsl(i &lt;&lt; 2, val);
+        v1 = vec_ld(i &lt;&lt; 2, val);
+        for ( ; i &lt; (dstW - 15); i+=16) {
+            int offset = i &lt;&lt; 2;
+            vector signed int v2 = vec_ld(offset + 16, val);
+            vector signed int v3 = vec_ld(offset + 32, val);
+            vector signed int v4 = vec_ld(offset + 48, val);
+            vector signed int v5 = vec_ld(offset + 64, val);
+            vector signed int v12 = vec_perm(v1, v2, perm1);
+            vector signed int v23 = vec_perm(v2, v3, perm1);
+            vector signed int v34 = vec_perm(v3, v4, perm1);
+            vector signed int v45 = vec_perm(v4, v5, perm1);
+
+            vector signed int vA = vec_sra(v12, altivec_vectorShiftInt19);
+            vector signed int vB = vec_sra(v23, altivec_vectorShiftInt19);
+            vector signed int vC = vec_sra(v34, altivec_vectorShiftInt19);
+            vector signed int vD = vec_sra(v45, altivec_vectorShiftInt19);
+            vector unsigned short vs1 = vec_packsu(vA, vB);
+            vector unsigned short vs2 = vec_packsu(vC, vD);
+            vector unsigned char vf = vec_packsu(vs1, vs2);
+            vec_st(vf, i, dest);
+            v1 = v5;
+        }
+    } else { // dest is properly aligned, great
+        for (i = 0; i &lt; (dstW - 15); i+=16) {
+            int offset = i &lt;&lt; 2;
+            vector signed int v1 = vec_ld(offset, val);
+            vector signed int v2 = vec_ld(offset + 16, val);
+            vector signed int v3 = vec_ld(offset + 32, val);
+            vector signed int v4 = vec_ld(offset + 48, val);
+            vector signed int v5 = vec_sra(v1, altivec_vectorShiftInt19);
+            vector signed int v6 = vec_sra(v2, altivec_vectorShiftInt19);
+            vector signed int v7 = vec_sra(v3, altivec_vectorShiftInt19);
+            vector signed int v8 = vec_sra(v4, altivec_vectorShiftInt19);
+            vector unsigned short vs1 = vec_packsu(v5, v6);
+            vector unsigned short vs2 = vec_packsu(v7, v8);
+            vector unsigned char vf = vec_packsu(vs1, vs2);
+            vec_st(vf, i, dest);
+        }
+    }
+    for ( ; i &lt; dstW ; i++) {
+        int t = val[i] &gt;&gt; 19;
+        dest[i] = (t &lt; 0) ? 0 : ((t &gt; 255) ? 255 : t);
+    }
+}
+
+static inline void
+yuv2yuvX_altivec_real(const int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,
+                      const int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,
+                      uint8_t *dest, uint8_t *uDest, uint8_t *vDest, int dstW, int chrDstW)
+{
+    const vector signed int vini = {(1 &lt;&lt; 18), (1 &lt;&lt; 18), (1 &lt;&lt; 18), (1 &lt;&lt; 18)};
+    register int i, j;
+    {
+        DECLARE_ALIGNED(16, int, val[dstW]);
+
+        for (i = 0; i &lt; (dstW -7); i+=4) {
+            vec_st(vini, i &lt;&lt; 2, val);
+        }
+        for (; i &lt; dstW; i++) {
+            val[i] = (1 &lt;&lt; 18);
+        }
+
+        for (j = 0; j &lt; lumFilterSize; j++) {
+            vector signed short l1, vLumFilter = vec_ld(j &lt;&lt; 1, lumFilter);
+            vector unsigned char perm, perm0 = vec_lvsl(j &lt;&lt; 1, lumFilter);
+            vLumFilter = vec_perm(vLumFilter, vLumFilter, perm0);
+            vLumFilter = vec_splat(vLumFilter, 0); // lumFilter[j] is loaded 8 times in vLumFilter
+
+            perm = vec_lvsl(0, lumSrc[j]);
+            l1 = vec_ld(0, lumSrc[j]);
+
+            for (i = 0; i &lt; (dstW - 7); i+=8) {
+                int offset = i &lt;&lt; 2;
+                vector signed short l2 = vec_ld((i &lt;&lt; 1) + 16, lumSrc[j]);
+
+                vector signed int v1 = vec_ld(offset, val);
+                vector signed int v2 = vec_ld(offset + 16, val);
+
+                vector signed short ls = vec_perm(l1, l2, perm); // lumSrc[j][i] ... lumSrc[j][i+7]
+
+                vector signed int i1 = vec_mule(vLumFilter, ls);
+                vector signed int i2 = vec_mulo(vLumFilter, ls);
+
+                vector signed int vf1 = vec_mergeh(i1, i2);
+                vector signed int vf2 = vec_mergel(i1, i2); // lumSrc[j][i] * lumFilter[j] ... lumSrc[j][i+7] * lumFilter[j]
+
+                vector signed int vo1 = vec_add(v1, vf1);
+                vector signed int vo2 = vec_add(v2, vf2);
+
+                vec_st(vo1, offset, val);
+                vec_st(vo2, offset + 16, val);
+
+                l1 = l2;
+            }
+            for ( ; i &lt; dstW; i++) {
+                val[i] += lumSrc[j][i] * lumFilter[j];
+            }
+        }
+        altivec_packIntArrayToCharArray(val, dest, dstW);
+    }
+    if (uDest != 0) {
+        DECLARE_ALIGNED(16, int, u[chrDstW]);
+        DECLARE_ALIGNED(16, int, v[chrDstW]);
+
+        for (i = 0; i &lt; (chrDstW -7); i+=4) {
+            vec_st(vini, i &lt;&lt; 2, u);
+            vec_st(vini, i &lt;&lt; 2, v);
+        }
+        for (; i &lt; chrDstW; i++) {
+            u[i] = (1 &lt;&lt; 18);
+            v[i] = (1 &lt;&lt; 18);
+        }
+
+        for (j = 0; j &lt; chrFilterSize; j++) {
+            vector signed short l1, l1_V, vChrFilter = vec_ld(j &lt;&lt; 1, chrFilter);
+            vector unsigned char perm, perm0 = vec_lvsl(j &lt;&lt; 1, chrFilter);
+            vChrFilter = vec_perm(vChrFilter, vChrFilter, perm0);
+            vChrFilter = vec_splat(vChrFilter, 0); // chrFilter[j] is loaded 8 times in vChrFilter
+
+            perm = vec_lvsl(0, chrSrc[j]);
+            l1 = vec_ld(0, chrSrc[j]);
+            l1_V = vec_ld(2048 &lt;&lt; 1, chrSrc[j]);
+
+            for (i = 0; i &lt; (chrDstW - 7); i+=8) {
+                int offset = i &lt;&lt; 2;
+                vector signed short l2 = vec_ld((i &lt;&lt; 1) + 16, chrSrc[j]);
+                vector signed short l2_V = vec_ld(((i + 2048) &lt;&lt; 1) + 16, chrSrc[j]);
+
+                vector signed int v1 = vec_ld(offset, u);
+                vector signed int v2 = vec_ld(offset + 16, u);
+                vector signed int v1_V = vec_ld(offset, v);
+                vector signed int v2_V = vec_ld(offset + 16, v);
+
+                vector signed short ls = vec_perm(l1, l2, perm); // chrSrc[j][i] ... chrSrc[j][i+7]
+                vector signed short ls_V = vec_perm(l1_V, l2_V, perm); // chrSrc[j][i+2048] ... chrSrc[j][i+2055]
+
+                vector signed int i1 = vec_mule(vChrFilter, ls);
+                vector signed int i2 = vec_mulo(vChrFilter, ls);
+                vector signed int i1_V = vec_mule(vChrFilter, ls_V);
+                vector signed int i2_V = vec_mulo(vChrFilter, ls_V);
+
+                vector signed int vf1 = vec_mergeh(i1, i2);
+                vector signed int vf2 = vec_mergel(i1, i2); // chrSrc[j][i] * chrFilter[j] ... chrSrc[j][i+7] * chrFilter[j]
+                vector signed int vf1_V = vec_mergeh(i1_V, i2_V);
+                vector signed int vf2_V = vec_mergel(i1_V, i2_V); // chrSrc[j][i] * chrFilter[j] ... chrSrc[j][i+7] * chrFilter[j]
+
+                vector signed int vo1 = vec_add(v1, vf1);
+                vector signed int vo2 = vec_add(v2, vf2);
+                vector signed int vo1_V = vec_add(v1_V, vf1_V);
+                vector signed int vo2_V = vec_add(v2_V, vf2_V);
+
+                vec_st(vo1, offset, u);
+                vec_st(vo2, offset + 16, u);
+                vec_st(vo1_V, offset, v);
+                vec_st(vo2_V, offset + 16, v);
+
+                l1 = l2;
+                l1_V = l2_V;
+            }
+            for ( ; i &lt; chrDstW; i++) {
+                u[i] += chrSrc[j][i] * chrFilter[j];
+                v[i] += chrSrc[j][i + 2048] * chrFilter[j];
+            }
+        }
+        altivec_packIntArrayToCharArray(u, uDest, chrDstW);
+        altivec_packIntArrayToCharArray(v, vDest, chrDstW);
+    }
+}
+
+static inline void hScale_altivec_real(int16_t *dst, int dstW,
+                                       const uint8_t *src, int srcW,
+                                       int xInc, const int16_t *filter,
+                                       const int16_t *filterPos, int filterSize)
+{
+    register int i;
+    DECLARE_ALIGNED(16, int, tempo[4]);
+
+    if (filterSize % 4) {
+        for (i=0; i&lt;dstW; i++) {
+            register int j;
+            register int srcPos = filterPos[i];
+            register int val = 0;
+            for (j=0; j&lt;filterSize; j++) {
+                val += ((int)src[srcPos + j])*filter[filterSize*i + j];
+            }
+            dst[i] = FFMIN(val&gt;&gt;7, (1&lt;&lt;15)-1);
+        }
+    }
+    else
+    switch (filterSize) {
+    case 4:
+    {
+    for (i=0; i&lt;dstW; i++) {
+        register int srcPos = filterPos[i];
+
+        vector unsigned char src_v0 = vec_ld(srcPos, src);
+        vector unsigned char src_v1, src_vF;
+        vector signed short src_v, filter_v;
+        vector signed int val_vEven, val_s;
+        if ((((int)src + srcPos)% 16) &gt; 12) {
+            src_v1 = vec_ld(srcPos + 16, src);
+        }
+        src_vF = vec_perm(src_v0, src_v1, vec_lvsl(srcPos, src));
+
+        src_v = // vec_unpackh sign-extends...
+            (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));
+        // now put our elements in the even slots
+        src_v = vec_mergeh(src_v, (vector signed short)vzero);
+
+        filter_v = vec_ld(i &lt;&lt; 3, filter);
+        // The 3 above is 2 (filterSize == 4) + 1 (sizeof(short) == 2).
+
+        // The neat trick: We only care for half the elements,
+        // high or low depending on (i&lt;&lt;3)%16 (it's 0 or 8 here),
+        // and we're going to use vec_mule, so we choose
+        // carefully how to &quot;unpack&quot; the elements into the even slots.
+        if ((i &lt;&lt; 3) % 16)
+            filter_v = vec_mergel(filter_v, (vector signed short)vzero);
+        else
+            filter_v = vec_mergeh(filter_v, (vector signed short)vzero);
+
+        val_vEven = vec_mule(src_v, filter_v);
+        val_s = vec_sums(val_vEven, vzero);
+        vec_st(val_s, 0, tempo);
+        dst[i] = FFMIN(tempo[3]&gt;&gt;7, (1&lt;&lt;15)-1);
+    }
+    }
+    break;
+
+    case 8:
+    {
+    for (i=0; i&lt;dstW; i++) {
+        register int srcPos = filterPos[i];
+
+        vector unsigned char src_v0 = vec_ld(srcPos, src);
+        vector unsigned char src_v1, src_vF;
+        vector signed short src_v, filter_v;
+        vector signed int val_v, val_s;
+        if ((((int)src + srcPos)% 16) &gt; 8) {
+            src_v1 = vec_ld(srcPos + 16, src);
+        }
+        src_vF = vec_perm(src_v0, src_v1, vec_lvsl(srcPos, src));
+
+        src_v = // vec_unpackh sign-extends...
+            (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));
+        filter_v = vec_ld(i &lt;&lt; 4, filter);
+        // the 4 above is 3 (filterSize == 8) + 1 (sizeof(short) == 2)
+
+        val_v = vec_msums(src_v, filter_v, (vector signed int)vzero);
+        val_s = vec_sums(val_v, vzero);
+        vec_st(val_s, 0, tempo);
+        dst[i] = FFMIN(tempo[3]&gt;&gt;7, (1&lt;&lt;15)-1);
+    }
+    }
+    break;
+
+    case 16:
+    {
+        for (i=0; i&lt;dstW; i++) {
+            register int srcPos = filterPos[i];
+
+            vector unsigned char src_v0 = vec_ld(srcPos, src);
+            vector unsigned char src_v1 = vec_ld(srcPos + 16, src);
+            vector unsigned char src_vF = vec_perm(src_v0, src_v1, vec_lvsl(srcPos, src));
+
+            vector signed short src_vA = // vec_unpackh sign-extends...
+                (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));
+            vector signed short src_vB = // vec_unpackh sign-extends...
+                (vector signed short)(vec_mergel((vector unsigned char)vzero, src_vF));
+
+            vector signed short filter_v0 = vec_ld(i &lt;&lt; 5, filter);
+            vector signed short filter_v1 = vec_ld((i &lt;&lt; 5) + 16, filter);
+            // the 5 above are 4 (filterSize == 16) + 1 (sizeof(short) == 2)
+
+            vector signed int val_acc = vec_msums(src_vA, filter_v0, (vector signed int)vzero);
+            vector signed int val_v = vec_msums(src_vB, filter_v1, val_acc);
+
+            vector signed int val_s = vec_sums(val_v, vzero);
+
+            vec_st(val_s, 0, tempo);
+            dst[i] = FFMIN(tempo[3]&gt;&gt;7, (1&lt;&lt;15)-1);
+        }
+    }
+    break;
+
+    default:
+    {
+    for (i=0; i&lt;dstW; i++) {
+        register int j;
+        register int srcPos = filterPos[i];
+
+        vector signed int val_s, val_v = (vector signed int)vzero;
+        vector signed short filter_v0R = vec_ld(i * 2 * filterSize, filter);
+        vector unsigned char permF = vec_lvsl((i * 2 * filterSize), filter);
+
+        vector unsigned char src_v0 = vec_ld(srcPos, src);
+        vector unsigned char permS = vec_lvsl(srcPos, src);
+
+        for (j = 0 ; j &lt; filterSize - 15; j += 16) {
+            vector unsigned char src_v1 = vec_ld(srcPos + j + 16, src);
+            vector unsigned char src_vF = vec_perm(src_v0, src_v1, permS);
+
+            vector signed short src_vA = // vec_unpackh sign-extends...
+                (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));
+            vector signed short src_vB = // vec_unpackh sign-extends...
+                (vector signed short)(vec_mergel((vector unsigned char)vzero, src_vF));
+
+            vector signed short filter_v1R = vec_ld((i * 2 * filterSize) + (j * 2) + 16, filter);
+            vector signed short filter_v2R = vec_ld((i * 2 * filterSize) + (j * 2) + 32, filter);
+            vector signed short filter_v0  = vec_perm(filter_v0R, filter_v1R, permF);
+            vector signed short filter_v1  = vec_perm(filter_v1R, filter_v2R, permF);
+
+            vector signed int val_acc = vec_msums(src_vA, filter_v0, val_v);
+            val_v = vec_msums(src_vB, filter_v1, val_acc);
+
+            filter_v0R = filter_v2R;
+            src_v0 = src_v1;
+        }
+
+        if (j &lt; filterSize-7) {
+            // loading src_v0 is useless, it's already done above
+            //vector unsigned char src_v0 = vec_ld(srcPos + j, src);
+            vector unsigned char src_v1, src_vF;
+            vector signed short src_v, filter_v1R, filter_v;
+            if ((((int)src + srcPos)% 16) &gt; 8) {
+                src_v1 = vec_ld(srcPos + j + 16, src);
+            }
+            src_vF = vec_perm(src_v0, src_v1, permS);
+
+            src_v = // vec_unpackh sign-extends...
+                (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));
+            // loading filter_v0R is useless, it's already done above
+            //vector signed short filter_v0R = vec_ld((i * 2 * filterSize) + j, filter);
+            filter_v1R = vec_ld((i * 2 * filterSize) + (j * 2) + 16, filter);
+            filter_v = vec_perm(filter_v0R, filter_v1R, permF);
+
+            val_v = vec_msums(src_v, filter_v, val_v);
+        }
+
+        val_s = vec_sums(val_v, vzero);
+
+        vec_st(val_s, 0, tempo);
+        dst[i] = FFMIN(tempo[3]&gt;&gt;7, (1&lt;&lt;15)-1);
+    }
+
+    }
+    }
+}
+
+static inline int yv12toyuy2_unscaled_altivec(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+                                              int srcSliceH, uint8_t* dstParam[], int dstStride_a[])
+{
+    uint8_t *dst=dstParam[0] + dstStride_a[0]*srcSliceY;
+    // yv12toyuy2(src[0], src[1], src[2], dst, c-&gt;srcW, srcSliceH, srcStride[0], srcStride[1], dstStride[0]);
+    uint8_t *ysrc = src[0];
+    uint8_t *usrc = src[1];
+    uint8_t *vsrc = src[2];
+    const int width = c-&gt;srcW;
+    const int height = srcSliceH;
+    const int lumStride = srcStride[0];
+    const int chromStride = srcStride[1];
+    const int dstStride = dstStride_a[0];
+    const vector unsigned char yperm = vec_lvsl(0, ysrc);
+    const int vertLumPerChroma = 2;
+    register unsigned int y;
+
+    if (width&amp;15) {
+        yv12toyuy2(ysrc, usrc, vsrc, dst, c-&gt;srcW, srcSliceH, lumStride, chromStride, dstStride);
+        return srcSliceH;
+    }
+
+    /* This code assumes:
+
+    1) dst is 16 bytes-aligned
+    2) dstStride is a multiple of 16
+    3) width is a multiple of 16
+    4) lum &amp; chrom stride are multiples of 8
+    */
+
+    for (y=0; y&lt;height; y++) {
+        int i;
+        for (i = 0; i &lt; width - 31; i+= 32) {
+            const unsigned int j = i &gt;&gt; 1;
+            vector unsigned char v_yA = vec_ld(i, ysrc);
+            vector unsigned char v_yB = vec_ld(i + 16, ysrc);
+            vector unsigned char v_yC = vec_ld(i + 32, ysrc);
+            vector unsigned char v_y1 = vec_perm(v_yA, v_yB, yperm);
+            vector unsigned char v_y2 = vec_perm(v_yB, v_yC, yperm);
+            vector unsigned char v_uA = vec_ld(j, usrc);
+            vector unsigned char v_uB = vec_ld(j + 16, usrc);
+            vector unsigned char v_u = vec_perm(v_uA, v_uB, vec_lvsl(j, usrc));
+            vector unsigned char v_vA = vec_ld(j, vsrc);
+            vector unsigned char v_vB = vec_ld(j + 16, vsrc);
+            vector unsigned char v_v = vec_perm(v_vA, v_vB, vec_lvsl(j, vsrc));
+            vector unsigned char v_uv_a = vec_mergeh(v_u, v_v);
+            vector unsigned char v_uv_b = vec_mergel(v_u, v_v);
+            vector unsigned char v_yuy2_0 = vec_mergeh(v_y1, v_uv_a);
+            vector unsigned char v_yuy2_1 = vec_mergel(v_y1, v_uv_a);
+            vector unsigned char v_yuy2_2 = vec_mergeh(v_y2, v_uv_b);
+            vector unsigned char v_yuy2_3 = vec_mergel(v_y2, v_uv_b);
+            vec_st(v_yuy2_0, (i &lt;&lt; 1), dst);
+            vec_st(v_yuy2_1, (i &lt;&lt; 1) + 16, dst);
+            vec_st(v_yuy2_2, (i &lt;&lt; 1) + 32, dst);
+            vec_st(v_yuy2_3, (i &lt;&lt; 1) + 48, dst);
+        }
+        if (i &lt; width) {
+            const unsigned int j = i &gt;&gt; 1;
+            vector unsigned char v_y1 = vec_ld(i, ysrc);
+            vector unsigned char v_u = vec_ld(j, usrc);
+            vector unsigned char v_v = vec_ld(j, vsrc);
+            vector unsigned char v_uv_a = vec_mergeh(v_u, v_v);
+            vector unsigned char v_yuy2_0 = vec_mergeh(v_y1, v_uv_a);
+            vector unsigned char v_yuy2_1 = vec_mergel(v_y1, v_uv_a);
+            vec_st(v_yuy2_0, (i &lt;&lt; 1), dst);
+            vec_st(v_yuy2_1, (i &lt;&lt; 1) + 16, dst);
+        }
+        if ((y&amp;(vertLumPerChroma-1)) == vertLumPerChroma-1) {
+            usrc += chromStride;
+            vsrc += chromStride;
+        }
+        ysrc += lumStride;
+        dst += dstStride;
+    }
+
+    return srcSliceH;
+}
+
+static inline int yv12touyvy_unscaled_altivec(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,
+                                              int srcSliceH, uint8_t* dstParam[], int dstStride_a[])
+{
+    uint8_t *dst=dstParam[0] + dstStride_a[0]*srcSliceY;
+    // yv12toyuy2(src[0], src[1], src[2], dst, c-&gt;srcW, srcSliceH, srcStride[0], srcStride[1], dstStride[0]);
+    uint8_t *ysrc = src[0];
+    uint8_t *usrc = src[1];
+    uint8_t *vsrc = src[2];
+    const int width = c-&gt;srcW;
+    const int height = srcSliceH;
+    const int lumStride = srcStride[0];
+    const int chromStride = srcStride[1];
+    const int dstStride = dstStride_a[0];
+    const int vertLumPerChroma = 2;
+    const vector unsigned char yperm = vec_lvsl(0, ysrc);
+    register unsigned int y;
+
+    if (width&amp;15) {
+        yv12touyvy(ysrc, usrc, vsrc, dst, c-&gt;srcW, srcSliceH, lumStride, chromStride, dstStride);
+        return srcSliceH;
+    }
+
+    /* This code assumes:
+
+    1) dst is 16 bytes-aligned
+    2) dstStride is a multiple of 16
+    3) width is a multiple of 16
+    4) lum &amp; chrom stride are multiples of 8
+    */
+
+    for (y=0; y&lt;height; y++) {
+        int i;
+        for (i = 0; i &lt; width - 31; i+= 32) {
+            const unsigned int j = i &gt;&gt; 1;
+            vector unsigned char v_yA = vec_ld(i, ysrc);
+            vector unsigned char v_yB = vec_ld(i + 16, ysrc);
+            vector unsigned char v_yC = vec_ld(i + 32, ysrc);
+            vector unsigned char v_y1 = vec_perm(v_yA, v_yB, yperm);
+            vector unsigned char v_y2 = vec_perm(v_yB, v_yC, yperm);
+            vector unsigned char v_uA = vec_ld(j, usrc);
+            vector unsigned char v_uB = vec_ld(j + 16, usrc);
+            vector unsigned char v_u = vec_perm(v_uA, v_uB, vec_lvsl(j, usrc));
+            vector unsigned char v_vA = vec_ld(j, vsrc);
+            vector unsigned char v_vB = vec_ld(j + 16, vsrc);
+            vector unsigned char v_v = vec_perm(v_vA, v_vB, vec_lvsl(j, vsrc));
+            vector unsigned char v_uv_a = vec_mergeh(v_u, v_v);
+            vector unsigned char v_uv_b = vec_mergel(v_u, v_v);
+            vector unsigned char v_uyvy_0 = vec_mergeh(v_uv_a, v_y1);
+            vector unsigned char v_uyvy_1 = vec_mergel(v_uv_a, v_y1);
+            vector unsigned char v_uyvy_2 = vec_mergeh(v_uv_b, v_y2);
+            vector unsigned char v_uyvy_3 = vec_mergel(v_uv_b, v_y2);
+            vec_st(v_uyvy_0, (i &lt;&lt; 1), dst);
+            vec_st(v_uyvy_1, (i &lt;&lt; 1) + 16, dst);
+            vec_st(v_uyvy_2, (i &lt;&lt; 1) + 32, dst);
+            vec_st(v_uyvy_3, (i &lt;&lt; 1) + 48, dst);
+        }
+        if (i &lt; width) {
+            const unsigned int j = i &gt;&gt; 1;
+            vector unsigned char v_y1 = vec_ld(i, ysrc);
+            vector unsigned char v_u = vec_ld(j, usrc);
+            vector unsigned char v_v = vec_ld(j, vsrc);
+            vector unsigned char v_uv_a = vec_mergeh(v_u, v_v);
+            vector unsigned char v_uyvy_0 = vec_mergeh(v_uv_a, v_y1);
+            vector unsigned char v_uyvy_1 = vec_mergel(v_uv_a, v_y1);
+            vec_st(v_uyvy_0, (i &lt;&lt; 1), dst);
+            vec_st(v_uyvy_1, (i &lt;&lt; 1) + 16, dst);
+        }
+        if ((y&amp;(vertLumPerChroma-1)) == vertLumPerChroma-1) {
+            usrc += chromStride;
+            vsrc += chromStride;
+        }
+        ysrc += lumStride;
+        dst += dstStride;
+    }
+    return srcSliceH;
+}

Added: haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/yuv2rgb_altivec.c
===================================================================
--- haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/yuv2rgb_altivec.c	2009-08-22 12:44:13 UTC (rev 32599)
+++ haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale/ppc/yuv2rgb_altivec.c	2009-08-22 13:25:38 UTC (rev 32600)
@@ -0,0 +1,953 @@
+/*
+ * AltiVec acceleration for colorspace conversion
+ *
+ * copyright (C) 2004 Marc Hoffman &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">marc.hoffman at analog.com</A>&gt;
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/*
+Convert I420 YV12 to RGB in various formats,
+  it rejects images that are not in 420 formats,
+  it rejects images that don't have widths of multiples of 16,
+  it rejects images that don't have heights of multiples of 2.
+Reject defers to C simulation code.
+
+Lots of optimizations to be done here.
+
+1. Need to fix saturation code. I just couldn't get it to fly with packs
+   and adds, so we currently use max/min to clip.
+
+2. The inefficient use of chroma loading needs a bit of brushing up.
+
+3. Analysis of pipeline stalls needs to be done. Use shark to identify
+   pipeline stalls.
+
+
+MODIFIED to calculate coeffs from currently selected color space.
+MODIFIED core to be a macro where you specify the output format.
+ADDED UYVY conversion which is never called due to some thing in swscale.
+CORRECTED algorithim selection to be strict on input formats.
+ADDED runtime detection of AltiVec.
+
+ADDED altivec_yuv2packedX vertical scl + RGB converter
+
+March 27,2004
+PERFORMANCE ANALYSIS
+
+The C version uses 25% of the processor or ~250Mips for D1 video rawvideo
+used as test.
+The AltiVec version uses 10% of the processor or ~100Mips for D1 video
+same sequence.
+
+720 * 480 * 30  ~10MPS
+
+so we have roughly 10 clocks per pixel. This is too high, something has
+to be wrong.
+
+OPTIMIZED clip codes to utilize vec_max and vec_packs removing the
+need for vec_min.
+
+OPTIMIZED DST OUTPUT cache/DMA controls. We are pretty much guaranteed to have
+the input video frame, it was just decompressed so it probably resides in L1
+caches. However, we are creating the output video stream. This needs to use the
+DSTST instruction to optimize for the cache. We couple this with the fact that
+we are not going to be visiting the input buffer again so we mark it Least
+Recently Used. This shaves 25% of the processor cycles off.
+
+Now memcpy is the largest mips consumer in the system, probably due
+to the inefficient X11 stuff.
+
+GL libraries seem to be very slow on this machine 1.33Ghz PB running
+Jaguar, this is not the case for my 1Ghz PB.  I thought it might be
+a versioning issue, however I have libGL.1.2.dylib for both
+machines. (We need to figure this out now.)
+
+GL2 libraries work now with patch for RGB32.
+
+NOTE: quartz vo driver ARGB32_to_RGB24 consumes 30% of the processor.
+
+Integrated luma prescaling adjustment for saturation/contrast/brightness
+adjustment.
+*/
+
+#include &lt;stdio.h&gt;
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+#include &lt;inttypes.h&gt;
+#include &lt;assert.h&gt;
+#include &quot;config.h&quot;
+#include &quot;libswscale/rgb2rgb.h&quot;
+#include &quot;libswscale/swscale.h&quot;
+#include &quot;libswscale/swscale_internal.h&quot;
+
+#undef PROFILE_THE_BEAST
+#undef INC_SCALING
+
+typedef unsigned char ubyte;
+typedef signed char   sbyte;
+
+
+/* RGB interleaver, 16 planar pels 8-bit samples per channel in
+   homogeneous vector registers x0,x1,x2 are interleaved with the
+   following technique:
+
+      o0 = vec_mergeh (x0,x1);
+      o1 = vec_perm (o0, x2, perm_rgb_0);
+      o2 = vec_perm (o0, x2, perm_rgb_1);
+      o3 = vec_mergel (x0,x1);
+      o4 = vec_perm (o3,o2,perm_rgb_2);
+      o5 = vec_perm (o3,o2,perm_rgb_3);
+
+  perm_rgb_0:   o0(RG).h v1(B) --&gt; o1*
+              0   1  2   3   4
+             rgbr|gbrg|brgb|rgbr
+             0010 0100 1001 0010
+             0102 3145 2673 894A
+
+  perm_rgb_1:   o0(RG).h v1(B) --&gt; o2
+              0   1  2   3   4
+             gbrg|brgb|bbbb|bbbb
+             0100 1001 1111 1111
+             B5CD 6EF7 89AB CDEF
+
+  perm_rgb_2:   o3(RG).l o2(rgbB.l) --&gt; o4*
+              0   1  2   3   4
+             gbrg|brgb|rgbr|gbrg
+             1111 1111 0010 0100
+             89AB CDEF 0182 3945
+
+  perm_rgb_2:   o3(RG).l o2(rgbB.l) ---&gt; o5*
+              0   1  2   3   4
+             brgb|rgbr|gbrg|brgb
+             1001 0010 0100 1001
+             a67b 89cA BdCD eEFf
+
+*/
+static
+const vector unsigned char
+  perm_rgb_0 = {0x00,0x01,0x10,0x02,0x03,0x11,0x04,0x05,
+                0x12,0x06,0x07,0x13,0x08,0x09,0x14,0x0a},
+  perm_rgb_1 = {0x0b,0x15,0x0c,0x0d,0x16,0x0e,0x0f,0x17,
+                0x18,0x19,0x1a,0x1b,0x1c,0x1d,0x1e,0x1f},
+  perm_rgb_2 = {0x10,0x11,0x12,0x13,0x14,0x15,0x16,0x17,
+                0x00,0x01,0x18,0x02,0x03,0x19,0x04,0x05},
+  perm_rgb_3 = {0x1a,0x06,0x07,0x1b,0x08,0x09,0x1c,0x0a,
+                0x0b,0x1d,0x0c,0x0d,0x1e,0x0e,0x0f,0x1f};
+
+#define vec_merge3(x2,x1,x0,y0,y1,y2)       \
+do {                                        \
+    __typeof__(x0) o0,o2,o3;                \
+        o0 = vec_mergeh (x0,x1);            \
+        y0 = vec_perm (o0, x2, perm_rgb_0); \
+        o2 = vec_perm (o0, x2, perm_rgb_1); \
+        o3 = vec_mergel (x0,x1);            \
+        y1 = vec_perm (o3,o2,perm_rgb_2);   \
+        y2 = vec_perm (o3,o2,perm_rgb_3);   \
+} while(0)
+
+#define vec_mstbgr24(x0,x1,x2,ptr)      \
+do {                                    \
+    __typeof__(x0) _0,_1,_2;            \
+    vec_merge3 (x0,x1,x2,_0,_1,_2);     \
+    vec_st (_0, 0, ptr++);              \
+    vec_st (_1, 0, ptr++);              \
+    vec_st (_2, 0, ptr++);              \
+}  while (0);
+
+#define vec_mstrgb24(x0,x1,x2,ptr)      \
+do {                                    \
+    __typeof__(x0) _0,_1,_2;            \
+    vec_merge3 (x2,x1,x0,_0,_1,_2);     \
+    vec_st (_0, 0, ptr++);              \
+    vec_st (_1, 0, ptr++);              \
+    vec_st (_2, 0, ptr++);              \
+}  while (0);
+
+/* pack the pixels in rgb0 format
+   msb R
+   lsb 0
+*/
+#define vec_mstrgb32(T,x0,x1,x2,x3,ptr)                                       \
+do {                                                                          \
+    T _0,_1,_2,_3;                                                            \
+    _0 = vec_mergeh (x0,x1);                                                  \
+    _1 = vec_mergeh (x2,x3);                                                  \
+    _2 = (T)vec_mergeh ((vector unsigned short)_0,(vector unsigned short)_1); \
+    _3 = (T)vec_mergel ((vector unsigned short)_0,(vector unsigned short)_1); \
+    vec_st (_2, 0*16, (T *)ptr);                                              \
+    vec_st (_3, 1*16, (T *)ptr);                                              \
+    _0 = vec_mergel (x0,x1);                                                  \
+    _1 = vec_mergel (x2,x3);                                                  \
+    _2 = (T)vec_mergeh ((vector unsigned short)_0,(vector unsigned short)_1); \
+    _3 = (T)vec_mergel ((vector unsigned short)_0,(vector unsigned short)_1); \
+    vec_st (_2, 2*16, (T *)ptr);                                              \
+    vec_st (_3, 3*16, (T *)ptr);                                              \
+    ptr += 4;                                                                 \
+}  while (0);
+
+/*
+
+  | 1     0       1.4021   | | Y |
+  | 1    -0.3441 -0.7142   |x| Cb|
+  | 1     1.7718  0        | | Cr|
+
+
+  Y:      [-128 127]
+  Cb/Cr : [-128 127]
+
+  typical yuv conversion work on Y: 0-255 this version has been optimized for jpeg decode.
+
+*/
+
+
+
+
+#define vec_unh(x) \
+    (vector signed short) \
+        vec_perm(x,(__typeof__(x)){0}, \
+                 ((vector unsigned char){0x10,0x00,0x10,0x01,0x10,0x02,0x10,0x03,\
+                                         0x10,0x04,0x10,0x05,0x10,0x06,0x10,0x07}))
+#define vec_unl(x) \
+    (vector signed short) \
+        vec_perm(x,(__typeof__(x)){0}, \
+                 ((vector unsigned char){0x10,0x08,0x10,0x09,0x10,0x0A,0x10,0x0B,\
+                                         0x10,0x0C,0x10,0x0D,0x10,0x0E,0x10,0x0F}))
+
+#define vec_clip_s16(x) \
+    vec_max (vec_min (x, ((vector signed short){235,235,235,235,235,235,235,235})), \
+                         ((vector signed short){ 16, 16, 16, 16, 16, 16, 16, 16}))
+
+#define vec_packclp(x,y) \
+    (vector unsigned char)vec_packs \
+        ((vector unsigned short)vec_max (x,((vector signed short) {0})), \
+         (vector unsigned short)vec_max (y,((vector signed short) {0})))
+
+//#define out_pixels(a,b,c,ptr) vec_mstrgb32(__typeof__(a),((__typeof__ (a)){255}),a,a,a,ptr)
+
+
+static inline void cvtyuvtoRGB (SwsContext *c,
+                                vector signed short Y, vector signed short U, vector signed short V,
+                                vector signed short *R, vector signed short *G, vector signed short *B)
+{
+    vector signed   short vx,ux,uvx;
+
+    Y = vec_mradds (Y, c-&gt;CY, c-&gt;OY);
+    U  = vec_sub (U,(vector signed short)
+                    vec_splat((vector signed short){128},0));
+    V  = vec_sub (V,(vector signed short)
+                    vec_splat((vector signed short){128},0));
+
+    //   ux  = (CBU*(u&lt;&lt;c-&gt;CSHIFT)+0x4000)&gt;&gt;15;
+    ux = vec_sl (U, c-&gt;CSHIFT);
+    *B = vec_mradds (ux, c-&gt;CBU, Y);
+
+    // vx  = (CRV*(v&lt;&lt;c-&gt;CSHIFT)+0x4000)&gt;&gt;15;
+    vx = vec_sl (V, c-&gt;CSHIFT);
+    *R = vec_mradds (vx, c-&gt;CRV, Y);
+
+    // uvx = ((CGU*u) + (CGV*v))&gt;&gt;15;
+    uvx = vec_mradds (U, c-&gt;CGU, Y);
+    *G  = vec_mradds (V, c-&gt;CGV, uvx);
+}
+
+
+/*
+  ------------------------------------------------------------------------------
+  CS converters
+  ------------------------------------------------------------------------------
+*/
+
+
+#define DEFCSP420_CVT(name,out_pixels)                                  \
+static int altivec_##name (SwsContext *c,                               \
+                           unsigned char **in, int *instrides,          \
+                           int srcSliceY,        int srcSliceH,         \
+                           unsigned char **oplanes, int *outstrides)    \
+{                                                                       \
+    int w = c-&gt;srcW;                                                    \
+    int h = srcSliceH;                                                  \
+    int i,j;                                                            \
+    int instrides_scl[3];                                               \
+    vector unsigned char y0,y1;                                         \
+                                                                        \
+    vector signed char  u,v;                                            \
+                                                                        \
+    vector signed short Y0,Y1,Y2,Y3;                                    \
+    vector signed short U,V;                                            \
+    vector signed short vx,ux,uvx;                                      \
+    vector signed short vx0,ux0,uvx0;                                   \
+    vector signed short vx1,ux1,uvx1;                                   \
+    vector signed short R0,G0,B0;                                       \
+    vector signed short R1,G1,B1;                                       \
+    vector unsigned char R,G,B;                                         \
+                                                                        \
+    vector unsigned char *y1ivP, *y2ivP, *uivP, *vivP;                  \
+    vector unsigned char align_perm;                                    \
+                                                                        \
+    vector signed short                                                 \
+        lCY  = c-&gt;CY,                                                   \
+        lOY  = c-&gt;OY,                                                   \
+        lCRV = c-&gt;CRV,                                                  \
+        lCBU = c-&gt;CBU,                                                  \
+        lCGU = c-&gt;CGU,                                                  \
+        lCGV = c-&gt;CGV;                                                  \
+                                                                        \
+    vector unsigned short lCSHIFT = c-&gt;CSHIFT;                          \
+                                                                        \
+    ubyte *y1i   = in[0];                                               \
+    ubyte *y2i   = in[0]+instrides[0];                                  \
+    ubyte *ui    = in[1];                                               \
+    ubyte *vi    = in[2];                                               \
+                                                                        \
+    vector unsigned char *oute                                          \
+        = (vector unsigned char *)                                      \
+            (oplanes[0]+srcSliceY*outstrides[0]);                       \
+    vector unsigned char *outo                                          \
+        = (vector unsigned char *)                                      \
+            (oplanes[0]+srcSliceY*outstrides[0]+outstrides[0]);         \
+                                                                        \
+                                                                        \
+    instrides_scl[0] = instrides[0]*2-w;  /* the loop moves y{1,2}i by w */ \
+    instrides_scl[1] = instrides[1]-w/2;  /* the loop moves ui by w/2 */    \
+    instrides_scl[2] = instrides[2]-w/2;  /* the loop moves vi by w/2 */    \
+                                                                        \
+                                                                        \
+    for (i=0;i&lt;h/2;i++) {                                               \
+        vec_dstst (outo, (0x02000002|(((w*3+32)/32)&lt;&lt;16)), 0);          \
+        vec_dstst (oute, (0x02000002|(((w*3+32)/32)&lt;&lt;16)), 1);          \
+                                                                        \
+        for (j=0;j&lt;w/16;j++) {                                          \
+                                                                        \
+            y1ivP = (vector unsigned char *)y1i;                        \
+            y2ivP = (vector unsigned char *)y2i;                        \
+            uivP  = (vector unsigned char *)ui;                         \
+            vivP  = (vector unsigned char *)vi;                         \
+                                                                        \
+            align_perm = vec_lvsl (0, y1i);                             \
+            y0 = (vector unsigned char)                                 \
+                 vec_perm (y1ivP[0], y1ivP[1], align_perm);             \
+                                                                        \
+            align_perm = vec_lvsl (0, y2i);                             \
+            y1 = (vector unsigned char)                                 \
+                 vec_perm (y2ivP[0], y2ivP[1], align_perm);             \
+                                                                        \
+            align_perm = vec_lvsl (0, ui);                              \
+            u = (vector signed char)                                    \
+                vec_perm (uivP[0], uivP[1], align_perm);                \
+                                                                        \
+            align_perm = vec_lvsl (0, vi);                              \
+            v = (vector signed char)                                    \
+                vec_perm (vivP[0], vivP[1], align_perm);                \
+                                                                        \
+            u  = (vector signed char)                                   \
+                 vec_sub (u,(vector signed char)                        \
+                          vec_splat((vector signed char){128},0));      \
+            v  = (vector signed char)                                   \
+                 vec_sub (v,(vector signed char)                        \
+                          vec_splat((vector signed char){128},0));      \
+                                                                        \
+            U  = vec_unpackh (u);                                       \
+            V  = vec_unpackh (v);                                       \
+                                                                        \
+                                                                        \
+            Y0 = vec_unh (y0);                                          \
+            Y1 = vec_unl (y0);                                          \
+            Y2 = vec_unh (y1);                                          \
+            Y3 = vec_unl (y1);                                          \
+                                                                        \
+            Y0 = vec_mradds (Y0, lCY, lOY);                             \
+            Y1 = vec_mradds (Y1, lCY, lOY);                             \
+            Y2 = vec_mradds (Y2, lCY, lOY);                             \
+            Y3 = vec_mradds (Y3, lCY, lOY);                             \
+                                                                        \
+            /*   ux  = (CBU*(u&lt;&lt;CSHIFT)+0x4000)&gt;&gt;15 */                  \
+            ux = vec_sl (U, lCSHIFT);                                   \
+            ux = vec_mradds (ux, lCBU, (vector signed short){0});       \
+            ux0  = vec_mergeh (ux,ux);                                  \
+            ux1  = vec_mergel (ux,ux);                                  \
+                                                                        \
+            /* vx  = (CRV*(v&lt;&lt;CSHIFT)+0x4000)&gt;&gt;15;        */            \
+            vx = vec_sl (V, lCSHIFT);                                   \
+            vx = vec_mradds (vx, lCRV, (vector signed short){0});       \
+            vx0  = vec_mergeh (vx,vx);                                  \
+            vx1  = vec_mergel (vx,vx);                                  \
+                                                                        \
+            /* uvx = ((CGU*u) + (CGV*v))&gt;&gt;15 */                         \
+            uvx = vec_mradds (U, lCGU, (vector signed short){0});       \
+            uvx = vec_mradds (V, lCGV, uvx);                            \
+            uvx0 = vec_mergeh (uvx,uvx);                                \
+            uvx1 = vec_mergel (uvx,uvx);                                \
+                                                                        \
+            R0 = vec_add (Y0,vx0);                                      \
+            G0 = vec_add (Y0,uvx0);                                     \
+            B0 = vec_add (Y0,ux0);                                      \
+            R1 = vec_add (Y1,vx1);                                      \
+            G1 = vec_add (Y1,uvx1);                                     \
+            B1 = vec_add (Y1,ux1);                                      \
+                                                                        \
+            R  = vec_packclp (R0,R1);                                   \
+            G  = vec_packclp (G0,G1);                                   \
+            B  = vec_packclp (B0,B1);                                   \
+                                                                        \
+            out_pixels(R,G,B,oute);                                     \
+                                                                        \
+            R0 = vec_add (Y2,vx0);                                      \
+            G0 = vec_add (Y2,uvx0);                                     \
+            B0 = vec_add (Y2,ux0);                                      \
+            R1 = vec_add (Y3,vx1);                                      \
+            G1 = vec_add (Y3,uvx1);                                     \
+            B1 = vec_add (Y3,ux1);                                      \
+            R  = vec_packclp (R0,R1);                                   \

[... truncated: 1413 lines follow ...]

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="019775.html">[Haiku-commits] r32599 -	haiku/trunk/src/add-ons/media/plugins/ffmpeg/libswscale
</A></li>
	<LI>Next message: <A HREF="019779.html">[Haiku-commits] r32601 - haiku/trunk/src/kits/game
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#19777">[ date ]</a>
              <a href="thread.html#19777">[ thread ]</a>
              <a href="subject.html#19777">[ subject ]</a>
              <a href="author.html#19777">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
