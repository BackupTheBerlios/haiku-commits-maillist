<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r20518 -	haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2007-April/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r20518%20-%0A%09haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server&In-Reply-To=%3C200704022344.l32NiPW9021552%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001350.html">
   <LINK REL="Next"  HREF="001352.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r20518 -	haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server</H1>
    <B>bonefish at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r20518%20-%0A%09haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server&In-Reply-To=%3C200704022344.l32NiPW9021552%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r20518 -	haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server">bonefish at mail.berlios.de
       </A><BR>
    <I>Tue Apr  3 01:44:25 CEST 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001350.html">[Haiku-commits] r20517 - haiku/trunk/src/kits/app
</A></li>
        <LI>Next message: <A HREF="001352.html">[Haiku-commits] r20518 - haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1351">[ date ]</a>
              <a href="thread.html#1351">[ thread ]</a>
              <a href="subject.html#1351">[ subject ]</a>
              <a href="author.html#1351">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: bonefish
Date: 2007-04-03 01:44:24 +0200 (Tue, 03 Apr 2007)
New Revision: 20518
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=20518&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=20518&amp;view=rev</A>

Modified:
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp
Log:
Synchronized with kernel file cache changes in r20509.


Modified: haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp	2007-04-02 22:53:01 UTC (rev 20517)
+++ haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp	2007-04-02 23:44:24 UTC (rev 20518)
@@ -1161,14 +1161,14 @@
 		vecs[index] = fileExtent-&gt;disk;
 		index++;
 
+		if (size &lt;= fileExtent-&gt;disk.length)
+			break;
+
 		if (index &gt;= maxVecs) {
 			*_count = index;
 			return B_BUFFER_OVERFLOW;
 		}
 
-		if (size &lt;= fileExtent-&gt;disk.length)
-			break;
-
 		size -= fileExtent-&gt;disk.length;
 	}
 
@@ -1185,8 +1185,8 @@
 pages_io(file_cache_ref *ref, off_t offset, const iovec *vecs, size_t count,
 	size_t *_numBytes, bool doWrite)
 {
-	TRACE((&quot;pages_io: ref = %p, offset = %Ld, size = %lu, vecCount = %lu, %s\n&quot;, ref, offset,
-		*_numBytes, count, doWrite ? &quot;write&quot; : &quot;read&quot;));
+	TRACE((&quot;pages_io: ref = %p, offset = %Ld, size = %lu, vecCount = %lu, %s\n&quot;,
+		ref, offset, *_numBytes, count, doWrite ? &quot;write&quot; : &quot;read&quot;));
 
 	// translate the iovecs into direct device accesses
 	file_io_vec fileVecs[MAX_FILE_IO_VECS];
@@ -1195,16 +1195,17 @@
 
 	status_t status = get_file_map(ref, offset, numBytes, fileVecs,
 		&amp;fileVecCount);
-	if (status &lt; B_OK) {
-		TRACE((&quot;get_file_map(offset = %Ld, numBytes = %lu) failed\n&quot;, offset,
-			numBytes));
+	if (status &lt; B_OK &amp;&amp; status != B_BUFFER_OVERFLOW) {
+		TRACE((&quot;get_file_map(offset = %Ld, numBytes = %lu) failed: %s\n&quot;,
+			offset, numBytes, strerror(status)));
 		return status;
 	}
 
-	// TODO: handle array overflow gracefully!
+	bool bufferOverflow = status == B_BUFFER_OVERFLOW;
 
 #ifdef TRACE_FILE_CACHE
-	dprintf(&quot;got %lu file vecs for %Ld:%lu:\n&quot;, fileVecCount, offset, numBytes);
+	dprintf(&quot;got %lu file vecs for %Ld:%lu%s:\n&quot;, fileVecCount, offset,
+		numBytes, bufferOverflow ? &quot; (array too small)&quot; : &quot;&quot;);
 	for (size_t i = 0; i &lt; fileVecCount; i++) {
 		dprintf(&quot;  [%lu] offset = %Ld, size = %Ld\n&quot;,
 			i, fileVecs[i].offset, fileVecs[i].length);
@@ -1279,75 +1280,100 @@
 	size_t vecOffset = size;
 	size_t bytesLeft = numBytes - size;
 
-	for (; fileVecIndex &lt; fileVecCount; fileVecIndex++) {
-		file_io_vec &amp;fileVec = fileVecs[fileVecIndex];
-		off_t fileOffset = fileVec.offset;
-		off_t fileLeft = fileVec.length;
+	while (true) {
+		for (; fileVecIndex &lt; fileVecCount; fileVecIndex++) {
+			file_io_vec &amp;fileVec = fileVecs[fileVecIndex];
+			off_t fileOffset = fileVec.offset;
+			off_t fileLeft = min_c(fileVec.length, bytesLeft);
 
-		fileLeft = min_c(fileVec.length, bytesLeft);
+			TRACE((&quot;FILE VEC [%lu] length %Ld\n&quot;, fileVecIndex, fileLeft));
 
-		TRACE((&quot;FILE VEC [%lu] length %Ld\n&quot;, fileVecIndex, fileLeft));
+			// process the complete fileVec
+			while (fileLeft &gt; 0) {
+				iovec tempVecs[MAX_TEMP_IO_VECS];
+				uint32 tempCount = 0;
 
-		// process the complete fileVec
-		while (fileLeft &gt; 0) {
-			iovec tempVecs[MAX_TEMP_IO_VECS];
-			uint32 tempCount = 0;
+				// size tracks how much of what is left of the current fileVec
+				// (fileLeft) has been assigned to tempVecs 
+				size = 0;
 
-			// size tracks how much of what is left of the current fileVec
-			// (fileLeft) has been assigned to tempVecs 
-			size = 0;
+				// assign what is left of the current fileVec to the tempVecs
+				for (size = 0; size &lt; fileLeft &amp;&amp; i &lt; count
+						&amp;&amp; tempCount &lt; MAX_TEMP_IO_VECS;) {
+					// try to satisfy one iovec per iteration (or as much as
+					// possible)
 
-			// assign what is left of the current fileVec to the tempVecs
-			while (size &lt; fileLeft &amp;&amp; i &lt; count
-					&amp;&amp; tempCount &lt; MAX_TEMP_IO_VECS) {
-				// try to satisfy one iovec per iteration (or as much as
-				// possible)
-				TRACE((&quot;fill vec %ld, offset = %lu, size = %lu\n&quot;,
-					i, vecOffset, size));
+					// bytes left of the current iovec
+					size_t vecLeft = vecs[i].iov_len - vecOffset;
+					if (vecLeft == 0) {
+						vecOffset = 0;
+						i++;
+						continue;
+					}
 
-				// bytes left of the current iovec
-				size_t vecLeft = vecs[i].iov_len - vecOffset;
-				if (vecLeft == 0) {
-					i++;
-					vecOffset = 0;
-					continue;
+					TRACE((&quot;fill vec %ld, offset = %lu, size = %lu\n&quot;,
+						i, vecOffset, size));
+
+					// actually available bytes
+					size_t tempVecSize = min_c(vecLeft, fileLeft - size);
+
+					tempVecs[tempCount].iov_base
+						= (void *)((addr_t)vecs[i].iov_base + vecOffset);
+					tempVecs[tempCount].iov_len = tempVecSize;
+					tempCount++;
+
+					size += tempVecSize;
+					vecOffset += tempVecSize;
 				}
 
-				// actually available bytes
-				size_t tempVecSize = min_c(vecLeft, fileLeft - size);
+				size_t bytes = size;
+				if (doWrite) {
+					status = vfs_write_pages(ref-&gt;deviceFD, fileOffset,
+						tempVecs, tempCount, &amp;bytes, false);
+				} else {
+					status = vfs_read_pages(ref-&gt;deviceFD, fileOffset,
+						tempVecs, tempCount, &amp;bytes, false);
+				}
+				if (status &lt; B_OK)
+					return status;
 
-				tempVecs[tempCount].iov_base
-					= (void *)((addr_t)vecs[i].iov_base + vecOffset);
-				tempVecs[tempCount].iov_len = tempVecSize;
-				tempCount++;
+				totalSize += bytes;
+				bytesLeft -= size;
+				fileOffset += size;
+				fileLeft -= size;
+				//dprintf(&quot;-&gt; file left = %Lu\n&quot;, fileLeft);
 
-				size += tempVecSize;
-				vecOffset += tempVecSize;
+				if (size != bytes || i &gt;= count) {
+					// there are no more bytes or iovecs, let's bail out
+					*_numBytes = totalSize;
+					return B_OK;
+				}
 			}
+		}
 
-			size_t bytes = size;
-			if (doWrite) {
-				status = vfs_write_pages(ref-&gt;deviceFD, fileOffset,
-					tempVecs, tempCount, &amp;bytes, false);
-			} else {
-				status = vfs_read_pages(ref-&gt;deviceFD, fileOffset,
-					tempVecs, tempCount, &amp;bytes, false);
+		if (bufferOverflow) {
+			status = get_file_map(ref, offset + totalSize, bytesLeft, fileVecs,
+				&amp;fileVecCount);
+			if (status &lt; B_OK &amp;&amp; status != B_BUFFER_OVERFLOW) {
+				TRACE((&quot;get_file_map(offset = %Ld, numBytes = %lu) failed: %s\n&quot;,
+					offset, numBytes, strerror(status)));
+				return status;
 			}
-			if (status &lt; B_OK)
-				return status;
 
-			totalSize += bytes;
-			bytesLeft -= size;
-			fileOffset += size;
-			fileLeft -= size;
-			//dprintf(&quot;-&gt; file left = %Lu\n&quot;, fileLeft);
+			bufferOverflow = status == B_BUFFER_OVERFLOW;
+			fileVecIndex = 0;
 
-			if (size != bytes || i &gt;= count) {
-				// there are no more bytes or iovecs, let's bail out
-				*_numBytes = totalSize;
-				return B_OK;
+#ifdef TRACE_FILE_CACHE
+			dprintf(&quot;got %lu file vecs for %Ld:%lu%s:\n&quot;, fileVecCount,
+				offset + totalSize, numBytes,
+				bufferOverflow ? &quot; (array too small)&quot; : &quot;&quot;);
+			for (size_t i = 0; i &lt; fileVecCount; i++) {
+				dprintf(&quot;  [%lu] offset = %Ld, size = %Ld\n&quot;,
+					i, fileVecs[i].offset, fileVecs[i].length);
 			}
-		}
+#endif
+		} else
+			break;
 	}
 
 	*_numBytes = totalSize;
@@ -1361,7 +1387,7 @@
 	sure that it matches that criterion.
 */
 static inline status_t
-read_chunk_into_cache(file_cache_ref *ref, off_t offset, size_t size,
+read_chunk_into_cache(file_cache_ref *ref, off_t offset, size_t numBytes,
 	int32 pageOffset, addr_t buffer, size_t bufferSize)
 {
 	TRACE((&quot;read_chunk(offset = %Ld, size = %lu, pageOffset = %ld, buffer = %#lx, bufferSize = %lu\n&quot;,
@@ -1374,7 +1400,7 @@
 	int32 pageIndex = 0;
 
 	// allocate pages for the cache and mark them busy
-	for (size_t pos = 0; pos &lt; size; pos += B_PAGE_SIZE) {
+	for (size_t pos = 0; pos &lt; numBytes; pos += B_PAGE_SIZE) {
 		vm_page *page = pages[pageIndex++] = vm_page_allocate_page(PAGE_STATE_FREE);
 		if (page == NULL)
 			panic(&quot;no more pages!&quot;);
@@ -1392,7 +1418,7 @@
 	mutex_unlock(&amp;ref-&gt;lock);
 
 	// read file into reserved pages
-	status_t status = pages_io(ref, offset, vecs, vecCount, &amp;size, false);
+	status_t status = pages_io(ref, offset, vecs, vecCount, &amp;numBytes, false);
 	if (status &lt; B_OK) {
 		// reading failed, free allocated pages
 
@@ -1493,7 +1519,7 @@
 /**	Like read_chunk_into_cache() but writes data into the cache */
 
 static inline status_t
-write_chunk_to_cache(file_cache_ref *ref, off_t offset, size_t size,
+write_chunk_to_cache(file_cache_ref *ref, off_t offset, size_t numBytes,
 	int32 pageOffset, addr_t buffer, size_t bufferSize)
 {
 	iovec vecs[MAX_IO_VECS];
@@ -1506,7 +1532,7 @@
 	bool writeThrough = false;
 
 	// allocate pages for the cache and mark them busy
-	for (size_t pos = 0; pos &lt; size; pos += B_PAGE_SIZE) {
+	for (size_t pos = 0; pos &lt; numBytes; pos += B_PAGE_SIZE) {
 		// ToDo: if space is becoming tight, and this cache is already grown
 		//	big - shouldn't we better steal the pages directly in that case?
 		//	(a working set like approach for the file cache)
@@ -1552,7 +1578,7 @@
 			iovec readVec = { (void *)last, B_PAGE_SIZE };
 			size_t bytesRead = B_PAGE_SIZE;
 
-			status = pages_io(ref, offset + size - B_PAGE_SIZE, &amp;readVec, 1,
+			status = pages_io(ref, offset + numBytes - B_PAGE_SIZE, &amp;readVec, 1,
 				&amp;bytesRead, false);
 			// ToDo: handle errors for real!
 			if (status &lt; B_OK)
@@ -1577,7 +1603,7 @@
 
 	if (writeThrough) {
 		// write cached pages back to the file if we were asked to do that
-		status_t status = pages_io(ref, offset, vecs, vecCount, &amp;size, true);
+		status_t status = pages_io(ref, offset, vecs, vecCount, &amp;numBytes, true);
 		if (status &lt; B_OK) {
 			// ToDo: remove allocated pages, ...?
 			panic(&quot;file_cache: remove allocated pages! write pages failed: %s\n&quot;,


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001350.html">[Haiku-commits] r20517 - haiku/trunk/src/kits/app
</A></li>
	<LI>Next message: <A HREF="001352.html">[Haiku-commits] r20518 - haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1351">[ date ]</a>
              <a href="thread.html#1351">[ thread ]</a>
              <a href="subject.html#1351">[ subject ]</a>
              <a href="author.html#1351">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
