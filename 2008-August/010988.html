<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r26975 - haiku/trunk/src/system/kernel/vm
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2008-August/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r26975%20-%20haiku/trunk/src/system/kernel/vm&In-Reply-To=%3C200808142046.m7EKkJkx030269%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="011005.html">
   <LINK REL="Next"  HREF="011003.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r26975 - haiku/trunk/src/system/kernel/vm</H1>
    <B>bonefish at mail.berlios.de</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r26975%20-%20haiku/trunk/src/system/kernel/vm&In-Reply-To=%3C200808142046.m7EKkJkx030269%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r26975 - haiku/trunk/src/system/kernel/vm">bonefish at mail.berlios.de
       </A><BR>
    <I>Thu Aug 14 22:46:19 CEST 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="011005.html">[Haiku-commits] r26974 -	haiku/trunk/src/add-ons/kernel/file_systems/cdda
</A></li>
        <LI>Next message: <A HREF="011003.html">[Haiku-commits] r26241 - haiku/trunk/src/add-ons/kernel/file_systems/ext2
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#10988">[ date ]</a>
              <a href="thread.html#10988">[ thread ]</a>
              <a href="subject.html#10988">[ subject ]</a>
              <a href="author.html#10988">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: bonefish
Date: 2008-08-14 22:46:12 +0200 (Thu, 14 Aug 2008)
New Revision: 26975
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=26975&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=26975&amp;view=rev</A>

Modified:
   haiku/trunk/src/system/kernel/vm/VMAnonymousCache.cpp
   haiku/trunk/src/system/kernel/vm/VMAnonymousCache.h
Log:
Patch by Zhao Shuai with minor changes by myself:
* Moved the static functions to the beginning of the file.
* Renamed several variables for more clarity, particularly
  offset/cacheOffset to index/pageIndex in case where the unit is pages.
* _SwapBlock{Build,Free}() can deal with a range of pages now, which
  should be more efficient.
* Additional checks/panics in swap_page_alloc().
* swap_file_add(): Wrong byte count was used when allocating and
  clearing the bitmap.
* swap_page_alloc(): Fixed off-by-one check. The last page of the swap
  file could not be used.


Modified: haiku/trunk/src/system/kernel/vm/VMAnonymousCache.cpp
===================================================================
--- haiku/trunk/src/system/kernel/vm/VMAnonymousCache.cpp	2008-08-14 17:39:33 UTC (rev 26974)
+++ haiku/trunk/src/system/kernel/vm/VMAnonymousCache.cpp	2008-08-14 20:46:12 UTC (rev 26975)
@@ -49,8 +49,9 @@
 #define SWAP_PAGE_NONE (~(swap_addr_t)0)
 
 // bitmap allocation macros
-#define MAP_SHIFT  5
-#define NUM_BITS_PER_WORD  32    // number of bits per word
+#define NUM_BYTES_PER_WORD 4
+#define NUM_BITS_PER_WORD  (8 * NUM_BYTES_PER_WORD)
+#define MAP_SHIFT  5     // 1 &lt;&lt; MAP_SHIFT == NUM_BITS_PER_WORD
 
 #define TESTBIT(map, i) \
 	(((map)[(i) &gt;&gt; MAP_SHIFT] &amp; (1 &lt;&lt; (i) % NUM_BITS_PER_WORD)))
@@ -75,7 +76,7 @@
 
 struct swap_hash_key {
 	VMAnonymousCache	*cache;
-	off_t				cache_offset;
+	off_t				page_index;  // page index in the cache
 };
 
 // Each swap block contains SWAP_BLOCK_PAGES pages
@@ -85,14 +86,6 @@
 	swap_addr_t		swap_pages[SWAP_BLOCK_PAGES];
 };
 
-static swap_addr_t swap_page_alloc(uint32 npages);
-static void swap_page_dealloc(swap_addr_t pageIndex, uint32 npages);
-static swap_file *find_swap_file(swap_addr_t pageIndex);
-static off_t swap_space_reserve(off_t amount);
-static void swap_space_unreserve(off_t amount);
-
-static object_cache *sSwapBlockCache;
-
 struct SwapHashTableDefinition {
 	typedef swap_hash_key KeyType;
 	typedef swap_block ValueType;
@@ -101,9 +94,9 @@
 
 	size_t HashKey(const swap_hash_key&amp; key) const
 	{
-		off_t cacheOffset = key.cache_offset &gt;&gt; SWAP_BLOCK_SHIFT;
+		off_t blockIndex = key.page_index &gt;&gt; SWAP_BLOCK_SHIFT;
 		VMAnonymousCache *cache = key.cache;
-		return cacheOffset ^ (int)(int *)cache;
+		return blockIndex ^ (int)(int *)cache;
 	}
 
 	size_t Hash(const swap_block *value) const
@@ -113,8 +106,8 @@
 
 	bool Compare(const swap_hash_key&amp; key, const swap_block *value) const
 	{
-		return (key.cache_offset &amp; ~(off_t)SWAP_BLOCK_MASK)
-				== (value-&gt;key.cache_offset &amp; ~(off_t)SWAP_BLOCK_MASK)
+		return (key.page_index &amp; ~(off_t)SWAP_BLOCK_MASK)
+				== (value-&gt;key.page_index &amp; ~(off_t)SWAP_BLOCK_MASK)
 			&amp;&amp; key.cache == value-&gt;key.cache;
 	}
 
@@ -138,18 +131,162 @@
 static off_t sAvailSwapSpace = 0;
 static mutex sAvailSwapSpaceLock;
 
+static object_cache *sSwapBlockCache;
 
+
+static swap_addr_t
+swap_page_alloc(uint32 npages)
+{
+	mutex_lock(&amp;sSwapFileListLock);
+
+	if (sSwapFileList.IsEmpty()) {
+		mutex_unlock(&amp;sSwapFileListLock);
+		panic(&quot;swap_page_alloc(): no swap file in the system\n&quot;);
+		return SWAP_PAGE_NONE;
+	}
+
+	// compute how many pages are free in all swap files
+	uint32 freeSwapPages = 0;
+	for (SwapFileList::Iterator it = sSwapFileList.GetIterator();
+			swap_file *file = it.Next();)
+		freeSwapPages += file-&gt;last_page - file-&gt;first_page - file-&gt;used;
+
+	if (freeSwapPages &lt; npages) {
+		mutex_unlock(&amp;sSwapFileListLock);
+		panic(&quot;swap_page_alloc(): swap space exhausted!\n&quot;);
+		return SWAP_PAGE_NONE;
+	}
+
+	swap_addr_t hint = 0;
+	swap_addr_t j;
+	for (j = 0; j &lt; sSwapFileCount; j++) {
+		if (sSwapFileAlloc == NULL)
+			sSwapFileAlloc = sSwapFileList.First();
+
+		hint = sSwapFileAlloc-&gt;hint;
+		swap_addr_t pageCount = sSwapFileAlloc-&gt;last_page
+			- sSwapFileAlloc-&gt;first_page;
+
+		swap_addr_t i = 0;
+		while (i &lt; npages &amp;&amp; (hint + npages) &lt;= pageCount) {
+			if (TESTBIT(sSwapFileAlloc-&gt;maps, hint + i)) {
+				hint++;
+				i = 0;
+			} else
+				i++;
+		}
+
+		if (i == npages)
+			break;
+
+		// this swap_file is full, find another
+		sSwapFileAlloc = sSwapFileList.GetNext(sSwapFileAlloc);
+	}
+
+	// no swap file can alloc so many pages, we return SWAP_PAGE_NONE
+	// and VMAnonymousCache::Write() will adjust allocation amount
+	if (j == sSwapFileCount) {
+		mutex_unlock(&amp;sSwapFileListLock);
+		return SWAP_PAGE_NONE;
+	}
+
+	swap_addr_t swapAddress = sSwapFileAlloc-&gt;first_page + hint;
+
+	for (uint32 i = 0; i &lt; npages; i++)
+		SETBIT(sSwapFileAlloc-&gt;maps, hint + i);
+	if (hint == sSwapFileAlloc-&gt;hint)
+		sSwapFileAlloc-&gt;hint += npages;
+
+	sSwapFileAlloc-&gt;used += npages;
+
+	// if this swap file has used more than 90% percent of its pages
+	// switch to another
+    if (sSwapFileAlloc-&gt;used
+			&gt; 9 * (sSwapFileAlloc-&gt;last_page - sSwapFileAlloc-&gt;first_page) / 10)
+		sSwapFileAlloc = sSwapFileList.GetNext(sSwapFileAlloc);
+
+	mutex_unlock(&amp;sSwapFileListLock);
+
+	return swapAddress;
+}
+
+
+static swap_file *
+find_swap_file(swap_addr_t swapAddress)
+{
+	for (SwapFileList::Iterator it = sSwapFileList.GetIterator();
+			swap_file *swapFile = it.Next();) {
+		if (swapAddress &gt;= swapFile-&gt;first_page
+				&amp;&amp; swapAddress &lt; swapFile-&gt;last_page)
+			return swapFile;
+	}
+
+	panic(&quot;find_swap_file(): can't find swap file for %ld\n&quot;, swapAddress);
+	return NULL;
+}
+
+
+static void
+swap_page_dealloc(swap_addr_t swapAddress, uint32 npages)
+{
+	if (swapAddress == SWAP_PAGE_NONE)
+		return;
+
+	mutex_lock(&amp;sSwapFileListLock);
+	swap_file *swapFile = find_swap_file(swapAddress);
+
+	swapAddress -= swapFile-&gt;first_page;
+
+	for (uint32 i = 0; i &lt; npages; i++)
+		CLEARBIT(swapFile-&gt;maps, swapAddress + i);
+
+	if (swapFile-&gt;hint &gt; swapAddress)
+		swapFile-&gt;hint = swapAddress;
+
+	swapFile-&gt;used -= npages;
+	mutex_unlock(&amp;sSwapFileListLock);
+}
+
+
+static off_t
+swap_space_reserve(off_t amount)
+{
+	mutex_lock(&amp;sAvailSwapSpaceLock);
+	if (sAvailSwapSpace &gt;= amount)
+		sAvailSwapSpace -= amount;
+	else {
+		sAvailSwapSpace = 0;
+		amount = sAvailSwapSpace;
+	}
+	mutex_unlock(&amp;sAvailSwapSpaceLock);
+
+	return amount;
+}
+
+
+static void
+swap_space_unreserve(off_t amount)
+{
+	mutex_lock(&amp;sAvailSwapSpaceLock);
+	sAvailSwapSpace += amount;
+	mutex_unlock(&amp;sAvailSwapSpaceLock);
+}
+
+
+// #pragma mark -
+
+
 VMAnonymousCache::~VMAnonymousCache()
 {
 	// free allocated swap space and swap block
 	for (off_t offset = virtual_base, toFree = fAllocatedSwapSize;
 			offset &lt; virtual_end &amp;&amp; toFree &gt; 0; offset += B_PAGE_SIZE) {
-		swap_addr_t pageIndex = _SwapBlockGetAddress(offset &gt;&gt; PAGE_SHIFT);
-		if (pageIndex == SWAP_PAGE_NONE)
+		swap_addr_t swapAddr = _SwapBlockGetAddress(offset &gt;&gt; PAGE_SHIFT);
+		if (swapAddr == SWAP_PAGE_NONE)
 			continue;
 
-		swap_page_dealloc(pageIndex, 1);
-		_SwapBlockFree(offset &gt;&gt; PAGE_SHIFT);
+		swap_page_dealloc(swapAddr, 1);
+		_SwapBlockFree(offset &gt;&gt; PAGE_SHIFT, 1);
 		toFree -= B_PAGE_SIZE;
 	}
 
@@ -202,10 +339,9 @@
 bool
 VMAnonymousCache::HasPage(off_t offset)
 {
-	offset &gt;&gt;= PAGE_SHIFT;
-	swap_addr_t pageIndex = _SwapBlockGetAddress(offset);
-	if (pageIndex != SWAP_PAGE_NONE)
+	if (_SwapBlockGetAddress(offset &gt;&gt; PAGE_SHIFT) != SWAP_PAGE_NONE)
 		return true;
+
 	return false;
 }
 
@@ -214,23 +350,19 @@
 VMAnonymousCache::Read(off_t offset, const iovec *vecs, size_t count,
 	size_t *_numBytes)
 {
-	off_t cacheOffset = offset &gt;&gt; PAGE_SHIFT;
+	off_t pageIndex = offset &gt;&gt; PAGE_SHIFT;
 
 	for (uint32 i = 0, j = 0; i &lt; count; i = j) {
-		swap_addr_t startPageIndex = _SwapBlockGetAddress(cacheOffset + i);
+		swap_addr_t startSwapAddr = _SwapBlockGetAddress(pageIndex + i);
 		for (j = i + 1; j &lt; count; j++) {
-			swap_addr_t pageIndex = _SwapBlockGetAddress(cacheOffset + j);
-			if (pageIndex != startPageIndex + j - i)
+			swap_addr_t swapAddr = _SwapBlockGetAddress(pageIndex + j);
+			if (swapAddr != startSwapAddr + j - i)
 				break;
 		}
 
-		swap_file *swapFile = find_swap_file(startPageIndex);
-		if (swapFile == NULL) {
-			panic(&quot;can't find swap file for page index %ld\n&quot;, startPageIndex);
-			return B_ERROR;
-		}
+		swap_file *swapFile = find_swap_file(startSwapAddr);
 
-		off_t pos = (startPageIndex - swapFile-&gt;first_page) * PAGE_SIZE;
+		off_t pos = (startSwapAddr - swapFile-&gt;first_page) * PAGE_SIZE;
 
 		status_t status = vfs_read_pages(swapFile-&gt;vnode, NULL, pos, vecs + i,
 				j - i, 0, _numBytes);
@@ -246,14 +378,14 @@
 VMAnonymousCache::Write(off_t offset, const iovec *vecs, size_t count,
 	size_t *_numBytes)
 {
-	offset &gt;&gt;= PAGE_SHIFT;
+	off_t pageIndex = offset &gt;&gt; PAGE_SHIFT;
 
 	Lock();
 	for (uint32 i = 0; i &lt; count; i++) {
-		swap_addr_t pageIndex = _SwapBlockGetAddress(offset + i);
-		if (pageIndex != SWAP_PAGE_NONE) {
-			swap_page_dealloc(pageIndex, 1);
-			_SwapBlockFree(offset + i);
+		swap_addr_t swapAddr = _SwapBlockGetAddress(pageIndex + i);
+		if (swapAddr != SWAP_PAGE_NONE) {
+			swap_page_dealloc(swapAddr, 1);
+			_SwapBlockFree(pageIndex + i, 1);
 			fAllocatedSwapSize -= B_PAGE_SIZE;
 		}
 	}
@@ -266,21 +398,17 @@
 
 	uint32 n = count;
 	for (uint32 i = 0; i &lt; count; i += n) {
-		swap_addr_t pageIndex;
+		swap_addr_t swapAddr;
 		// try to allocate n pages, if fail, try to allocate n/2
-		while ((pageIndex = swap_page_alloc(n)) == SWAP_PAGE_NONE
-				&amp;&amp; n &gt;= 2)
+		while ((swapAddr = swap_page_alloc(n)) == SWAP_PAGE_NONE &amp;&amp; n &gt;= 2)
 			n &gt;&gt;= 1;
-		if (pageIndex == SWAP_PAGE_NONE)
-			panic(&quot;can't allocate swap space\n&quot;);
+		if (swapAddr == SWAP_PAGE_NONE)
+			panic(&quot;VMAnonymousCache::Write(): can't allocate swap space\n&quot;);
 
-		swap_file *swapFile = find_swap_file(pageIndex);
-		if (swapFile == NULL) {
-			panic(&quot;can't find swap file for page index %ld\n&quot;, pageIndex);
-			return B_ERROR;
-		}
+		swap_file *swapFile = find_swap_file(swapAddr);
 
-		off_t pos = (pageIndex - swapFile-&gt;first_page) * B_PAGE_SIZE;
+		off_t pos = (swapAddr - swapFile-&gt;first_page) * B_PAGE_SIZE;
+
 		status_t status = vfs_write_pages(swapFile-&gt;vnode, NULL, pos, vecs + i,
 				n, 0, _numBytes);
 		if (status != B_OK) {
@@ -288,12 +416,11 @@
 			fAllocatedSwapSize -= n * B_PAGE_SIZE;
 			Unlock();
 
-			swap_page_dealloc(pageIndex, n);
+			swap_page_dealloc(swapAddr, n);
 			return status;
 		}
 
-		for (uint32 j = 0; j &lt; n; j++)
-			_SwapBlockBuild(offset + i + j, pageIndex + j);
+		_SwapBlockBuild(pageIndex + i, swapAddr, n);
 	}
 
 	return B_OK;
@@ -359,11 +486,10 @@
 	if (committed_size &gt; actualSize)
 		_Commit(actualSize);
 
-	// TODO: iterate over swap blocks
 	for (off_t offset = source-&gt;virtual_base; offset &lt; source-&gt;virtual_end;
 			offset += PAGE_SIZE) {
-		off_t cacheOffset = offset &gt;&gt; PAGE_SHIFT;
-		swap_addr_t sourceSwapIndex = source-&gt;_SwapBlockGetAddress(cacheOffset);
+		off_t pageIndex = offset &gt;&gt; PAGE_SHIFT;
+		swap_addr_t sourceSwapIndex = source-&gt;_SwapBlockGetAddress(pageIndex);
 
 		if (sourceSwapIndex == SWAP_PAGE_NONE)
 			// this page is not swapped out
@@ -374,12 +500,12 @@
 			// free the swap space
 			swap_page_dealloc(sourceSwapIndex, 1);
 		} else {
-			swap_addr_t swapIndex = _SwapBlockGetAddress(cacheOffset);
+			swap_addr_t swapIndex = _SwapBlockGetAddress(pageIndex);
 
 			if (swapIndex == SWAP_PAGE_NONE) {
 				// the page is not shadowed,
 				// assign the swap address to the new cache
-				_SwapBlockBuild(cacheOffset, sourceSwapIndex);
+				_SwapBlockBuild(pageIndex, sourceSwapIndex, 1);
 				fAllocatedSwapSize += B_PAGE_SIZE;
 			} else {
 				// the page is shadowed and is also swapped out
@@ -387,61 +513,70 @@
 			}
 		}
 		source-&gt;fAllocatedSwapSize -= B_PAGE_SIZE;
-		source-&gt;_SwapBlockFree(cacheOffset);
+		source-&gt;_SwapBlockFree(pageIndex, 1);
 	}
 }
 
 
 void
-VMAnonymousCache::_SwapBlockBuild(off_t cacheOffset, swap_addr_t pageIndex)
+VMAnonymousCache::_SwapBlockBuild(off_t startPageIndex,
+	swap_addr_t startSwapAddress, uint32 count)
 {
 	mutex_lock(&amp;sSwapHashLock);
 
-	swap_hash_key key = { this, cacheOffset };
+	for (uint32 i = 0; i &lt; count; i++) {
+		off_t pageIndex = startPageIndex + i;
+		swap_addr_t swapAddress = startSwapAddress + i;
 
-	swap_block *swap = sSwapHashTable.Lookup(key);
-	if (swap == NULL) {
-		swap = (swap_block *)object_cache_alloc(sSwapBlockCache,
-				CACHE_DONT_SLEEP);
+		swap_hash_key key = { this, pageIndex };
+
+		swap_block *swap = sSwapHashTable.Lookup(key);
 		if (swap == NULL) {
-			// TODO: wait until memory can be allocated
-			mutex_unlock(&amp;sSwapHashLock);
-			return;
+			swap = (swap_block *)object_cache_alloc(sSwapBlockCache,
+					CACHE_DONT_SLEEP);
+			if (swap == NULL) {
+				// TODO: wait until memory can be allocated
+				mutex_unlock(&amp;sSwapHashLock);
+				return;
+			}
+
+			swap-&gt;key.cache = this;
+			swap-&gt;key.page_index = pageIndex &amp; ~(off_t)SWAP_BLOCK_MASK;
+			swap-&gt;used = 0;
+			for (uint32 i = 0; i &lt; SWAP_BLOCK_PAGES; i++)
+				swap-&gt;swap_pages[i] = SWAP_PAGE_NONE;
+
+			sSwapHashTable.Insert(swap);
 		}
 
-		swap-&gt;key.cache = this;
-		swap-&gt;key.cache_offset = cacheOffset &amp; ~(off_t)SWAP_BLOCK_MASK;
-		swap-&gt;used = 0;
-		for (uint32 i = 0; i &lt; SWAP_BLOCK_PAGES; i++)
-			swap-&gt;swap_pages[i] = SWAP_PAGE_NONE;
+		swap_addr_t blockIndex = pageIndex &amp; SWAP_BLOCK_MASK;
+		swap-&gt;swap_pages[blockIndex] = swapAddress;
 
-		sSwapHashTable.Insert(swap);
+		swap-&gt;used++;
 	}
 
-	swap_addr_t blockIndex = cacheOffset &amp; SWAP_BLOCK_MASK;
-	swap-&gt;swap_pages[blockIndex] = pageIndex;
-
-	swap-&gt;used++;
-
 	mutex_unlock(&amp;sSwapHashLock);
 }
 
 
 void
-VMAnonymousCache::_SwapBlockFree(off_t cacheOffset)
+VMAnonymousCache::_SwapBlockFree(off_t startPageIndex, uint32 count)
 {
 	mutex_lock(&amp;sSwapHashLock);
 
-	swap_hash_key key = { this, cacheOffset };
-	swap_block *swap = sSwapHashTable.Lookup(key);
-	if (swap != NULL) {
-		swap_addr_t pageIndex = swap-&gt;swap_pages[cacheOffset &amp; SWAP_BLOCK_MASK];
-		if (pageIndex != SWAP_PAGE_NONE) {
-			swap-&gt;swap_pages[cacheOffset &amp; SWAP_BLOCK_MASK] = SWAP_PAGE_NONE;
-			swap-&gt;used--;
-			if (swap-&gt;used == 0) {
-				sSwapHashTable.Remove(swap);
-				object_cache_free(sSwapBlockCache, swap);
+	for (uint32 i = 0; i &lt; count; i++) {
+		off_t pageIndex = startPageIndex + i;
+		swap_hash_key key = { this, pageIndex };
+		swap_block *swap = sSwapHashTable.Lookup(key);
+		if (swap != NULL) {
+			swap_addr_t swapAddr = swap-&gt;swap_pages[pageIndex &amp; SWAP_BLOCK_MASK];
+			if (swapAddr != SWAP_PAGE_NONE) {
+				swap-&gt;swap_pages[pageIndex &amp; SWAP_BLOCK_MASK] = SWAP_PAGE_NONE;
+				swap-&gt;used--;
+				if (swap-&gt;used == 0) {
+					sSwapHashTable.Remove(swap);
+					object_cache_free(sSwapBlockCache, swap);
+				}
 			}
 		}
 	}
@@ -451,22 +586,22 @@
 
 
 swap_addr_t
-VMAnonymousCache::_SwapBlockGetAddress(off_t cacheOffset)
+VMAnonymousCache::_SwapBlockGetAddress(off_t pageIndex)
 {
 	mutex_lock(&amp;sSwapHashLock);
 
-	swap_hash_key key = { this, cacheOffset };
+	swap_hash_key key = { this, pageIndex };
 	swap_block *swap = sSwapHashTable.Lookup(key);
-	swap_addr_t pageIndex = SWAP_PAGE_NONE;
+	swap_addr_t swapAddress = SWAP_PAGE_NONE;
 
 	if (swap != NULL) {
-		swap_addr_t blockIndex = cacheOffset &amp; SWAP_BLOCK_MASK;
-		pageIndex = swap-&gt;swap_pages[blockIndex];
+		swap_addr_t blockIndex = pageIndex &amp; SWAP_BLOCK_MASK;
+		swapAddress = swap-&gt;swap_pages[blockIndex];
 	}
 
 	mutex_unlock(&amp;sSwapHashLock);
 
-	return pageIndex;
+	return swapAddress;
 }
 
 
@@ -522,173 +657,9 @@
 }
 
 
-static swap_file *
-find_swap_file(swap_addr_t pageIndex)
-{
-	for (SwapFileList::Iterator it = sSwapFileList.GetIterator();
-			swap_file *swapFile = it.Next();) {
-		if (pageIndex &gt;= swapFile-&gt;first_page
-				&amp;&amp; pageIndex &lt; swapFile-&gt;last_page)
-			return swapFile;
-	}
+// #pragma mark -
 
-	return NULL;
-}
 
-
-// used by page daemon to free swap space
-bool
-swap_free_page_swap_space(vm_page *page)
-{
-	VMAnonymousCache *cache = dynamic_cast&lt;VMAnonymousCache *&gt;(page-&gt;cache);
-	if (cache == NULL)
-		return false;
-
-	swap_addr_t pageIndex = cache-&gt;_SwapBlockGetAddress(page-&gt;cache_offset);
-	if (pageIndex == SWAP_PAGE_NONE)
-		return false;
-
-	swap_page_dealloc(pageIndex, 1);
-	cache-&gt;fAllocatedSwapSize -= B_PAGE_SIZE;
-	cache-&gt;_SwapBlockFree(page-&gt;cache_offset);
-	return true;
-}
-
-
-uint32
-swap_available_pages()
-{
-	mutex_lock(&amp;sAvailSwapSpaceLock);
-	uint32 avail = sAvailSwapSpace &gt;&gt; PAGE_SHIFT;
-	mutex_unlock(&amp;sAvailSwapSpaceLock);
-
-	return avail;
-}
-
-
-uint32
-swap_total_swap_pages()
-{
-	mutex_lock(&amp;sSwapFileListLock);
-
-	uint32 totalSwapPages = 0;
-	for (SwapFileList::Iterator it = sSwapFileList.GetIterator();
-			swap_file *swapFile = it.Next();)
-		totalSwapPages += swapFile-&gt;last_page - swapFile-&gt;first_page;
-
-	mutex_unlock(&amp;sSwapFileListLock);
-
-	return totalSwapPages;
-}
-
-
-static swap_addr_t
-swap_page_alloc(uint32 npages)
-{
-	swap_addr_t hint = 0;
-	swap_addr_t j;
-
-	if (sSwapFileList.IsEmpty())
-		return SWAP_PAGE_NONE;
-
-	mutex_lock(&amp;sSwapFileListLock);
-	for (j = 0; j &lt; sSwapFileCount; j++) {
-		if (sSwapFileAlloc == NULL)
-			sSwapFileAlloc = sSwapFileList.First();
-
-		hint = sSwapFileAlloc-&gt;hint;
-		swap_addr_t pageCount = sSwapFileAlloc-&gt;last_page
-			- sSwapFileAlloc-&gt;first_page;
-
-		swap_addr_t i = 0;
-		while (i &lt; npages &amp;&amp; (hint + npages) &lt; pageCount) {
-			if (TESTBIT(sSwapFileAlloc-&gt;maps, hint + i)) {
-				hint++;
-				i = 0;
-			} else
-				i++;
-		}
-
-		if (i == npages)
-			break;
-
-		// this swap_file is full, find another
-		sSwapFileAlloc = sSwapFileList.GetNext(sSwapFileAlloc);
-	}
-
-	if (j == sSwapFileCount) {
-		panic(&quot;swap space exhausted\n&quot;);
-		mutex_unlock(&amp;sSwapFileListLock);
-		return SWAP_PAGE_NONE;
-	}
-
-	swap_addr_t pageIndex = sSwapFileAlloc-&gt;first_page + hint;
-
-	for (uint32 i = 0; i &lt; npages; i++)
-		SETBIT(sSwapFileAlloc-&gt;maps, hint + i);
-	if (hint == sSwapFileAlloc-&gt;hint)
-		sSwapFileAlloc-&gt;hint += npages;
-
-	sSwapFileAlloc-&gt;used += npages;
-
-	// if this swap file has used more than 90% percent of its pages
-	// switch to another
-    if (sSwapFileAlloc-&gt;used
-			&gt; 9 * (sSwapFileAlloc-&gt;last_page - sSwapFileAlloc-&gt;first_page) / 10)
-		sSwapFileAlloc = sSwapFileList.GetNext(sSwapFileAlloc);
-
-	mutex_unlock(&amp;sSwapFileListLock);
-	return pageIndex;
-}
-
-
-static void
-swap_page_dealloc(swap_addr_t pageIndex, uint32 npages)
-{
-	if (pageIndex == SWAP_PAGE_NONE)
-		return;
-
-	mutex_lock(&amp;sSwapFileListLock);
-	swap_file *swapFile = find_swap_file(pageIndex);
-
-	pageIndex -= swapFile-&gt;first_page;
-
-	for (uint32 i = 0; i &lt; npages; i++)
-		CLEARBIT(swapFile-&gt;maps, pageIndex + i);
-
-	if (swapFile-&gt;hint &gt; pageIndex)
-		swapFile-&gt;hint = pageIndex;
-
-	swapFile-&gt;used -= npages;
-	mutex_unlock(&amp;sSwapFileListLock);
-}
-
-
-static off_t
-swap_space_reserve(off_t amount)
-{
-	mutex_lock(&amp;sAvailSwapSpaceLock);
-	if (sAvailSwapSpace &gt;= amount)
-		sAvailSwapSpace -= amount;
-	else {
-		sAvailSwapSpace = 0;
-		amount = sAvailSwapSpace;
-	}
-	mutex_unlock(&amp;sAvailSwapSpaceLock);
-
-	return amount;
-}
-
-
-static void
-swap_space_unreserve(off_t amount)
-{
-	mutex_lock(&amp;sAvailSwapSpaceLock);
-	sAvailSwapSpace += amount;
-	mutex_unlock(&amp;sAvailSwapSpaceLock);
-}
-
-
 status_t
 swap_file_add(char *path)
 {
@@ -722,14 +693,13 @@
 	int32 pageCount = st.st_size &gt;&gt; PAGE_SHIFT;
 	swap-&gt;used = 0;
 
-	swap-&gt;maps = (uint32 *)
-		malloc((pageCount + NUM_BITS_PER_WORD - 1) / NUM_BITS_PER_WORD);
+	swap-&gt;maps = (uint32 *)malloc((pageCount + 7) / 8);
 	if (swap-&gt;maps == NULL) {
 		free(swap);
 		vfs_put_vnode(node);
 		return B_NO_MEMORY;
 	}
-	memset(swap-&gt;maps, 0, pageCount % 8 + 1);
+	memset(swap-&gt;maps, 0, (pageCount + 7) / 8);
 	swap-&gt;hint = 0;
 
 	// set start page index and add this file to swap file list
@@ -808,7 +778,7 @@
 	sSwapBlockCache = create_object_cache(&quot;swapblock&quot;,
 			sizeof(swap_block), sizeof(void*), NULL, NULL, NULL);
 	if (sSwapBlockCache == NULL)
-		panic(&quot;can't create object cache for swap blocks\n&quot;);
+		panic(&quot;swap_init(): can't create object cache for swap blocks\n&quot;);
 
 	// init swap hash table
 	sSwapHashTable.Init();
@@ -824,6 +794,7 @@
 	sAvailSwapSpace = 0;
 }
 
+
 void
 swap_init_post_modules()
 {
@@ -867,4 +838,50 @@
 	swap_file_add(&quot;/var/swap&quot;);
 }
 
+
+// used by page daemon to free swap space
+bool
+swap_free_page_swap_space(vm_page *page)
+{
+	VMAnonymousCache *cache = dynamic_cast&lt;VMAnonymousCache *&gt;(page-&gt;cache);
+	if (cache == NULL)
+		return false;
+
+	swap_addr_t swapAddress = cache-&gt;_SwapBlockGetAddress(page-&gt;cache_offset);
+	if (swapAddress == SWAP_PAGE_NONE)
+		return false;
+
+	swap_page_dealloc(swapAddress, 1);
+	cache-&gt;fAllocatedSwapSize -= B_PAGE_SIZE;
+	cache-&gt;_SwapBlockFree(page-&gt;cache_offset, 1);
+	return true;
+}
+
+
+uint32
+swap_available_pages()
+{
+	mutex_lock(&amp;sAvailSwapSpaceLock);
+	uint32 avail = sAvailSwapSpace &gt;&gt; PAGE_SHIFT;
+	mutex_unlock(&amp;sAvailSwapSpaceLock);
+
+	return avail;
+}
+
+
+uint32
+swap_total_swap_pages()
+{
+	mutex_lock(&amp;sSwapFileListLock);
+
+	uint32 totalSwapPages = 0;
+	for (SwapFileList::Iterator it = sSwapFileList.GetIterator();
+			swap_file *swapFile = it.Next();)
+		totalSwapPages += swapFile-&gt;last_page - swapFile-&gt;first_page;
+
+	mutex_unlock(&amp;sSwapFileListLock);
+
+	return totalSwapPages;
+}
+
 #endif	// ENABLE_SWAP_SUPPORT

Modified: haiku/trunk/src/system/kernel/vm/VMAnonymousCache.h
===================================================================
--- haiku/trunk/src/system/kernel/vm/VMAnonymousCache.h	2008-08-14 17:39:33 UTC (rev 26974)
+++ haiku/trunk/src/system/kernel/vm/VMAnonymousCache.h	2008-08-14 20:46:12 UTC (rev 26975)
@@ -46,9 +46,10 @@
 	virtual	void		MergeStore(VMCache* source);
 
 private:
-			void		_SwapBlockBuild(off_t cacheOffset, swap_addr_t pageIndex);
-			void        _SwapBlockFree(off_t cacheOffset);
-			swap_addr_t	_SwapBlockGetAddress(off_t cacheOffset);
+			void		_SwapBlockBuild(off_t pageIndex,
+							swap_addr_t swapAddress, uint32 count);
+			void        _SwapBlockFree(off_t pageIndex, uint32 count);
+			swap_addr_t	_SwapBlockGetAddress(off_t pageIndex);
 			status_t	_Commit(off_t size);
 
 private:


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="011005.html">[Haiku-commits] r26974 -	haiku/trunk/src/add-ons/kernel/file_systems/cdda
</A></li>
	<LI>Next message: <A HREF="011003.html">[Haiku-commits] r26241 - haiku/trunk/src/add-ons/kernel/file_systems/ext2
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#10988">[ date ]</a>
              <a href="thread.html#10988">[ thread ]</a>
              <a href="subject.html#10988">[ subject ]</a>
              <a href="author.html#10988">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
