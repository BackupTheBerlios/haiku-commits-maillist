<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r24588 -	haiku/trunk/src/add-ons/kernel/generic/locked_pool
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2008-March/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r24588%20-%0A%09haiku/trunk/src/add-ons/kernel/generic/locked_pool&In-Reply-To=%3C200803261050.m2QAom4Z004144%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="007103.html">
   <LINK REL="Next"  HREF="007108.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r24588 -	haiku/trunk/src/add-ons/kernel/generic/locked_pool</H1>
    <B>axeld at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r24588%20-%0A%09haiku/trunk/src/add-ons/kernel/generic/locked_pool&In-Reply-To=%3C200803261050.m2QAom4Z004144%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r24588 -	haiku/trunk/src/add-ons/kernel/generic/locked_pool">axeld at mail.berlios.de
       </A><BR>
    <I>Wed Mar 26 11:50:48 CET 2008</I>
    <P><UL>
        <LI>Previous message: <A HREF="007103.html">[Haiku-commits] r24587 - haiku/trunk/src/tools/fs_shell
</A></li>
        <LI>Next message: <A HREF="007108.html">[Haiku-commits] r24589 - haiku/trunk/src/system/kernel/cache
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#7105">[ date ]</a>
              <a href="thread.html#7105">[ thread ]</a>
              <a href="subject.html#7105">[ subject ]</a>
              <a href="author.html#7105">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: axeld
Date: 2008-03-26 11:50:47 +0100 (Wed, 26 Mar 2008)
New Revision: 24588
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=24588&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=24588&amp;view=rev</A>

Modified:
   haiku/trunk/src/add-ons/kernel/generic/locked_pool/locked_pool.c
Log:
* Something was fishy with the previous diff_lock-based implementation;
  while I couldn't put my finger on it, I rarely got crashes with it.
* I've greatly simplified that mechanism now, and got rid of the 
  diff_locks completely - at least I understand the code now :)
* Coding style cleanup.


Modified: haiku/trunk/src/add-ons/kernel/generic/locked_pool/locked_pool.c
===================================================================
--- haiku/trunk/src/add-ons/kernel/generic/locked_pool/locked_pool.c	2008-03-26 04:18:40 UTC (rev 24587)
+++ haiku/trunk/src/add-ons/kernel/generic/locked_pool/locked_pool.c	2008-03-26 10:50:47 UTC (rev 24588)
@@ -1,27 +1,27 @@
 /*
+ * Copyright 2008, Axel D&#246;rfler, <A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de.</A>
  * Copyright 2002/03, Thomas Kurschel. All rights reserved.
+ *
  * Distributed under the terms of the MIT License.
  */
 
-/*
-	Deadlock-safe allocation of locked memory.
+/*!	Deadlock-safe allocation of locked memory.
 
 	Allocation/freeing is optimized for speed. Count of &lt;sem&gt;
-	is the number of free blocks and thus should be modified 
+	is the number of free blocks and thus should be modified
 	by each alloc() and free(). As this count is only crucial if
 	an allocation is waiting for a free block, &lt;sem&gt; is only
-	updated on demand - the correct number of free blocks is 
-	stored in &lt;free_blocks&gt; and the difference between &lt;free_blocks&gt;
-	and the semaphore count is stored in &lt;diff_locks&gt;. There
-	are only three cases where &lt;sem&gt; is updated:
+	updated on demand - the correct number of free blocks is
+	stored in &lt;free_blocks&gt;. There are only three cases where
+	&lt;sem&gt; is updated:
 
 	- if an	allocation fails because there is no free block left;
-	  in this case, &lt;num_waiting&gt; increased by one and then the 
-	  thread makes &lt;sem&gt; up-to-date and waits for a free block 
+	  in this case, &lt;num_waiting&gt; increased by one and then the
+	  thread makes &lt;sem&gt; up-to-date and waits for a free block
 	  via &lt;sem&gt; in one step; finally, &lt;num_waiting&gt; is decreased
 	  by one
 	- if a block is freed and &lt;num_waiting&gt; is non-zero;
-	  here, count of &lt;sem&gt; is updated to release threads waiting 
+	  here, count of &lt;sem&gt; is updated to release threads waiting
 	  for allocation
 	- if a new chunk of blocks is allocated;
 	  same as previous case
@@ -51,7 +51,6 @@
 	benaphore mutex;			// to be used whenever some variable of the first
 								// block of this structure is read or modified
 	int free_blocks;			// # free blocks
-	int diff_locks;				// # how often &lt;sem&gt; must be acquired
 	int num_waiting;			// # waiting allocations
 	void *free_list;			// list of free blocks
 	int next_ofs;				// offset of next-pointer in block
@@ -77,265 +76,141 @@
 // header of memory chunk
 typedef struct chunk_header {
 	struct chunk_header *next;	// free-list
-	area_id region;				// underlying region
+	area_id area;				// underlying area
 	int num_blocks;				// size in blocks
 } chunk_header;
 
 
 // global list of pools
-static locked_pool *locked_pools;
-// benaphore to protect locked_pools
-static benaphore locked_pool_ben;
+static locked_pool *sLockedPools;
+// benaphore to protect sLockedPools
+static benaphore sLockedPoolsLock;
 // true, if thread should shut down
-static bool locked_pool_shutting_down;
+static bool sShuttingDown;
 // background thread to enlarge pools
-static thread_id locked_pool_enlarger_thread;
+static thread_id sEnlargerThread;
 // semaphore to wake up enlarger thread
-static sem_id locked_pool_enlarger_sem;
+static sem_id sEnlargerSemaphore;
 
 // macro to access next-pointer in free block
 #define NEXT_PTR(pool, a) ((void **)(((char *)a) + pool-&gt;next_ofs))
 
 
-/** public: alloc memory from pool */
-
-static void *
-pool_alloc(locked_pool *pool)
-{
-	void *block;
-	int num_to_lock;
-
-	TRACE((&quot;pool_alloc()\n&quot;));
-
-	benaphore_lock(&amp;pool-&gt;mutex);
-
-	--pool-&gt;free_blocks;
-
-	if (pool-&gt;free_blocks &gt; 0) {
-		// there are free blocks - grab one
-
-		// increase difference between allocations executed and those
-		// reflected in pool semaphore
-		++pool-&gt;diff_locks;
-
-		TRACE((&quot;freeblocks=%d, diff_locks=%d, free_list=%p\n&quot;,
-			pool-&gt;free_blocks, pool-&gt;diff_locks, pool-&gt;free_list));
-
-		block = pool-&gt;free_list;
-		pool-&gt;free_list = *NEXT_PTR(pool, block);
-		
-		TRACE((&quot;new free_list=%p\n&quot;, pool-&gt;free_list));
-
-		benaphore_unlock(&amp;pool-&gt;mutex);
-		return block;
-	}
-
-	// entire pool is in use
-	// we should do a ++free_blocks here, but this can lead to race
-	// condition: when we wait for &lt;sem&gt; and a block gets released
-	// and another thread calls alloc() before we grab the freshly freed
-	// block, the other thread could overtake us and grab the free block
-	// instead! by leaving free_block at a negative value, the other
-	// thread cannot see the free block and thus will leave it for us
-
-	// tell them we are waiting on semaphore
-	++pool-&gt;num_waiting;
-
-	// make pool semaphore up-to-date; 
-	// add one as we want to allocate a block
-	num_to_lock = pool-&gt;diff_locks+1;
-	pool-&gt;diff_locks = 0;
-
-	TRACE((&quot;locking %d times (%d waiting allocs)\n&quot;, num_to_lock, pool-&gt;num_waiting));
-
-	benaphore_unlock(&amp;pool-&gt;mutex);
-
-	// awake background thread
-	release_sem_etc(locked_pool_enlarger_sem, 1, B_DO_NOT_RESCHEDULE);
-	// make samphore up-to-date and wait until a block is available
-	acquire_sem_etc(pool-&gt;sem, num_to_lock, 0, 0);
-
-	benaphore_lock(&amp;pool-&gt;mutex);
-
-	// tell them that we don't wait on semaphore anymore	
-	--pool-&gt;num_waiting;
-
-	TRACE((&quot;continuing alloc (%d free blocks)\n&quot;, pool-&gt;free_blocks));
-
-	block = pool-&gt;free_list;
-	pool-&gt;free_list = *NEXT_PTR(pool, block);
-
-	benaphore_unlock(&amp;pool-&gt;mutex);
-	return block;
-}
-
-
-/** public: free block */
-
-static void
-pool_free(locked_pool *pool, void *block)
-{
-	int num_to_unlock;
-
-	TRACE((&quot;pool_free()\n&quot;));
-
-	benaphore_lock(&amp;pool-&gt;mutex);
-
-	// add to free list	
-	*NEXT_PTR(pool, block) = pool-&gt;free_list;
-	pool-&gt;free_list = block;
-
-	++pool-&gt;free_blocks;
-
-	// increase difference between allocation executed and those
-	// reflected in pool semaphore
-	--pool-&gt;diff_locks;
-
-	TRACE((&quot;freeblocks=%d, diff_locks=%d, free_list=%p\n&quot;,
-		pool-&gt;free_blocks, pool-&gt;diff_locks, pool-&gt;free_list));
-
-	if (pool-&gt;num_waiting == 0) {
-		// if noone is waiting, this is it
-		//SHOW_FLOW0( 3, &quot;leaving&quot; );
-		benaphore_unlock(&amp;pool-&gt;mutex);
-		//SHOW_FLOW0( 3, &quot;done&quot; );
-		return;
-	}
-
-	// someone is waiting on semaphore, so we have to make it up-to-date
-	num_to_unlock = -pool-&gt;diff_locks;
-	pool-&gt;diff_locks = 0;
-
-	TRACE((&quot;unlocking %d times (%d waiting allocs)\n&quot;,
-		num_to_unlock, pool-&gt;num_waiting));
-
-	benaphore_unlock(&amp;pool-&gt;mutex);
-
-	// now it is up-to-date and waiting allocations can be continued
-	release_sem_etc(pool-&gt;sem, num_to_unlock, 0);
-	return;
-}
-
-
-/** enlarge memory pool by &lt;num_block&gt; blocks */
-
+/*! Enlarge memory pool by &lt;num_block&gt; blocks */
 static status_t
-enlarge_pool(locked_pool *pool, int num_blocks)
+enlarge_pool(locked_pool *pool, int numBlocks)
 {
 	void **next;
 	int i;
-	status_t res;
-	area_id region;
+	int numWaiting;
+	status_t status;
+	area_id area;
 	chunk_header *chunk;
-	size_t chunk_size;
-	int num_to_unlock;
-	void *block, *last_block;
-	
+	size_t chunkSize;
+	void *block, *lastBlock;
+
 	TRACE((&quot;enlarge_pool()\n&quot;));
 
 	// get memory directly from VM; we don't let user code access memory
-	chunk_size = num_blocks * pool-&gt;block_size + pool-&gt;header_size;
-	chunk_size = (chunk_size + B_PAGE_SIZE - 1) &amp; ~(B_PAGE_SIZE - 1);
+	chunkSize = numBlocks * pool-&gt;block_size + pool-&gt;header_size;
+	chunkSize = (chunkSize + B_PAGE_SIZE - 1) &amp; ~(B_PAGE_SIZE - 1);
 
-	res = region = create_area(pool-&gt;name,
-		(void **)&amp;chunk, B_ANY_KERNEL_ADDRESS, chunk_size,
+	status = area = create_area(pool-&gt;name,
+		(void **)&amp;chunk, B_ANY_KERNEL_ADDRESS, chunkSize,
 		pool-&gt;lock_flags, 0);
-	if (res &lt; 0) {
-		dprintf(&quot;cannot enlarge pool (%s)\n&quot;, strerror(res));
-		return res;
+	if (status &lt; B_OK) {
+		dprintf(&quot;cannot enlarge pool (%s)\n&quot;, strerror(status));
+		// TODO: we should wait a bit and try again!
+		return status;
 	}
 
-	chunk-&gt;region = region;
-	chunk-&gt;num_blocks = num_blocks;
+	chunk-&gt;area = area;
+	chunk-&gt;num_blocks = numBlocks;
 
 	// create free_list and call add-hook
 	// very important: we first create a freelist within the chunk,
 	// going from lower to higher addresses; at the end of the loop,
-	// &quot;next&quot; points to the head of the list and &quot;last_block&quot; to the
+	// &quot;next&quot; points to the head of the list and &quot;lastBlock&quot; to the
 	// last list node!
 	next = NULL;
 
-	last_block = (char *)chunk + pool-&gt;header_size + 
-		(num_blocks-1) * pool-&gt;block_size;
+	lastBlock = (char *)chunk + pool-&gt;header_size +
+		(numBlocks-1) * pool-&gt;block_size;
 
-	for (i = 0, block = last_block; i &lt; num_blocks;
-		 ++i, block = (char *)block - pool-&gt;block_size) 
+	for (i = 0, block = lastBlock; i &lt; numBlocks;
+		 ++i, block = (char *)block - pool-&gt;block_size)
 	{
 		if (pool-&gt;add_hook) {
-			if ((res = pool-&gt;add_hook(block, pool-&gt;hook_arg)) &lt; 0)
+			if ((status = pool-&gt;add_hook(block, pool-&gt;hook_arg)) &lt; B_OK)
 				break;
 		}
 
-		*NEXT_PTR(pool, block) = next;		
+		*NEXT_PTR(pool, block) = next;
 		next = block;
 	}
 
-	if (i &lt; num_blocks) {
+	if (i &lt; numBlocks) {
 		// ups - pre-init failed somehow
 		// call remove-hook for blocks that we called add-hook for
 		int j;
 
-		for (block = last_block, j = 0; j &lt; i; ++j, block = (char *)block - pool-&gt;block_size) {
+		for (block = lastBlock, j = 0; j &lt; i; ++j,
+				block = (char *)block - pool-&gt;block_size) {
 			if (pool-&gt;remove_hook)
 				pool-&gt;remove_hook(block, pool-&gt;hook_arg);
 		}
 
-		// destroy area and give up		
-		delete_area(chunk-&gt;region);
+		// destroy area and give up
+		delete_area(chunk-&gt;area);
 
-		return res;
+		return status;
 	}
 
 	// add new blocks to pool
 	benaphore_lock(&amp;pool-&gt;mutex);
 
-	// see remarks about initialising list within chunk	
-	*NEXT_PTR(pool, last_block) = pool-&gt;free_list;
+	// see remarks about initialising list within chunk
+	*NEXT_PTR(pool, lastBlock) = pool-&gt;free_list;
 	pool-&gt;free_list = next;
 
 	chunk-&gt;next = pool-&gt;chunks;
 	pool-&gt;chunks = chunk;
 
-	pool-&gt;num_blocks += num_blocks;
+	pool-&gt;num_blocks += numBlocks;
+	pool-&gt;free_blocks += numBlocks;
 
-	pool-&gt;free_blocks += num_blocks;
-	pool-&gt;diff_locks -= num_blocks;
+	TRACE((&quot;done - num_blocks=%d, free_blocks=%d, num_waiting=%d\n&quot;,
+		pool-&gt;num_blocks, pool-&gt;free_blocks, pool-&gt;num_waiting));
 
-	// update sem instantly (we could check waiting flag whether updating
-	// is really necessary, but we don't go for speed here)
-	num_to_unlock = -pool-&gt;diff_locks;
-	pool-&gt;diff_locks = 0;
+	numWaiting = min_c(pool-&gt;num_waiting, numBlocks);
+	pool-&gt;num_waiting -= numWaiting;
 
-	TRACE((&quot;done - num_blocks=%d, free_blocks=%d, num_waiting=%d, num_to_unlock=%d\n&quot;,
-		pool-&gt;num_blocks, pool-&gt;free_blocks, pool-&gt;num_waiting, num_to_unlock));
-
 	benaphore_unlock(&amp;pool-&gt;mutex);
 
-	// bring sem up-to-date, releasing threads that wait for empty blocks	
-	release_sem_etc(pool-&gt;sem, num_to_unlock, 0);
+	// release threads that wait for empty blocks
+	release_sem_etc(pool-&gt;sem, numWaiting, 0);
 
 	return B_OK;
 }
 
 
-/** background thread that adjusts pool size */
-
+/*! Background thread that adjusts pool size */
 static int32
-enlarger_threadproc(void *arg)
-{	
+enlarger_thread(void *arg)
+{
 	while (1) {
 		locked_pool *pool;
 
-		acquire_sem(locked_pool_enlarger_sem);
+		acquire_sem(sEnlargerSemaphore);
 
-		if (locked_pool_shutting_down)
+		if (sShuttingDown)
 			break;
 
 		// protect traversing of global list and
 		// block destroy_pool() to not clean up a pool we are enlarging
-		benaphore_lock(&amp;locked_pool_ben);
+		benaphore_lock(&amp;sLockedPoolsLock);
 
-		for (pool = locked_pools; pool; pool = pool-&gt;next) {
+		for (pool = sLockedPools; pool; pool = pool-&gt;next) {
 			int num_free;
 
 			// this mutex is probably not necessary (at least on 80x86)
@@ -353,20 +228,19 @@
 			// never create more blocks then defined - the caller may have
 			// a good reason for choosing the limit
 			if (pool-&gt;num_blocks &lt; pool-&gt;max_blocks) {
-				enlarge_pool(pool, 
+				enlarge_pool(pool,
 					min(pool-&gt;enlarge_by, pool-&gt;max_blocks - pool-&gt;num_blocks));
 			}
 		}
 
-		benaphore_unlock(&amp;locked_pool_ben);
+		benaphore_unlock(&amp;sLockedPoolsLock);
 	}
 
 	return 0;
 }
 
 
-/** free all chunks belonging to pool */
-
+/*! Free all chunks belonging to pool */
 static void
 free_chunks(locked_pool *pool)
 {
@@ -374,37 +248,182 @@
 
 	for (chunk = pool-&gt;chunks; chunk; chunk = next) {
 		int i;
-		void *block, *last_block;
+		void *block, *lastBlock;
 
 		next = chunk-&gt;next;
 
-		last_block = (char *)chunk + pool-&gt;header_size + 
+		lastBlock = (char *)chunk + pool-&gt;header_size +
 			(chunk-&gt;num_blocks-1) * pool-&gt;block_size;
 
-		// don't forget to call remove-hook		
-		for (i = 0, block = last_block; i &lt; pool-&gt;num_blocks; ++i, block = (char *)block - pool-&gt;block_size) {
+		// don't forget to call remove-hook
+		for (i = 0, block = lastBlock; i &lt; pool-&gt;num_blocks; ++i, block = (char *)block - pool-&gt;block_size) {
 			if (pool-&gt;remove_hook)
 				pool-&gt;remove_hook(block, pool-&gt;hook_arg);
 		}
 
-		delete_area(chunk-&gt;region);
+		delete_area(chunk-&gt;area);
 	}
 
 	pool-&gt;chunks = NULL;
 }
 
 
-/** public: create pool */
+/*! Global init, executed when module is loaded */
+static status_t
+init_locked_pool(void)
+{
+	status_t status = benaphore_init(&amp;sLockedPoolsLock,
+		&quot;locked_pool_global_list&quot;);
+	if (status &lt; B_OK)
+		goto err;
 
+	status = sEnlargerSemaphore = create_sem(0, &quot;locked_pool_enlarger&quot;);
+	if (status &lt; B_OK)
+		goto err2;
+
+	sLockedPools = NULL;
+	sShuttingDown = false;
+
+	status = sEnlargerThread = spawn_kernel_thread(enlarger_thread,
+		&quot;locked_pool_enlarger&quot;, B_NORMAL_PRIORITY, NULL);
+	if (status &lt; B_OK)
+		goto err3;
+
+	resume_thread(sEnlargerThread);
+	return B_OK;
+
+err3:
+	delete_sem(sEnlargerSemaphore);
+err2:
+	benaphore_destroy(&amp;sLockedPoolsLock);
+err:
+	return status;
+}
+
+
+/*! Global uninit, executed before module is unloaded */
+static status_t
+uninit_locked_pool(void)
+{
+	sShuttingDown = true;
+
+	release_sem(sEnlargerSemaphore);
+
+	wait_for_thread(sEnlargerThread, NULL);
+
+	delete_sem(sEnlargerSemaphore);
+	benaphore_destroy(&amp;sLockedPoolsLock);
+
+	return B_OK;
+}
+
+
+//	#pragma mark - Module API
+
+
+/*! Alloc memory from pool */
+static void *
+pool_alloc(locked_pool *pool)
+{
+	void *block;
+
+	TRACE((&quot;pool_alloc()\n&quot;));
+
+	benaphore_lock(&amp;pool-&gt;mutex);
+
+	--pool-&gt;free_blocks;
+
+	if (pool-&gt;free_blocks &gt; 0) {
+		// there are free blocks - grab one
+
+		TRACE((&quot;freeblocks=%d, free_list=%p\n&quot;,
+			pool-&gt;free_blocks, pool-&gt;free_list));
+
+		block = pool-&gt;free_list;
+		pool-&gt;free_list = *NEXT_PTR(pool, block);
+
+		TRACE((&quot;new free_list=%p\n&quot;, pool-&gt;free_list));
+
+		benaphore_unlock(&amp;pool-&gt;mutex);
+		return block;
+	}
+
+	// entire pool is in use
+	// we should do a ++free_blocks here, but this can lead to race
+	// condition: when we wait for &lt;sem&gt; and a block gets released
+	// and another thread calls alloc() before we grab the freshly freed
+	// block, the other thread could overtake us and grab the free block
+	// instead! by leaving free_block at a negative value, the other
+	// thread cannot see the free block and thus will leave it for us
+
+	// tell them we are waiting on semaphore
+	++pool-&gt;num_waiting;
+
+	TRACE((&quot;%d waiting allocs\n&quot;, pool-&gt;num_waiting));
+
+	benaphore_unlock(&amp;pool-&gt;mutex);
+
+	// awake background thread
+	release_sem_etc(sEnlargerSemaphore, 1, B_DO_NOT_RESCHEDULE);
+	// make samphore up-to-date and wait until a block is available
+	acquire_sem(pool-&gt;sem);
+
+	benaphore_lock(&amp;pool-&gt;mutex);
+
+	TRACE((&quot;continuing alloc (%d free blocks)\n&quot;, pool-&gt;free_blocks));
+
+	block = pool-&gt;free_list;
+	pool-&gt;free_list = *NEXT_PTR(pool, block);
+
+	benaphore_unlock(&amp;pool-&gt;mutex);
+	return block;
+}
+
+
+static void
+pool_free(locked_pool *pool, void *block)
+{
+	TRACE((&quot;pool_free()\n&quot;));
+
+	benaphore_lock(&amp;pool-&gt;mutex);
+
+	// add to free list
+	*NEXT_PTR(pool, block) = pool-&gt;free_list;
+	pool-&gt;free_list = block;
+
+	++pool-&gt;free_blocks;
+
+	TRACE((&quot;freeblocks=%d, free_list=%p\n&quot;, pool-&gt;free_blocks,
+		pool-&gt;free_list));
+
+	if (pool-&gt;num_waiting == 0) {
+		// if no one is waiting, this is it
+		benaphore_unlock(&amp;pool-&gt;mutex);
+		return;
+	}
+
+	// someone is waiting on the semaphore
+
+	TRACE((&quot;%d waiting allocs\n&quot;, pool-&gt;num_waiting));
+	pool-&gt;num_waiting--;
+
+	benaphore_unlock(&amp;pool-&gt;mutex);
+
+	// now it is up-to-date and waiting allocations can be continued
+	release_sem(pool-&gt;sem);
+	return;
+}
+
+
 static locked_pool *
 create_pool(int block_size, int alignment, int next_ofs,
-	int chunk_size, int max_blocks, int min_free_blocks, 
+	int chunkSize, int max_blocks, int min_free_blocks,
 	const char *name, uint32 lock_flags,
-	locked_pool_add_hook add_hook, 
+	locked_pool_add_hook add_hook,
 	locked_pool_remove_hook remove_hook, void *hook_arg)
 {
 	locked_pool *pool;
-	status_t res;
+	status_t status;
 
 	TRACE((&quot;create_pool()\n&quot;));
 
@@ -414,36 +433,35 @@
 
 	memset(pool, sizeof(*pool), 0);
 
-	if ((res = benaphore_init(&amp;pool-&gt;mutex, &quot;locked_pool&quot;)) &lt; 0)
+	if ((status = benaphore_init(&amp;pool-&gt;mutex, &quot;locked_pool&quot;)) &lt; 0)
 		goto err;
 
-	if ((res = pool-&gt;sem = create_sem(0, &quot;locked_pool&quot;)) &lt; 0)
+	if ((status = pool-&gt;sem = create_sem(0, &quot;locked_pool&quot;)) &lt; 0)
 		goto err1;
 
 	if ((pool-&gt;name = strdup(name)) == NULL) {
-		res = B_NO_MEMORY;
+		status = B_NO_MEMORY;
 		goto err3;
 	}
-	
+
 	pool-&gt;alignment = alignment;
-	
-	// take care that there is always enough space to fulfill alignment	
+
+	// take care that there is always enough space to fulfill alignment
 	pool-&gt;block_size = (block_size + pool-&gt;alignment) &amp; ~pool-&gt;alignment;
-	
+
 	pool-&gt;next_ofs = next_ofs;
 	pool-&gt;lock_flags = lock_flags;
-	
-	pool-&gt;header_size = max((sizeof( chunk_header ) + pool-&gt;alignment) &amp; ~pool-&gt;alignment, 
+
+	pool-&gt;header_size = max((sizeof( chunk_header ) + pool-&gt;alignment) &amp; ~pool-&gt;alignment,
 		pool-&gt;alignment + 1);
 
-	pool-&gt;enlarge_by = (((chunk_size + B_PAGE_SIZE - 1) &amp; ~(B_PAGE_SIZE - 1)) - pool-&gt;header_size)
+	pool-&gt;enlarge_by = (((chunkSize + B_PAGE_SIZE - 1) &amp; ~(B_PAGE_SIZE - 1)) - pool-&gt;header_size)
 		/ pool-&gt;block_size;
 
 	pool-&gt;max_blocks = max_blocks;
 	pool-&gt;min_free_blocks = min_free_blocks;
 	pool-&gt;free_blocks = 0;
 	pool-&gt;num_blocks = 0;
-	pool-&gt;diff_locks = 0;
 	pool-&gt;num_waiting = 0;
 	pool-&gt;free_list = NULL;
 	pool-&gt;add_hook = add_hook;
@@ -457,14 +475,14 @@
 
 	// if there is a minimum size, enlarge pool right now
 	if (min_free_blocks &gt; 0) {
-		if ((res = enlarge_pool(pool, min(pool-&gt;enlarge_by, pool-&gt;max_blocks))) &lt; 0)
+		if ((status = enlarge_pool(pool, min(pool-&gt;enlarge_by, pool-&gt;max_blocks))) &lt; 0)
 			goto err4;
 	}
 
 	// add to global list, so enlarger thread takes care of pool
-	benaphore_lock(&amp;locked_pool_ben);
-	ADD_DL_LIST_HEAD(pool, locked_pools, );
-	benaphore_unlock(&amp;locked_pool_ben);
+	benaphore_lock(&amp;sLockedPoolsLock);
+	ADD_DL_LIST_HEAD(pool, sLockedPools, );
+	benaphore_unlock(&amp;sLockedPoolsLock);
 
 	return pool;
 
@@ -480,8 +498,6 @@
 }
 
 
-/** public: destroy pool */
-
 static void
 destroy_pool(locked_pool *pool)
 {
@@ -489,11 +505,11 @@
 
 	// first, remove from global list, so enlarger thread
 	// won't touch this pool anymore
-	benaphore_lock(&amp;locked_pool_ben);
-	REMOVE_DL_LIST(pool, locked_pools, );
-	benaphore_unlock(&amp;locked_pool_ben);
+	benaphore_lock(&amp;sLockedPoolsLock);
+	REMOVE_DL_LIST(pool, sLockedPools, );
+	benaphore_unlock(&amp;sLockedPoolsLock);
 
-	// then cleanup pool	
+	// then cleanup pool
 	free_chunks(pool);
 
 	free(pool-&gt;name);
@@ -504,59 +520,7 @@
 }
 
 
-/** global init, executed when module is loaded */
-
 static status_t
-init_locked_pool(void)
-{
-	status_t res;
-	
-	if ((res = benaphore_init(&amp;locked_pool_ben, &quot;locked_pool_global_list&quot;)) &lt; B_OK)
-		goto err;
-
-	if ((res = locked_pool_enlarger_sem = create_sem(0, &quot;locked_pool_enlarger&quot;)) &lt; B_OK)
-		goto err2;
-
-	locked_pools = NULL;
-	locked_pool_shutting_down = false;
-
-	if ((res = locked_pool_enlarger_thread = spawn_kernel_thread(enlarger_threadproc,
-					&quot;locked_pool_enlarger&quot;, B_NORMAL_PRIORITY, NULL)) &lt; B_OK)
-		goto err3;
-
-	resume_thread(locked_pool_enlarger_thread);
-
-	return B_OK;
-
-err3:
-	delete_sem(locked_pool_enlarger_sem);
-err2:
-	benaphore_destroy(&amp;locked_pool_ben);
-err:
-	return res;
-}
-
-
-/** global uninit, executed before module is unloaded */
-
-static status_t
-uninit_locked_pool(void)
-{
-	int32 retcode;
-	locked_pool_shutting_down = true;
-	
-	release_sem(locked_pool_enlarger_sem);
-
-	wait_for_thread(locked_pool_enlarger_thread, &amp;retcode);
-
-	delete_sem(locked_pool_enlarger_sem);
-	benaphore_destroy(&amp;locked_pool_ben);
-
-	return B_OK;
-}
-
-
-static status_t
 std_ops(int32 op, ...)
 {
 	switch (op) {
@@ -578,16 +542,15 @@
 		std_ops
 	},
 
-	pool_alloc, 
+	pool_alloc,
 	pool_free,
 
-	create_pool, 
+	create_pool,
 	destroy_pool
 };
 
-#if !_BUILDING_kernel &amp;&amp; !BOOT
+
 module_info *modules[] = {
 	&amp;interface.minfo,
 	NULL
 };
-#endif


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="007103.html">[Haiku-commits] r24587 - haiku/trunk/src/tools/fs_shell
</A></li>
	<LI>Next message: <A HREF="007108.html">[Haiku-commits] r24589 - haiku/trunk/src/system/kernel/cache
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#7105">[ date ]</a>
              <a href="thread.html#7105">[ thread ]</a>
              <a href="subject.html#7105">[ subject ]</a>
              <a href="author.html#7105">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
