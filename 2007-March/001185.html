<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [Haiku-commits] r20406 -	haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server
   </TITLE>
   <LINK REL="Index" HREF="http://lists.berlios.de/pipermail/haiku-commits/2007-March/index.html" >
   <LINK REL="made" HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r20406%20-%0A%09haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server&In-Reply-To=%3C200703230009.l2N09vMt029060%40sheep.berlios.de%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="001217.html">
   <LINK REL="Next"  HREF="001186.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[Haiku-commits] r20406 -	haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server</H1>
    <B>bonefish at BerliOS</B> 
    <A HREF="mailto:haiku-commits%40lists.berlios.de?Subject=Re%3A%20%5BHaiku-commits%5D%20r20406%20-%0A%09haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server&In-Reply-To=%3C200703230009.l2N09vMt029060%40sheep.berlios.de%3E"
       TITLE="[Haiku-commits] r20406 -	haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server">bonefish at mail.berlios.de
       </A><BR>
    <I>Fri Mar 23 01:09:57 CET 2007</I>
    <P><UL>
        <LI>Previous message: <A HREF="001217.html">[Haiku-commits] r20405 - in haiku/trunk/headers/private: kernel/util userlandfs/shared
</A></li>
        <LI>Next message: <A HREF="001186.html">[Haiku-commits] r20407 - in haiku/trunk: headers/private/kernel	src/system/kernel/vm
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1185">[ date ]</a>
              <a href="thread.html#1185">[ thread ]</a>
              <a href="subject.html#1185">[ subject ]</a>
              <a href="author.html#1185">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Author: bonefish
Date: 2007-03-23 01:09:55 +0100 (Fri, 23 Mar 2007)
New Revision: 20406
ViewCVS: <A HREF="http://svn.berlios.de/viewcvs/haiku?rev=20406&amp;view=rev">http://svn.berlios.de/viewcvs/haiku?rev=20406&amp;view=rev</A>

Added:
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp
Modified:
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.cpp
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.h
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/Jamfile
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/UserlandFSServer.cpp
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_fs_cache.h
   haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_kernel_emu.cpp
Log:
Added a Haiku file cache implementation to the UserlandFSServer.
Basically reused the kernel implementation, but needed to hack it quite
a bit and also add an emulation of the required VM interface.
Completely untested yet.


Modified: haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.cpp
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.cpp	2007-03-23 00:03:59 UTC (rev 20405)
+++ haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.cpp	2007-03-23 00:09:55 UTC (rev 20406)
@@ -9,6 +9,7 @@
 
 #include &quot;Debug.h&quot;
 #include &quot;kernel_emu.h&quot;
+#include &quot;haiku_fs_cache.h&quot;
 
 
 // constructor
@@ -35,8 +36,22 @@
 {
 	if (!fFSModule-&gt;mount)
 		return B_BAD_VALUE;
-	return fFSModule-&gt;mount(GetID(), device, flags, parameters, &amp;fVolumeCookie,
-		rootID);
+
+	// make the volume know to the file cache emulation
+	status_t error
+		= UserlandFS::HaikuKernelEmu::file_cache_register_volume(this);
+	if (error != B_OK)
+		return error;
+
+	// mount
+	error = fFSModule-&gt;mount(GetID(), device, flags, parameters,
+		&amp;fVolumeCookie, rootID);
+	if (error != B_OK) {
+		UserlandFS::HaikuKernelEmu::file_cache_unregister_volume(this);
+		return error;
+	}
+
+	return B_OK;
 }
 
 // Unmount
@@ -45,7 +60,14 @@
 {
 	if (!fFSModule-&gt;unmount)
 		return B_BAD_VALUE;
-	return fFSModule-&gt;unmount(fVolumeCookie);
+
+	// unmount
+	status_t error = fFSModule-&gt;unmount(fVolumeCookie);
+
+	// unregister with the file cache emulation
+	UserlandFS::HaikuKernelEmu::file_cache_unregister_volume(this);
+
+	return error;
 }
 
 // Sync
@@ -76,6 +98,21 @@
 }
 
 
+// #pragma mark - file cache
+
+
+// GetFileMap
+status_t
+HaikuKernelVolume::GetFileMap(fs_vnode node, off_t offset, size_t size,
+	struct file_io_vec* vecs, size_t* count)
+{
+	if (!fFSModule-&gt;get_file_map)
+		return B_BAD_VALUE;
+	return fFSModule-&gt;get_file_map(fVolumeCookie, node, offset, size, vecs,
+		count);
+}
+
+
 // #pragma mark - vnodes
 
 

Modified: haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.h
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.h	2007-03-23 00:03:59 UTC (rev 20405)
+++ haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/HaikuKernelVolume.h	2007-03-23 00:09:55 UTC (rev 20406)
@@ -25,6 +25,11 @@
 	virtual	status_t			WriteFSInfo(const struct fs_info* info,
 									uint32 mask);
 
+	// file cache
+	virtual	status_t			GetFileMap(fs_vnode node, off_t offset,
+									size_t size, struct file_io_vec* vecs,
+									size_t* count);
+
 	// vnodes
 	virtual	status_t			Lookup(fs_vnode dir, const char* entryName,
 									vnode_id* vnid, int* type);

Modified: haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/Jamfile
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/Jamfile	2007-03-23 00:03:59 UTC (rev 20405)
+++ haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/Jamfile	2007-03-23 00:09:55 UTC (rev 20406)
@@ -41,6 +41,7 @@
 	  DispatcherFileSystem.cpp
 	  FileSystem.cpp
 	  haiku_block_cache.cpp
+	  haiku_file_cache.cpp
 	  haiku_hash.cpp
 	  haiku_lock.cpp
 	  HaikuKernelFileSystem.cpp

Modified: haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/UserlandFSServer.cpp
===================================================================
--- haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/UserlandFSServer.cpp	2007-03-23 00:03:59 UTC (rev 20405)
+++ haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/UserlandFSServer.cpp	2007-03-23 00:09:55 UTC (rev 20406)
@@ -24,6 +24,7 @@
 #include &quot;FileSystem.h&quot;
 #include &quot;FSInfo.h&quot;
 #include &quot;haiku_block_cache_priv.h&quot;
+#include &quot;haiku_fs_cache.h&quot;
 #include &quot;HaikuKernelFileSystem.h&quot;
 #include &quot;RequestThread.h&quot;
 #include &quot;ServerDefs.h&quot;
@@ -281,6 +282,11 @@
 	if (error != B_OK)
 		RETURN_ERROR(error);
 
+	// init file cache
+	error = UserlandFS::HaikuKernelEmu::file_cache_init();
+	if (error != B_OK)
+		RETURN_ERROR(error);
+
 	// init the FS
 	error = fileSystem-&gt;Init();
 	if (error != B_OK)

Copied: haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp (from rev 20374, haiku/trunk/src/system/kernel/cache/file_cache.cpp)
===================================================================
--- haiku/trunk/src/system/kernel/cache/file_cache.cpp	2007-03-11 23:17:28 UTC (rev 20374)
+++ haiku/trunk/src/add-ons/kernel/file_systems/userlandfs/server/haiku_file_cache.cpp	2007-03-23 00:09:55 UTC (rev 20406)
@@ -0,0 +1,1893 @@
+/*
+ * Copyright 2004-2007, Haiku Inc. All rights reserved.
+ * Distributed under the terms of the MIT License.
+ *
+ * Authors:
+ * 		Axel D&#246;rfler &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">axeld at pinc-software.de</A>&gt;
+ * 		Ingo Weinhold &lt;<A HREF="https://lists.berlios.de/mailman/listinfo/haiku-commits">bonefish at cs.tu-berlin.de</A>&gt;
+ */
+
+#include &quot;haiku_fs_cache.h&quot;
+
+#include &lt;new&gt;
+
+#include &lt;stdlib.h&gt;
+#include &lt;string.h&gt;
+#include &lt;unistd.h&gt;
+
+#include &lt;Debug.h&gt;
+
+#include &lt;kernel/util/DoublyLinkedList.h&gt;
+
+#include &quot;haiku_hash.h&quot;
+#include &quot;haiku_lock.h&quot;
+#include &quot;HaikuKernelVolume.h&quot;
+#include &quot;kernel_emu.h&quot;
+
+#undef TRACE
+//#define TRACE_FILE_CACHE
+#ifdef TRACE_FILE_CACHE
+#	define TRACE(x) dprintf x
+#else
+#	define TRACE(x) ;
+#endif
+
+using std::nothrow;
+
+
+// This is a hacked version of the kernel file cache implementation. The main
+// part of the implementation didn't change that much -- some code not needed
+// in userland has been removed, file_cache_ref, vm_cache_ref and vm_cache
+// have been unified, and the complete interface to the VM (vm_*()) and the
+// VFS (vfs_*()) has been re-implemented to suit our needs.
+//
+// The PagePool class is a data structure used for managing the pages (vm_page)
+// allocated and assigned to caches (file_cache_ref). It has a list for free
+// pages, i.e. those that are not assigned to any cache and can be reused at
+// once. A second list contains those pages that belong to a cache, but are
+// not in use by any of the functions. These pages have a reference count of
+// 0. They will be stolen from the owning cache when a usable page is needed,
+// there are no free pages anymore, and the limit of pages that shall be used
+// at maximum has already been reached.
+//
+// The only purpose of the page reference count (vm_page::ref_count) is to
+// indicate whether the page is in use (i.e. known to one or more of the cache
+// functions currently being executed). vm_page_get_page(),
+// vm_page_allocate_page(), and vm_cache_lookup_page acquire a reference to
+// the page, vm_page_put_page() releases a reference.
+
+// vm_page::state indicates in what state
+// a page currently is. PAGE_STATE_FREE is only encountered for pages not
+// belonging to a cache (being in page pool's free pages list, or just having
+// been removed or not yet added). PAGE_STATE_ACTIVE/MODIFIED indicate that
+// the page contains valid file data, in the latter case not yet written to
+// disk. PAGE_STATE_BUSY means that the page is currently being manipulated by
+// an operation, usually meaning that page data are being read from/written to
+// disk. The required behavior when encountering a busy page, is to put the
+// page, release the page pool and cache locks, wait a short time, and
+// retry again later.
+//
+// Changing the page state requires having a reference to the page,
+// holding the lock of the owning cache (if any) and the lock of the page pool
+// (in case the page is not newly allocated).
+//
+// A page is in up to three lists. The free or unused list in the page pool
+// (guarded by the page pool lock), the pages list of the cache the page
+// belongs to, and the modified pages list of the cache (both cache lists
+// are guarded by both the page pool and the cache lock). The modified pages
+// list only contains PAGE_STATE_MODIFIED or PAGE_STATE_BUSY pages.
+
+
+// maximum number of iovecs per request
+#define MAX_IO_VECS			64	// 256 kB
+#define MAX_FILE_IO_VECS	32
+
+#define CACHED_FILE_EXTENTS	2
+	// must be smaller than MAX_FILE_IO_VECS
+	// ToDo: find out how much of these are typically used
+
+using UserlandFS::KernelEmu::dprintf;
+using UserlandFS::KernelEmu::panic;
+#define user_memcpy(a, b, c) memcpy(a, b, c)
+
+#define PAGE_ALIGN(x) (((x) + (B_PAGE_SIZE - 1)) &amp; ~(B_PAGE_SIZE - 1))
+
+namespace UserlandFS {
+namespace HaikuKernelEmu {
+
+enum {
+	PAGE_STATE_ACTIVE = 0,
+	PAGE_STATE_BUSY,
+	PAGE_STATE_MODIFIED,
+	PAGE_STATE_FREE
+};
+
+enum {
+	PHYSICAL_PAGE_NO_WAIT = 0,
+	PHYSICAL_PAGE_CAN_WAIT,
+};
+
+struct vm_page;
+struct file_cache_ref;
+
+typedef DoublyLinkedListLink&lt;vm_page&gt; page_link;
+
+// vm page
+struct vm_page {
+	vm_page*			next;
+	page_link			link_cache;
+	page_link			link_cache_modified;
+	page_link			link_pool;
+	file_cache_ref*		cache;
+	off_t				offset;
+	void*				data;
+	uint8				state;
+	uint32				ref_count;
+
+	vm_page()
+		: next(NULL),
+		  cache(NULL),
+		  offset(0),
+		  data(malloc(B_PAGE_SIZE)),
+		  state(PAGE_STATE_FREE),
+		  ref_count(1)
+	{
+	}
+
+	~vm_page()
+	{
+		free(data);
+	}
+
+	addr_t				Address() const	{ return (addr_t)data; }
+
+	static int Compare(void *_cacheEntry, const void *_key);
+	static uint32 Hash(void *_cacheEntry, const void *_key, uint32 range);
+};
+
+struct file_extent {
+	off_t			offset;
+	file_io_vec		disk;
+};
+
+struct file_map {
+	file_map();
+	~file_map();
+
+	file_extent *operator[](uint32 index);
+	file_extent *ExtentAt(uint32 index);
+	status_t Add(file_io_vec *vecs, size_t vecCount, off_t &amp;lastOffset);
+	void Free();
+
+	union {
+		file_extent	direct[CACHED_FILE_EXTENTS];
+		file_extent	*array;
+	};
+	size_t			count;
+};
+
+
+static vm_page *vm_page_allocate_page(int state);
+static void vm_page_get_page(vm_page* page);
+static status_t vm_page_put_page(vm_page* page);
+static status_t vm_page_set_state(vm_page *page, int state);
+
+static void vm_cache_insert_page(file_cache_ref *cacheRef, vm_page *page,
+	off_t offset);
+static void vm_cache_remove_page(file_cache_ref *cacheRef, vm_page *page);
+static vm_page *vm_cache_lookup_page(file_cache_ref *cacheRef, off_t page);
+static status_t vm_cache_resize(file_cache_ref *cacheRef, off_t newSize);
+static status_t vm_cache_write_modified(file_cache_ref *ref, bool fsReenter);
+
+static status_t vfs_read_pages(int fd, off_t pos, const iovec *vecs,
+	size_t count, size_t *_numBytes, bool fsReenter);
+static status_t vfs_write_pages(int fd, off_t pos, const iovec *vecs,
+	size_t count, size_t *_numBytes, bool fsReenter);
+static status_t vfs_get_file_map(file_cache_ref *cache, off_t offset,
+	size_t size, struct file_io_vec *vecs, size_t *_count);
+
+static HaikuKernelVolume* file_cache_get_volume(mount_id mountID);
+
+static status_t pages_io(file_cache_ref *ref, off_t offset, const iovec *vecs,
+	size_t count, size_t *_numBytes, bool doWrite);
+
+
+typedef DoublyLinkedList&lt;vm_page,
+	DoublyLinkedListMemberGetLink&lt;vm_page,
+		&amp;vm_page::link_cache_modified&gt; &gt; cache_modified_page_list;
+
+typedef DoublyLinkedList&lt;vm_page,
+	DoublyLinkedListMemberGetLink&lt;vm_page,
+		&amp;vm_page::link_cache&gt; &gt; cache_page_list;
+
+struct file_cache_ref {
+	mutex						lock;
+	mount_id					mountID;
+	vnode_id					nodeID;
+	fs_vnode					nodeHandle;
+	int							deviceFD;
+	off_t						virtual_size;
+
+	cache_page_list				pages;
+	cache_modified_page_list	modifiedPages;
+
+	file_map					map;
+};
+
+struct page_hash_key {
+	page_hash_key() {}
+	page_hash_key(int fd, vnode_id id, off_t offset)
+		: deviceFD(fd),
+		  nodeID(id),
+		  offset(offset)
+	{
+	}
+
+	int				deviceFD;
+	vnode_id		nodeID;
+	off_t			offset;
+};
+
+
+struct volume_list_entry;
+typedef DoublyLinkedListLink&lt;volume_list_entry&gt; volume_list_link;
+
+struct volume_list_entry {
+	volume_list_link	link;
+	HaikuKernelVolume*	volume;
+};
+
+typedef DoublyLinkedList&lt;volume_list_entry,
+	DoublyLinkedListMemberGetLink&lt;volume_list_entry,
+		&amp;volume_list_entry::link&gt; &gt; volume_list;
+
+typedef DoublyLinkedList&lt;vm_page,
+	DoublyLinkedListMemberGetLink&lt;vm_page,
+		&amp;vm_page::link_pool&gt; &gt; pool_page_list;
+
+struct PagePool {
+
+	PagePool()
+		: pageHash(NULL),
+		  unusedPages(),
+		  freePages(),
+		  allocatedPages(0)
+	{
+	}
+
+	~PagePool()
+	{
+	}
+
+	status_t Init()
+	{
+		status_t error = recursive_lock_init(&amp;lock, &quot;page pool&quot;);
+		if (error != B_OK) {
+			panic(&quot;PagePool: Failed to init lock\n&quot;);
+			return error;
+		}
+
+		pageHash = hash_init(256, 0, &amp;vm_page::Compare, &amp;vm_page::Hash);
+		if (pageHash == NULL) {
+			panic(&quot;PagePool: Failed to create page hash\n&quot;);
+			return B_NO_MEMORY;
+		}
+
+		return B_OK;
+	}
+
+	bool Lock() { return (recursive_lock_lock(&amp;lock) == B_OK); }
+	void Unlock() { recursive_lock_unlock(&amp;lock); }
+
+	recursive_lock	lock;
+	hash_table*		pageHash;
+	pool_page_list	unusedPages;
+	pool_page_list	freePages;
+	uint32			allocatedPages;
+};
+
+struct PagePutter {
+	PagePutter(vm_page* page)
+		: fPage(page)
+	{
+	}
+	
+	~PagePutter()
+	{
+		if (fPage)
+			vm_page_put_page(fPage);
+	}
+
+private:
+	vm_page*	fPage;
+};
+
+static PagePool sPagePool;
+static const uint32 kMaxAllocatedPages = 1024;
+static volume_list sVolumeList;
+static mutex sVolumeListLock;
+
+
+int
+vm_page::Compare(void *_cacheEntry, const void *_key)
+{
+	vm_page *page = (vm_page*)_cacheEntry;
+	const page_hash_key *key = (const page_hash_key *)_key;
+
+	// device FD
+	if (page-&gt;cache-&gt;deviceFD != key-&gt;deviceFD)
+		return page-&gt;cache-&gt;deviceFD - key-&gt;deviceFD;
+
+	// node ID
+	if (page-&gt;cache-&gt;nodeID &lt; key-&gt;nodeID)
+		return -1;
+	if (page-&gt;cache-&gt;nodeID &gt; key-&gt;nodeID)
+		return 1;
+
+	// offset
+	if (page-&gt;offset &lt; key-&gt;offset)
+		return -1;
+	if (page-&gt;offset &gt; key-&gt;offset)
+		return 1;
+
+	return 0;
+}
+
+uint32
+vm_page::Hash(void *_cacheEntry, const void *_key, uint32 range)
+{
+	vm_page *page = (vm_page*)_cacheEntry;
+	const page_hash_key *key = (const page_hash_key *)_key;
+
+	int fd = (page ? page-&gt;cache-&gt;deviceFD : key-&gt;deviceFD);
+	vnode_id id = (page ? page-&gt;cache-&gt;nodeID : key-&gt;nodeID);
+	off_t offset = (page ? page-&gt;offset : key-&gt;offset);
+
+	uint32 value = fd;
+	value = value * 17 + id;
+	value = value * 17 + offset;
+
+	return value % range;
+}
+
+
+vm_page *
+vm_page_allocate_page(int state)
+{
+	AutoLocker&lt;PagePool&gt; poolLocker(sPagePool);
+
+	// is a queued free page available?
+	vm_page* page = sPagePool.freePages.RemoveHead();
+	if (page) {
+		page-&gt;ref_count++;
+		return page;
+	}
+
+	// no free page
+
+	// If the limit for allocated pages has been reached, we try to steal an
+	// unused page.
+	if (sPagePool.allocatedPages &gt;= kMaxAllocatedPages
+		&amp;&amp; !sPagePool.unusedPages.IsEmpty()) {
+		// we grab the first non-busy page
+		for (pool_page_list::Iterator it(&amp;sPagePool.unusedPages);
+			vm_page* currentPage = it.Next();) {
+			if (currentPage-&gt;state != PAGE_STATE_BUSY) {
+				it.Remove();
+				page = currentPage;
+				page-&gt;ref_count++;
+				break;
+			}
+		}
+
+		// If we've found a suitable page, we need to mark it busy, write it
+		// if it was modified, and finally remove it from its cache.
+		if (page != NULL) {
+			bool modified = (page-&gt;state == PAGE_STATE_MODIFIED);
+
+			// mark the page busy
+			page-&gt;state = PAGE_STATE_BUSY;
+
+			// We don't need the pool lock anymore.
+			poolLocker.Unlock();
+
+			file_cache_ref* cache = page-&gt;cache;
+
+			// If the page is modified, we write it to the disk.
+			if (modified) {
+				// find out, how much to write, and remove the page from the
+				// cache's modified pages list
+				MutexLocker cacheLocker(cache-&gt;lock);
+				size_t bytes = min_c(B_PAGE_SIZE,
+					cache-&gt;virtual_size - page-&gt;offset);
+				cache-&gt;modifiedPages.Remove(page);
+				cacheLocker.Unlock();
+
+				// if we need to write anything, do it now
+				if (bytes &gt; 0) {
+					iovec vecs[1];
+					vecs[0].iov_base = page-&gt;data;
+					vecs[0].iov_len = bytes;
+					status_t error = pages_io(cache, page-&gt;offset, vecs, 1,
+						&amp;bytes, true);
+					if (error != B_OK) {
+						// failed to write the page: bad, but we can't do
+						// much about it
+						dprintf(&quot;vm_page_allocate_page(): Failed to write &quot;
+							&quot;page %p (cache %p, offset: %lld).\n&quot;, page,
+							cache, page-&gt;offset);
+					}
+				}
+			}
+
+			// remove the page from the cache
+			MutexLocker cacheLocker(cache-&gt;lock);
+			vm_cache_remove_page(cache, page);
+
+			// now it's ours
+			page-&gt;state = PAGE_STATE_FREE;
+
+			return page;
+		}
+	}
+
+	// no page yet -- allocate a new one
+
+	page = new(nothrow) vm_page;
+	if (!page || !page-&gt;data) {
+		delete page;
+		return NULL;
+	}
+
+	sPagePool.allocatedPages++;
+
+	return page;
+}
+
+
+static void
+vm_page_get_page(vm_page* page)
+{
+	if (page) {
+		AutoLocker&lt;PagePool&gt; _(sPagePool);
+
+		// increase ref count
+		page-&gt;ref_count++;
+
+		// if the page was unused before, remove it from the unused pages list
+		if (page-&gt;ref_count == 1)
+			sPagePool.unusedPages.Remove(page);
+	}
+}
+
+
+static status_t
+vm_page_put_page(vm_page* page)
+{
+	if (!page)
+		return B_BAD_VALUE;
+
+	AutoLocker&lt;PagePool&gt; _(sPagePool);
+
+	if (page-&gt;ref_count &lt;= 0) {
+		panic(&quot;vm_page_put_page(): page %p already unreferenced!\n&quot;, page);
+		return B_BAD_VALUE;
+	}
+
+	// decrease ref count
+	page-&gt;ref_count--;
+
+	if (page-&gt;ref_count &gt; 0)
+		return B_OK;
+
+	// the page is unreference now: add it to the unused or free pages list
+
+	if (page-&gt;state == PAGE_STATE_FREE) {
+		// page is free
+		// if we've maxed out the allowed allocated page, free this one,
+		// otherwise add it to the free list
+		if (sPagePool.allocatedPages &gt; kMaxAllocatedPages) {
+			delete page;
+			sPagePool.allocatedPages--;
+		} else
+			sPagePool.freePages.Add(page);
+	} else {
+		// page is is not free; add to unused pages list
+		sPagePool.unusedPages.Add(page);
+	}
+
+	return B_OK;
+}
+
+
+status_t
+vm_page_set_state(vm_page *page, int state)
+{
+	AutoLocker&lt;PagePool&gt; _(sPagePool);
+
+	if (page-&gt;ref_count &lt;= 0) {
+		panic(&quot;vm_page_set_state(): page %p is already unreferenced!\n&quot;,
+			page);
+		return B_BAD_VALUE;
+	}
+
+	if (state == page-&gt;state)
+		return B_OK;
+
+	// If it was modified before, remove the page from the cache's modified
+	// pages list.
+	if (page-&gt;state == PAGE_STATE_MODIFIED &amp;&amp; page-&gt;cache)
+		page-&gt;cache-&gt;modifiedPages.Remove(page);
+
+	switch (state) {
+		case PAGE_STATE_ACTIVE:
+		case PAGE_STATE_BUSY:
+		case PAGE_STATE_FREE:
+			page-&gt;state = state;
+			break;
+
+		case PAGE_STATE_MODIFIED:
+		{
+			page-&gt;state = state;
+
+			// add page to the modified list of the cache
+			if (!page-&gt;cache) {
+				panic(&quot;vm_page_set_state(): setting page state of page %p &quot;
+					&quot;to PAGE_STATE_MODIFIED, but page is not in a cache\n&quot;,
+					page);
+				return B_BAD_VALUE;
+			}
+
+			page-&gt;cache-&gt;modifiedPages.Add(page);
+
+			break;
+		}
+
+		default:
+			panic(&quot;vm_page_set_state(): invalid page state: %d\n&quot;, state);
+			return B_BAD_VALUE;
+	}
+
+	return B_OK;
+}
+
+
+void
+vm_cache_insert_page(file_cache_ref *cache, vm_page *page, off_t offset)
+{
+	AutoLocker&lt;PagePool&gt; _(sPagePool);
+
+	if (page-&gt;cache != NULL) {
+		panic(&quot;vm_cache_insert_page(%p, %p): page already in cache %p\n&quot;,
+			cache, page, page-&gt;cache);
+		return;
+	}
+
+	page-&gt;cache = cache;
+	page-&gt;offset = offset;
+
+	// insert page into hash
+	status_t error = hash_insert(sPagePool.pageHash, page);
+	if (error != B_OK) {
+		panic(&quot;vm_cache_insert_page(): Failed to insert page %p into hash!\n&quot;,
+			page);
+		page-&gt;cache = NULL;
+		page-&gt;offset = 0;
+		return;
+	}
+
+	// add page to cache page list
+	cache-&gt;pages.Add(page);
+}
+
+
+void
+vm_cache_remove_page(file_cache_ref *cache, vm_page *page)
+{
+	if (cache != page-&gt;cache) {
+		panic(&quot;vm_cache_remove_page(%p, %p): page is in cache %p\n&quot;,
+			cache, page, page-&gt;cache);
+		return;
+	}
+
+	AutoLocker&lt;PagePool&gt; _(sPagePool);
+
+	if (page-&gt;state == PAGE_STATE_MODIFIED)
+		cache-&gt;modifiedPages.Remove(page);
+
+	cache-&gt;pages.Remove(page);
+
+	hash_remove(sPagePool.pageHash, page);
+
+	page-&gt;cache = NULL;
+	page-&gt;offset = 0;
+}
+
+
+vm_page *
+vm_cache_lookup_page(file_cache_ref *cache, off_t offset)
+{
+	if (!cache)
+		return NULL;
+
+	AutoLocker&lt;PagePool&gt; _(sPagePool);
+
+	page_hash_key key(cache-&gt;deviceFD, cache-&gt;nodeID, offset);
+
+	vm_page* page = (vm_page*)hash_lookup(sPagePool.pageHash, &amp;key);
+
+	if (page)
+		vm_page_get_page(page);
+
+	return page;
+}
+
+
+// cache must be locked
+//
+status_t
+vm_cache_resize(file_cache_ref *cache, off_t newSize)
+{
+	off_t oldAlignedSize = PAGE_ALIGN(cache-&gt;virtual_size);
+	off_t newAlignedSize = PAGE_ALIGN(newSize);
+
+	cache-&gt;virtual_size = newSize;
+
+	// if the aligned cache size increased or remained the same, we're done
+	if (newAlignedSize &gt;= oldAlignedSize)
+		return B_OK;
+
+	// the file shrinks, so we need to get rid of excess pages
+
+	// Hold the page pool lock virtually all the time from now on.
+	AutoLocker&lt;PagePool&gt; poolLocker(sPagePool);
+
+	// For sake of efficiency we sort the cache's list of pages so that all
+	// pages that need to be removed are at the beginning of the list.
+	vm_page* page = cache-&gt;pages.Head();
+	if (newAlignedSize &gt; 0) {
+		while (page) {
+			vm_page* nextPage = cache-&gt;pages.GetNext(page);
+
+			if (page-&gt;offset &gt;= newAlignedSize) {
+				// move to the beginning of the list
+				cache-&gt;pages.Remove(page);
+				cache-&gt;pages.Add(page, false);
+			}
+
+			page = nextPage;
+		}
+	}
+
+	// now we remove and free the excess pages one by one
+	while (true) {
+		// get the first page in the list to remove
+		// (since we sorted the list, this is usually very cheap)
+		for (cache_page_list::Iterator it(&amp;cache-&gt;pages); (page = it.Next());) {
+			if (page-&gt;offset &gt;= newAlignedSize)
+				break;
+		}
+
+		// no more pages? -- then we're done
+		if (!page)
+			return B_OK;
+
+		if (page-&gt;state == PAGE_STATE_BUSY) {
+			// the page is busy -- wait a while and try again
+			poolLocker.Unlock();
+			mutex_unlock(&amp;cache-&gt;lock);
+			sleep(20000);
+			mutex_lock(&amp;cache-&gt;lock);
+			poolLocker.Lock();
+		} else {
+			// the page isn't busy -- get rid of it
+			vm_page_get_page(page);
+			vm_cache_remove_page(cache, page);
+			vm_page_set_state(page, PAGE_STATE_FREE);
+			vm_page_put_page(page);
+		}
+	}
+
+	return B_OK;
+}
+
+
+status_t
+vm_cache_write_modified(file_cache_ref *cache, bool fsReenter)
+{
+	// TODO: Write more than one page at a time. To avoid deadlocks, when a
+	// busy page is encountered the previously collected pages need to be
+	// written. Otherwise as many pages as our on-stack array can contain
+	// can be processed at once.
+	MutexLocker locker(cache-&gt;lock);
+	while (true) {	
+		// get the next modified page and mark it busy
+		vm_page* page = NULL;
+
+		while (true) {
+			// get the first modified page
+			AutoLocker&lt;PagePool&gt; poolLocker(sPagePool);
+			page = cache-&gt;modifiedPages.Head();
+
+			if (!page)
+				return B_OK;
+
+			// if not marked busy, remove it and mark it busy
+			if (page-&gt;state != PAGE_STATE_BUSY) {
+				cache-&gt;modifiedPages.Remove(page);
+				vm_page_get_page(page);
+				page-&gt;state = PAGE_STATE_BUSY;
+				break;
+			}
+
+			// page is busy -- wait a while
+			vm_page_put_page(page);
+			poolLocker.Unlock();
+			locker.Unlock();
+			sleep(20000);
+			locker.Lock();
+		}
+
+		locker.Unlock();
+
+		// write the page
+		size_t bytes = min_c(B_PAGE_SIZE, cache-&gt;virtual_size - page-&gt;offset);
+		iovec vecs[1];
+		vecs[0].iov_base = page-&gt;data;
+		vecs[0].iov_len = bytes;
+		status_t error = pages_io(cache, page-&gt;offset, vecs, 1, &amp;bytes, true);
+		if (error != B_OK)
+			return error;
+
+		locker.Lock();
+
+		vm_page_set_state(page, PAGE_STATE_ACTIVE);
+		vm_page_put_page(page);
+	}
+
+	return B_OK;
+}
+
+
+status_t
+vfs_read_pages(int fd, off_t pos, const iovec *vecs, size_t count,
+	size_t *_numBytes, bool fsReenter)
+{
+	// check how much the iovecs allow us to read
+	size_t toRead = 0;
+	for (size_t i = 0; i &lt; count; i++)
+		toRead += vecs[i].iov_len;
+
+	iovec* newVecs = NULL;
+	if (*_numBytes &lt; toRead) {
+		// We're supposed to read less than specified by the vecs. Since
+		// readv_pos() doesn't support this, we need to clone the vecs.
+		newVecs = new(nothrow) iovec[count];
+		if (!newVecs)
+			return B_NO_MEMORY;
+
+		size_t newCount = 0;
+		for (size_t i = 0; i &lt; count &amp;&amp; toRead &gt; 0; i++) {
+			size_t vecLen = min_c(vecs[i].iov_len, toRead);
+			newVecs[i].iov_base = vecs[i].iov_base;
+			newVecs[i].iov_len = vecLen;
+			toRead -= vecLen;
+			newCount++;
+		}
+
+		vecs = newVecs;
+		count = newCount;
+	}
+
+	ssize_t bytesRead = readv_pos(fd, pos, vecs, count);
+	delete[] newVecs;
+	if (bytesRead &lt; 0)
+		return bytesRead;
+
+	*_numBytes = bytesRead;
+	return B_OK;
+}
+
+
+status_t
+vfs_write_pages(int fd, off_t pos, const iovec *vecs, size_t count,
+	size_t *_numBytes, bool fsReenter)
+{
+	// check how much the iovecs allow us to write
+	size_t toWrite = 0;
+	for (size_t i = 0; i &lt; count; i++)
+		toWrite += vecs[i].iov_len;
+
+	iovec* newVecs = NULL;
+	if (*_numBytes &lt; toWrite) {
+		// We're supposed to write less than specified by the vecs. Since
+		// writev_pos() doesn't support this, we need to clone the vecs.
+		newVecs = new(nothrow) iovec[count];
+		if (!newVecs)
+			return B_NO_MEMORY;
+
+		size_t newCount = 0;
+		for (size_t i = 0; i &lt; count &amp;&amp; toWrite &gt; 0; i++) {
+			size_t vecLen = min_c(vecs[i].iov_len, toWrite);
+			newVecs[i].iov_base = vecs[i].iov_base;
+			newVecs[i].iov_len = vecLen;
+			toWrite -= vecLen;
+			newCount++;
+		}
+
+		vecs = newVecs;
+		count = newCount;
+	}
+
+	ssize_t bytesWritten = writev_pos(fd, pos, vecs, count);
+	delete[] newVecs;
+	if (bytesWritten &lt; 0)
+		return bytesWritten;
+
+	*_numBytes = bytesWritten;
+	return B_OK;
+}
+
+
+status_t
+vfs_get_file_map(file_cache_ref *cache, off_t offset, size_t size,
+	struct file_io_vec *vecs, size_t *_count)
+{
+	// get the volume for the cache
+	HaikuKernelVolume* volume = file_cache_get_volume(cache-&gt;mountID);
+	if (!volume) {
+		panic(&quot;vfs_get_file_map(): no volume for ID %ld\n&quot;, cache-&gt;mountID);
+		return B_ERROR;
+	}
+
+	// node handle cached?
+	fs_vnode nodeHandle = NULL;
+	{
+		MutexLocker _(cache-&gt;lock);
+		nodeHandle = cache-&gt;nodeHandle;
+	}
+
+	// if not cached, get the node handle
+	if (!nodeHandle) {
+		status_t error = UserlandFS::KernelEmu::get_vnode(cache-&gt;mountID,
+			cache-&gt;nodeID, &amp;nodeHandle);
+		if (error != B_OK)
+			return error;
+		UserlandFS::KernelEmu::put_vnode(cache-&gt;mountID, cache-&gt;nodeID);
+
+		// cache the handle
+		MutexLocker _(cache-&gt;lock);
+		cache-&gt;nodeHandle = nodeHandle;
+	}
+
+	return volume-&gt;GetFileMap(nodeHandle, offset, size, vecs, _count);
+}

[... truncated: 1144 lines follow ...]

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message: <A HREF="001217.html">[Haiku-commits] r20405 - in haiku/trunk/headers/private: kernel/util userlandfs/shared
</A></li>
	<LI>Next message: <A HREF="001186.html">[Haiku-commits] r20407 - in haiku/trunk: headers/private/kernel	src/system/kernel/vm
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#1185">[ date ]</a>
              <a href="thread.html#1185">[ thread ]</a>
              <a href="subject.html#1185">[ subject ]</a>
              <a href="author.html#1185">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.berlios.de/mailman/listinfo/haiku-commits">More information about the Haiku-commits
mailing list</a><br>
</body></html>
